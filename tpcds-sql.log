ubuntu@ubuntu-Virtual-Machine:~/git$ git clone https://github.com/maropu/spark-tpcds-datagen.git
Cloning into 'spark-tpcds-datagen'...
remote: Enumerating objects: 4686, done.
remote: Counting objects: 100% (505/505), done.
remote: Compressing objects: 100% (143/143), done.
remote: Total 4686 (delta 333), reused 500 (delta 332), pack-reused 4181
Receiving objects: 100% (4686/4686), 36.14 MiB | 11.39 MiB/s, done.
Resolving deltas: 100% (2760/2760), done.
ubuntu@ubuntu-Virtual-Machine:~/git$ ls
101                                flink-playgrounds  presto             spark-homework
admission-controller-webhook-demo  golang             skaffold           spark-tpcds-datagen
flink-1.15.0                       kind               skaffold_download  SparkWordCount
flink-1.15.0-bin-scala_2.12.tgz    kylin              spark              trino
ubuntu@ubuntu-Virtual-Machine:~/git$ cd spark-tpcds-datagen/
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ ls
assembly  bin  build  LICENSE  pom.xml  README.md  reports  scalastyle-config.xml  src  thirdparty
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ wget https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz
--2022-07-24 17:52:21--  https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz
Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2
Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 224374704 (214M) [application/x-gzip]
Saving to: ‘spark-3.1.1-bin-hadoop2.7.tgz’

spark-3.1.1-bin-hadoop2.7.t 100%[==========================================>] 213.98M  9.71MB/s    in 24s     

2022-07-24 17:52:46 (9.09 MB/s) - ‘spark-3.1.1-bin-hadoop2.7.tgz’ saved [224374704/224374704]

ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ tar -zxvf spark-3.1.1-bin-hadoop2.7.tgz 
spark-3.1.1-bin-hadoop2.7/
spark-3.1.1-bin-hadoop2.7/NOTICE
spark-3.1.1-bin-hadoop2.7/kubernetes/
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/python_executable_check.py
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/autoscale.py
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/py_container_checks.py
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/decommissioning.py
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/pyfiles.py
spark-3.1.1-bin-hadoop2.7/kubernetes/tests/decommissioning_cleanup.py
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/decom.sh
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile
spark-3.1.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile
spark-3.1.1-bin-hadoop2.7/jars/
spark-3.1.1-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar
spark-3.1.1-bin-hadoop2.7/jars/RoaringBitmap-0.9.0.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-digester-1.8.jar
spark-3.1.1-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/derby-10.12.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar
spark-3.1.1-bin-hadoop2.7/jars/okhttp-3.12.12.jar
spark-3.1.1-bin-hadoop2.7/jars/httpcore-4.4.12.jar
spark-3.1.1-bin-hadoop2.7/jars/logging-interceptor-3.12.12.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/scala-library-2.12.10.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/parquet-format-2.4.0.jar
spark-3.1.1-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar
spark-3.1.1-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-logging-1.1.3.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar
spark-3.1.1-bin-hadoop2.7/jars/jdo-api-3.0.1.jar
spark-3.1.1-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0-M1.jar
spark-3.1.1-bin-hadoop2.7/jars/json4s-core_2.12-3.7.0-M5.jar
spark-3.1.1-bin-hadoop2.7/jars/JLargeArrays-1.5.jar
spark-3.1.1-bin-hadoop2.7/jars/jsp-api-2.1.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-autoscaling-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar
spark-3.1.1-bin-hadoop2.7/jars/json4s-ast_2.12-3.7.0-M5.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-cli-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar
spark-3.1.1-bin-hadoop2.7/jars/parquet-common-1.10.1.jar
spark-3.1.1-bin-hadoop2.7/jars/stax-api-1.0.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.10.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-storage-api-2.7.2.jar
spark-3.1.1-bin-hadoop2.7/jars/algebra_2.12-2.0.0-M2.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/guice-servlet-3.0.jar
spark-3.1.1-bin-hadoop2.7/jars/spire-util_2.12-0.17.0-M1.jar
spark-3.1.1-bin-hadoop2.7/jars/jakarta.activation-api-1.2.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jline-2.14.6.jar
spark-3.1.1-bin-hadoop2.7/jars/breeze_2.12-1.0.jar
spark-3.1.1-bin-hadoop2.7/jars/metrics-jvm-4.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar
spark-3.1.1-bin-hadoop2.7/jars/machinist_2.12-0.6.8.jar
spark-3.1.1-bin-hadoop2.7/jars/scala-compiler-2.12.10.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-pool-1.5.4.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-repl_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jta-1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-admissionregistration-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar
spark-3.1.1-bin-hadoop2.7/jars/metrics-graphite-4.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-streaming_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-launcher_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/objenesis-2.6.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-collections-3.2.2.jar
spark-3.1.1-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jpam-1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar
spark-3.1.1-bin-hadoop2.7/jars/xmlenc-0.52.jar
spark-3.1.1-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-common-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-extensions-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/py4j-0.10.9.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0-M1.jar
spark-3.1.1-bin-hadoop2.7/jars/avro-1.8.2.jar
spark-3.1.1-bin-hadoop2.7/jars/curator-client-2.7.1.jar
spark-3.1.1-bin-hadoop2.7/jars/javax.inject-1.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-apiextensions-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jersey-media-jaxb-2.30.jar
spark-3.1.1-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-io-2.4.jar
spark-3.1.1-bin-hadoop2.7/jars/json4s-jackson_2.12-3.7.0-M5.jar
spark-3.1.1-bin-hadoop2.7/jars/paranamer-2.8.jar
spark-3.1.1-bin-hadoop2.7/jars/cats-kernel_2.12-2.0.0-M4.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-mllib_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jersey-server-2.30.jar
spark-3.1.1-bin-hadoop2.7/jars/stream-2.9.6.jar
spark-3.1.1-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar
spark-3.1.1-bin-hadoop2.7/jars/gson-2.2.4.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/xml-apis-1.4.01.jar
spark-3.1.1-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar
spark-3.1.1-bin-hadoop2.7/jars/antlr4-runtime-4.8-1.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-policy-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-jdbc-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-exec-2.3.7-core.jar
spark-3.1.1-bin-hadoop2.7/jars/opencsv-2.3.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-certificates-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar
spark-3.1.1-bin-hadoop2.7/jars/jsr305-3.0.0.jar
spark-3.1.1-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-sketch_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-dbcp-1.4.jar
spark-3.1.1-bin-hadoop2.7/jars/jersey-container-servlet-core-2.30.jar
spark-3.1.1-bin-hadoop2.7/jars/okio-1.14.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hk2-api-2.6.1.jar
spark-3.1.1-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar
spark-3.1.1-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar
spark-3.1.1-bin-hadoop2.7/jars/orc-mapreduce-1.5.12.jar
spark-3.1.1-bin-hadoop2.7/jars/chill-java-0.9.5.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-settings-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-tags_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jakarta.servlet-api-4.0.3.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/automaton-1.11-8.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-lang-2.6.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-annotations-2.10.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar
spark-3.1.1-bin-hadoop2.7/jars/velocity-1.5.jar
spark-3.1.1-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar
spark-3.1.1-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar
spark-3.1.1-bin-hadoop2.7/jars/JTransforms-3.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jersey-client-2.30.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-catalyst_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/httpclient-4.5.6.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-discovery-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar
spark-3.1.1-bin-hadoop2.7/jars/spire_2.12-0.17.0-M1.jar
spark-3.1.1-bin-hadoop2.7/jars/jersey-hk2-2.30.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-sql_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-math3-3.4.1.jar
spark-3.1.1-bin-hadoop2.7/jars/xbean-asm7-shaded-4.15.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-network-common_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar
spark-3.1.1-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar
spark-3.1.1-bin-hadoop2.7/jars/snappy-java-1.1.8.2.jar
spark-3.1.1-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-shims-0.23-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/guava-14.0.1.jar
spark-3.1.1-bin-hadoop2.7/jars/stax-api-1.0-2.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-service-rpc-3.1.2.jar
spark-3.1.1-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-graphx_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/oro-2.0.8.jar
spark-3.1.1-bin-hadoop2.7/jars/arrow-memory-netty-2.0.0.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-scheduling-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/libfb303-0.9.3.jar
spark-3.1.1-bin-hadoop2.7/jars/core-1.1.2.jar
spark-3.1.1-bin-hadoop2.7/jars/jersey-container-servlet-2.30.jar
spark-3.1.1-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar
spark-3.1.1-bin-hadoop2.7/jars/super-csv-2.2.0.jar
spark-3.1.1-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-module-paranamer-2.10.0.jar
spark-3.1.1-bin-hadoop2.7/jars/aopalliance-1.0.jar
spark-3.1.1-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.10.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-shims-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/json-1.8.jar
spark-3.1.1-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar
spark-3.1.1-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar
spark-3.1.1-bin-hadoop2.7/jars/orc-shims-1.5.12.jar
spark-3.1.1-bin-hadoop2.7/jars/jetty-6.1.26.jar
spark-3.1.1-bin-hadoop2.7/jars/arrow-vector-2.0.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.10.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jersey-common-2.30.jar
spark-3.1.1-bin-hadoop2.7/jars/aircompressor-0.10.jar
spark-3.1.1-bin-hadoop2.7/jars/lz4-java-1.7.1.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/activation-1.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-crypto-1.1.0.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-tags_2.12-3.1.1-tests.jar
spark-3.1.1-bin-hadoop2.7/jars/libthrift-0.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/HikariCP-2.5.1.jar
spark-3.1.1-bin-hadoop2.7/jars/generex-1.0.2.jar
spark-3.1.1-bin-hadoop2.7/jars/breeze-macros_2.12-1.0.jar
spark-3.1.1-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar
spark-3.1.1-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar
spark-3.1.1-bin-hadoop2.7/jars/json4s-scalap_2.12-3.7.0-M5.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-events-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-lang3-3.10.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.11.2.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-httpclient-3.1.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-client-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-hive_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/shims-0.9.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar
spark-3.1.1-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/orc-core-1.5.12.jar
spark-3.1.1-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-common-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/xz-1.5.jar
spark-3.1.1-bin-hadoop2.7/jars/ST4-4.0.4.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-yarn_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-batch-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/netty-all-4.1.51.Final.jar
spark-3.1.1-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar
spark-3.1.1-bin-hadoop2.7/jars/chill_2.12-0.9.5.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-databind-2.10.0.jar
spark-3.1.1-bin-hadoop2.7/jars/scala-reflect-2.12.10.jar
spark-3.1.1-bin-hadoop2.7/jars/joda-time-2.10.5.jar
spark-3.1.1-bin-hadoop2.7/jars/minlog-1.3.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar
spark-3.1.1-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-compress-1.20.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-core_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar
spark-3.1.1-bin-hadoop2.7/jars/jodd-core-3.5.2.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-storageclass-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-core-2.10.0.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-core-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-net-3.1.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar
spark-3.1.1-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar
spark-3.1.1-bin-hadoop2.7/jars/janino-3.0.16.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-shims-common-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/javolution-5.5.1.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-rbac-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/transaction-api-1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-metrics-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-cli-1.2.jar
spark-3.1.1-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar
spark-3.1.1-bin-hadoop2.7/jars/metrics-jmx-4.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/zstd-jni-1.4.8-1.jar
spark-3.1.1-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-codec-1.10.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/curator-framework-2.7.1.jar
spark-3.1.1-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-metastore-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-beeline-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/metrics-core-4.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-llap-common-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/arrow-format-2.0.0.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-kvstore_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar
spark-3.1.1-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/arrow-memory-core-2.0.0.jar
spark-3.1.1-bin-hadoop2.7/jars/parquet-column-1.10.1.jar
spark-3.1.1-bin-hadoop2.7/jars/jetty-util-6.1.26.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-coordination-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar
spark-3.1.1-bin-hadoop2.7/jars/guice-3.0.jar
spark-3.1.1-bin-hadoop2.7/jars/commons-text-1.6.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-apps-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/metrics-json-4.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/snakeyaml-1.24.jar
spark-3.1.1-bin-hadoop2.7/jars/ivy-2.4.0.jar
spark-3.1.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar
spark-3.1.1-bin-hadoop2.7/jars/univocity-parsers-2.9.1.jar
spark-3.1.1-bin-hadoop2.7/jars/pyrolite-4.30.jar
spark-3.1.1-bin-hadoop2.7/jars/spark-mesos_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/jars/log4j-1.2.17.jar
spark-3.1.1-bin-hadoop2.7/jars/hive-serde-2.3.7.jar
spark-3.1.1-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar
spark-3.1.1-bin-hadoop2.7/jars/kubernetes-model-networking-4.12.0.jar
spark-3.1.1-bin-hadoop2.7/jars/zookeeper-3.4.14.jar
spark-3.1.1-bin-hadoop2.7/data/
spark-3.1.1-bin-hadoop2.7/data/mllib/
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_lda_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_svm_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/iris_libsvm.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_movielens_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/als/
spark-3.1.1-bin-hadoop2.7/data/mllib/als/test.data
spark-3.1.1-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/pic_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/images/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/kittens/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/license.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg
spark-3.1.1-bin-hadoop2.7/data/mllib/images/license.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/ridge-data/
spark-3.1.1-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data
spark-3.1.1-bin-hadoop2.7/data/mllib/kmeans_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/pagerank_data.txt
spark-3.1.1-bin-hadoop2.7/data/mllib/gmm_data.txt
spark-3.1.1-bin-hadoop2.7/data/graphx/
spark-3.1.1-bin-hadoop2.7/data/graphx/users.txt
spark-3.1.1-bin-hadoop2.7/data/graphx/followers.txt
spark-3.1.1-bin-hadoop2.7/data/streaming/
spark-3.1.1-bin-hadoop2.7/data/streaming/AFINN-111.txt
spark-3.1.1-bin-hadoop2.7/R/
spark-3.1.1-bin-hadoop2.7/R/lib/
spark-3.1.1-bin-hadoop2.7/R/lib/sparkr.zip
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/tests/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/tests/testthat/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/profile/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/profile/shell.R
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/profile/general.R
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/INDEX
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/Meta/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/help/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/help/AnIndex
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/help/paths.rds
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/R/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/R/SparkR
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/NAMESPACE
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/html/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/html/00Index.html
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/html/R.css
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/worker/
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/worker/worker.R
spark-3.1.1-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R
spark-3.1.1-bin-hadoop2.7/README.md
spark-3.1.1-bin-hadoop2.7/RELEASE
spark-3.1.1-bin-hadoop2.7/yarn/
spark-3.1.1-bin-hadoop2.7/yarn/spark-3.1.1-yarn-shuffle.jar
spark-3.1.1-bin-hadoop2.7/LICENSE
spark-3.1.1-bin-hadoop2.7/sbin/
spark-3.1.1-bin-hadoop2.7/sbin/start-workers.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-master.sh
spark-3.1.1-bin-hadoop2.7/sbin/workers.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-worker.sh
spark-3.1.1-bin-hadoop2.7/sbin/spark-config.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-history-server.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-slaves.sh
spark-3.1.1-bin-hadoop2.7/sbin/spark-daemon.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-worker.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh
spark-3.1.1-bin-hadoop2.7/sbin/decommission-worker.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh
spark-3.1.1-bin-hadoop2.7/sbin/decommission-slave.sh
spark-3.1.1-bin-hadoop2.7/sbin/slaves.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-history-server.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-thriftserver.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-thriftserver.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-slave.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-all.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-slave.sh
spark-3.1.1-bin-hadoop2.7/sbin/spark-daemons.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-workers.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-slaves.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-all.sh
spark-3.1.1-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh
spark-3.1.1-bin-hadoop2.7/sbin/stop-master.sh
spark-3.1.1-bin-hadoop2.7/examples/
spark-3.1.1-bin-hadoop2.7/examples/src/
spark-3.1.1-bin-hadoop2.7/examples/src/main/
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/survreg.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/glm.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/lm_with_elastic_net.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/lda.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/kstest.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/ml.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/fmRegressor.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/mlp.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/als.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/fmClassifier.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/logit.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/gbt.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/ml/fpm.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/dataframe.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/data-manipulation.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/streaming/
spark-3.1.1-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/people.json
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/users.avro
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/people.csv
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/users.parquet
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/users.orc
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/dir1/
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/user.avsc
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/full_user.avsc
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/kv1.txt
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/people.txt
spark-3.1.1-bin-hadoop2.7/examples/src/main/resources/employees.json
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java
spark-3.1.1-bin-hadoop2.7/examples/src/main/scripts/
spark-3.1.1-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/kmeans.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/univariate_feature_selector_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/als_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/variance_threshold_selector_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/logistic_regression.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/als.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/status_api_demo.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/pagerank.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sort.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/transitive_closure.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/pi.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/datasource.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/hive.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/arrow.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/sql/basic.py
spark-3.1.1-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py
spark-3.1.1-bin-hadoop2.7/examples/jars/
spark-3.1.1-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.1.1.jar
spark-3.1.1-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar
spark-3.1.1-bin-hadoop2.7/conf/
spark-3.1.1-bin-hadoop2.7/conf/metrics.properties.template
spark-3.1.1-bin-hadoop2.7/conf/workers.template
spark-3.1.1-bin-hadoop2.7/conf/fairscheduler.xml.template
spark-3.1.1-bin-hadoop2.7/conf/log4j.properties.template
spark-3.1.1-bin-hadoop2.7/conf/spark-defaults.conf.template
spark-3.1.1-bin-hadoop2.7/conf/spark-env.sh.template
spark-3.1.1-bin-hadoop2.7/bin/
spark-3.1.1-bin-hadoop2.7/bin/sparkR.cmd
spark-3.1.1-bin-hadoop2.7/bin/sparkR
spark-3.1.1-bin-hadoop2.7/bin/spark-submit
spark-3.1.1-bin-hadoop2.7/bin/pyspark2.cmd
spark-3.1.1-bin-hadoop2.7/bin/spark-class
spark-3.1.1-bin-hadoop2.7/bin/pyspark.cmd
spark-3.1.1-bin-hadoop2.7/bin/spark-submit2.cmd
spark-3.1.1-bin-hadoop2.7/bin/load-spark-env.cmd
spark-3.1.1-bin-hadoop2.7/bin/spark-sql
spark-3.1.1-bin-hadoop2.7/bin/docker-image-tool.sh
spark-3.1.1-bin-hadoop2.7/bin/find-spark-home.cmd
spark-3.1.1-bin-hadoop2.7/bin/load-spark-env.sh
spark-3.1.1-bin-hadoop2.7/bin/pyspark
spark-3.1.1-bin-hadoop2.7/bin/spark-shell.cmd
spark-3.1.1-bin-hadoop2.7/bin/spark-shell2.cmd
spark-3.1.1-bin-hadoop2.7/bin/spark-submit.cmd
spark-3.1.1-bin-hadoop2.7/bin/beeline.cmd
spark-3.1.1-bin-hadoop2.7/bin/find-spark-home
spark-3.1.1-bin-hadoop2.7/bin/spark-class.cmd
spark-3.1.1-bin-hadoop2.7/bin/sparkR2.cmd
spark-3.1.1-bin-hadoop2.7/bin/beeline
spark-3.1.1-bin-hadoop2.7/bin/spark-class2.cmd
spark-3.1.1-bin-hadoop2.7/bin/spark-sql.cmd
spark-3.1.1-bin-hadoop2.7/bin/run-example
spark-3.1.1-bin-hadoop2.7/bin/spark-shell
spark-3.1.1-bin-hadoop2.7/bin/run-example.cmd
spark-3.1.1-bin-hadoop2.7/bin/spark-sql2.cmd
spark-3.1.1-bin-hadoop2.7/python/
spark-3.1.1-bin-hadoop2.7/python/.gitignore
spark-3.1.1-bin-hadoop2.7/python/run-tests-with-coverage
spark-3.1.1-bin-hadoop2.7/python/mypy.ini
spark-3.1.1-bin-hadoop2.7/python/pylintrc
spark-3.1.1-bin-hadoop2.7/python/MANIFEST.in
spark-3.1.1-bin-hadoop2.7/python/README.md
spark-3.1.1-bin-hadoop2.7/python/test_coverage/
spark-3.1.1-bin-hadoop2.7/python/test_coverage/coverage_daemon.py
spark-3.1.1-bin-hadoop2.7/python/test_coverage/conf/
spark-3.1.1-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf
spark-3.1.1-bin-hadoop2.7/python/test_coverage/sitecustomize.py
spark-3.1.1-bin-hadoop2.7/python/run-tests.py
spark-3.1.1-bin-hadoop2.7/python/setup.py
spark-3.1.1-bin-hadoop2.7/python/test_support/
spark-3.1.1-bin-hadoop2.7/python/test_support/userlibrary.py
spark-3.1.1-bin-hadoop2.7/python/test_support/hello/
spark-3.1.1-bin-hadoop2.7/python/test_support/hello/sub_hello/
spark-3.1.1-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt
spark-3.1.1-bin-hadoop2.7/python/test_support/hello/hello.txt
spark-3.1.1-bin-hadoop2.7/python/test_support/userlib-0.1.zip
spark-3.1.1-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/people.json
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/people_array.json
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/text-test.txt
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/ages.csv
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/streaming/
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt
spark-3.1.1-bin-hadoop2.7/python/test_support/sql/people1.json
spark-3.1.1-bin-hadoop2.7/python/pyspark/
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_worker.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_serializers.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_util.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_rdd.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_profiler.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_install_spark.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_join.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_context.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_conf.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/tests/test_daemon.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/_typing.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/testing/
spark-3.1.1-bin-hadoop2.7/python/pyspark/testing/mlutils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/testing/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/testing/mllibutils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/testing/utils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/testing/sqlutils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/testing/streamingutils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/accumulators.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/rddsampler.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/install.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/status.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_util.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/evaluation.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/_typing.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/functions.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/recommendation.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/fpm.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/pipeline.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/base.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/feature.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/stat.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/stat.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/image.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/classification.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/common.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/pipeline.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/recommendation.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/clustering.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/regression.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/param/
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/param/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/param/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/param/shared.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/param/shared.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/feature.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/classification.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tree.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/util.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tuning.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/fpm.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/regression.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/functions.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/base.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/image.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/tree.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/clustering.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/common.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/linalg/
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/evaluation.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/ml/util.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/context.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/find_spark_home.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/serializers.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/java_gateway.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/traceback_utils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/tests/
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/tests/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/tests/test_resources.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/profile.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/information.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/requests.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/information.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/requests.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resource/profile.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/conf.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resultiterable.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/version.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/files.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/_typing.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/recommendation.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/fpm.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/feature.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/classification.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/common.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/random.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/recommendation.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/clustering.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/regression.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/feature.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/classification.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tree.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/util.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/fpm.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/regression.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/random.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/test.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/test.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/tree.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/clustering.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/common.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/linalg/
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/mllib/util.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/resultiterable.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/profiler.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/statcounter.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/join.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/daemon.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/rdd.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/context.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/cloudpickle/
spark-3.1.1-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle_fast.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/cloudpickle/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/cloudpickle/compat.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/storagelevel.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/version.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/py.typed
spark-3.1.1-bin-hadoop2.7/python/pyspark/files.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/worker.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/statcounter.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/conf.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/shell.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/tests/
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/dstream.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/kinesis.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/context.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/dstream.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/listener.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/kinesis.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/listener.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/context.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/streaming/util.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/accumulators.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/profiler.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/status.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/broadcast.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/types.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/functions.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/series.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/frame.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/_typing.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/functions.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/streaming.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/context.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/column.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/catalog.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/types.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/window.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/udf.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/conf.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/session.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/column.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/group.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/catalog.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/group.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/context.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/types.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/functions.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/conf.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/udf.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/avro/
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/avro/functions.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/avro/functions.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/readwriter.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/window.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/session.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/sql/streaming.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/shuffle.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/rdd.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/taskcontext.pyi
spark-3.1.1-bin-hadoop2.7/python/pyspark/taskcontext.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/_globals.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/broadcast.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/util.py
spark-3.1.1-bin-hadoop2.7/python/pyspark/storagelevel.py
spark-3.1.1-bin-hadoop2.7/python/.coveragerc
spark-3.1.1-bin-hadoop2.7/python/docs/
spark-3.1.1-bin-hadoop2.7/python/docs/make2.bat
spark-3.1.1-bin-hadoop2.7/python/docs/source/
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/pyspark.ss.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/index.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/pyspark.ml.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/pyspark.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/pyspark.mllib.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/pyspark.streaming.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/pyspark.sql.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/reference/pyspark.resource.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/index.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/getting_started/
spark-3.1.1-bin-hadoop2.7/python/docs/source/getting_started/index.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/getting_started/quickstart.ipynb
spark-3.1.1-bin-hadoop2.7/python/docs/source/getting_started/install.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/conf.py
spark-3.1.1-bin-hadoop2.7/python/docs/source/_templates/
spark-3.1.1-bin-hadoop2.7/python/docs/source/_templates/autosummary/
spark-3.1.1-bin-hadoop2.7/python/docs/source/_templates/autosummary/class.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/_templates/autosummary/class_with_docs.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/_static/
spark-3.1.1-bin-hadoop2.7/python/docs/source/_static/copybutton.js
spark-3.1.1-bin-hadoop2.7/python/docs/source/_static/css/
spark-3.1.1-bin-hadoop2.7/python/docs/source/_static/css/pyspark.css
spark-3.1.1-bin-hadoop2.7/python/docs/source/development/
spark-3.1.1-bin-hadoop2.7/python/docs/source/development/setting_ide.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/development/index.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/development/debugging.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/development/testing.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/development/contributing.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/user_guide/
spark-3.1.1-bin-hadoop2.7/python/docs/source/user_guide/arrow_pandas.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/user_guide/index.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/user_guide/python_packaging.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/index.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst
spark-3.1.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst
spark-3.1.1-bin-hadoop2.7/python/docs/make.bat
spark-3.1.1-bin-hadoop2.7/python/docs/Makefile
spark-3.1.1-bin-hadoop2.7/python/lib/
spark-3.1.1-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt
spark-3.1.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip
spark-3.1.1-bin-hadoop2.7/python/lib/pyspark.zip
spark-3.1.1-bin-hadoop2.7/python/run-tests
spark-3.1.1-bin-hadoop2.7/python/setup.cfg
spark-3.1.1-bin-hadoop2.7/licenses/
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-respond.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-antlr.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-janino.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-protobuf.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jquery.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-scopt.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-netlib.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-datatables.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-paranamer.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-CC0.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jodd.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-f2j.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-machinist.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-javolution.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-modernizr.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-spire.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-join.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-slf4j.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-arpack.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-javassist.html
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-zstd.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-scala.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-automaton.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-minlog.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-mustache.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-jline.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-py4j.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-re2j.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-kryo.txt
spark-3.1.1-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ ls
assembly  build    pom.xml    reports                spark-3.1.1-bin-hadoop2.7      src
bin       LICENSE  README.md  scalastyle-config.xml  spark-3.1.1-bin-hadoop2.7.tgz  thirdparty
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ mkdir -p tpcds-data-1g
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ export SPARK_HOME=./spark-3.1.1-bin-hadoop2.7
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ ./bin/dsdgen --output-location tpcds-data-1g
/home/ubuntu/git/spark-tpcds-datagen/bin/../target/spark-tpcds-datagen_2.12-0.1.0-SNAPSHOT-with-dependencies.jar not found, so use pre-compiled /home/ubuntu/git/spark-tpcds-datagen/bin/../assembly/spark-tpcds-datagen_2.12-0.1.0-SNAPSHOT-with-dependencies.jar
Using `spark-submit` from path: ./spark-3.1.1-bin-hadoop2.7
22/07/24 17:58:22 WARN Utils: Your hostname, ubuntu-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 172.28.45.111 instead (on interface eth0)
22/07/24 17:58:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
22/07/24 17:58:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/07/24 17:58:23 INFO SparkContext: Running Spark version 3.1.1
22/07/24 17:58:23 INFO ResourceUtils: ==============================================================
22/07/24 17:58:23 INFO ResourceUtils: No custom resources configured for spark.driver.
22/07/24 17:58:23 INFO ResourceUtils: ==============================================================
22/07/24 17:58:23 INFO SparkContext: Submitted application: org.apache.spark.sql.execution.benchmark.TPCDSDatagen
22/07/24 17:58:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/07/24 17:58:23 INFO ResourceProfile: Limiting resource is cpu
22/07/24 17:58:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/07/24 17:58:23 INFO SecurityManager: Changing view acls to: ubuntu
22/07/24 17:58:23 INFO SecurityManager: Changing modify acls to: ubuntu
22/07/24 17:58:23 INFO SecurityManager: Changing view acls groups to: 
22/07/24 17:58:23 INFO SecurityManager: Changing modify acls groups to: 
22/07/24 17:58:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()
22/07/24 17:58:24 INFO Utils: Successfully started service 'sparkDriver' on port 44383.
22/07/24 17:58:24 INFO SparkEnv: Registering MapOutputTracker
22/07/24 17:58:24 INFO SparkEnv: Registering BlockManagerMaster
22/07/24 17:58:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/07/24 17:58:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/07/24 17:58:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/07/24 17:58:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-17404399-720e-4cb5-a8df-d41753170c31
22/07/24 17:58:24 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/07/24 17:58:24 INFO SparkEnv: Registering OutputCommitCoordinator
22/07/24 17:58:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/07/24 17:58:24 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ubuntu-Virtual-Machine.mshome.net:4040
22/07/24 17:58:24 INFO SparkContext: Added JAR file:/home/ubuntu/git/spark-tpcds-datagen/bin/../assembly/spark-tpcds-datagen_2.12-0.1.0-SNAPSHOT-with-dependencies.jar at spark://ubuntu-Virtual-Machine.mshome.net:44383/jars/spark-tpcds-datagen_2.12-0.1.0-SNAPSHOT-with-dependencies.jar with timestamp 1658656703542
22/07/24 17:58:24 INFO Executor: Starting executor ID driver on host ubuntu-Virtual-Machine.mshome.net
22/07/24 17:58:24 INFO Executor: Fetching spark://ubuntu-Virtual-Machine.mshome.net:44383/jars/spark-tpcds-datagen_2.12-0.1.0-SNAPSHOT-with-dependencies.jar with timestamp 1658656703542
22/07/24 17:58:24 INFO TransportClientFactory: Successfully created connection to ubuntu-Virtual-Machine.mshome.net/172.28.45.111:44383 after 34 ms (0 ms spent in bootstraps)
22/07/24 17:58:24 INFO Utils: Fetching spark://ubuntu-Virtual-Machine.mshome.net:44383/jars/spark-tpcds-datagen_2.12-0.1.0-SNAPSHOT-with-dependencies.jar to /tmp/spark-fe9b1ba4-3ef1-4061-ad6d-b15f9243ba66/userFiles-8c04bc04-8299-4d8a-8d33-71ff8593fb55/fetchFileTemp5532151666400986914.tmp
22/07/24 17:58:24 INFO Executor: Adding file:/tmp/spark-fe9b1ba4-3ef1-4061-ad6d-b15f9243ba66/userFiles-8c04bc04-8299-4d8a-8d33-71ff8593fb55/spark-tpcds-datagen_2.12-0.1.0-SNAPSHOT-with-dependencies.jar to class loader
22/07/24 17:58:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38047.
22/07/24 17:58:24 INFO NettyBlockTransferService: Server created on ubuntu-Virtual-Machine.mshome.net:38047
22/07/24 17:58:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/07/24 17:58:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 38047, None)
22/07/24 17:58:24 INFO BlockManagerMasterEndpoint: Registering block manager ubuntu-Virtual-Machine.mshome.net:38047 with 366.3 MiB RAM, BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 38047, None)
22/07/24 17:58:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 38047, None)
22/07/24 17:58:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 38047, None)
22/07/24 17:58:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/ubuntu/git/spark-tpcds-datagen/spark-warehouse').
22/07/24 17:58:25 INFO SharedState: Warehouse path is 'file:/home/ubuntu/git/spark-tpcds-datagen/spark-warehouse'.
22/07/24 17:58:28 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
22/07/24 17:58:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:58:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:58:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:58:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:58:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:58:29 INFO CodeGenerator: Code generated in 286.774905 ms
22/07/24 17:58:29 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 17:58:29 INFO DAGScheduler: Got job 0 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 17:58:29 INFO DAGScheduler: Final stage: ResultStage 0 (main at NativeMethodAccessorImpl.java:0)
22/07/24 17:58:29 INFO DAGScheduler: Parents of final stage: List()
22/07/24 17:58:29 INFO DAGScheduler: Missing parents: List()
22/07/24 17:58:29 INFO DAGScheduler: Submitting ResultStage 0 (CoalescedRDD[6] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 17:58:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 234.0 KiB, free 366.1 MiB)
22/07/24 17:58:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 71.0 KiB, free 366.0 MiB)
22/07/24 17:58:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 71.0 KiB, free: 366.2 MiB)
22/07/24 17:58:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1383
22/07/24 17:58:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (CoalescedRDD[6] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 17:58:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
22/07/24 17:58:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 17:58:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
22/07/24 17:58:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:58:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:58:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:58:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:58:30 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:58:30 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:58:30 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 17:58:30 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 17:58:30 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 17:58:30 INFO ParquetOutputFormat: Dictionary is on
22/07/24 17:58:30 INFO ParquetOutputFormat: Validation is off
22/07/24 17:58:30 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 17:58:30 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 17:58:30 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 17:58:30 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 17:58:30 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 17:58:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "cs_sold_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_sold_time_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ship_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_bill_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_bill_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_bill_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_bill_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ship_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ship_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ship_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ship_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_call_center_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_catalog_page_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ship_mode_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_warehouse_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_promo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_order_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_quantity",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_wholesale_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_list_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_sales_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ext_discount_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ext_sales_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ext_wholesale_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ext_list_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ext_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_coupon_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_ext_ship_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_net_paid",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_net_paid_inc_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_net_paid_inc_ship",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_net_paid_inc_ship_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cs_net_profit",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 cs_sold_date_sk;
  optional int32 cs_sold_time_sk;
  optional int32 cs_ship_date_sk;
  optional int32 cs_bill_customer_sk;
  optional int32 cs_bill_cdemo_sk;
  optional int32 cs_bill_hdemo_sk;
  optional int32 cs_bill_addr_sk;
  optional int32 cs_ship_customer_sk;
  optional int32 cs_ship_cdemo_sk;
  optional int32 cs_ship_hdemo_sk;
  optional int32 cs_ship_addr_sk;
  optional int32 cs_call_center_sk;
  optional int32 cs_catalog_page_sk;
  optional int32 cs_ship_mode_sk;
  optional int32 cs_warehouse_sk;
  optional int32 cs_item_sk;
  optional int32 cs_promo_sk;
  optional int32 cs_order_number;
  optional int32 cs_quantity;
  optional int32 cs_wholesale_cost (DECIMAL(7,2));
  optional int32 cs_list_price (DECIMAL(7,2));
  optional int32 cs_sales_price (DECIMAL(7,2));
  optional int32 cs_ext_discount_amt (DECIMAL(7,2));
  optional int32 cs_ext_sales_price (DECIMAL(7,2));
  optional int32 cs_ext_wholesale_cost (DECIMAL(7,2));
  optional int32 cs_ext_list_price (DECIMAL(7,2));
  optional int32 cs_ext_tax (DECIMAL(7,2));
  optional int32 cs_coupon_amt (DECIMAL(7,2));
  optional int32 cs_ext_ship_cost (DECIMAL(7,2));
  optional int32 cs_net_paid (DECIMAL(7,2));
  optional int32 cs_net_paid_inc_tax (DECIMAL(7,2));
  optional int32 cs_net_paid_inc_ship (DECIMAL(7,2));
  optional int32 cs_net_paid_inc_ship_tax (DECIMAL(7,2));
  optional int32 cs_net_profit (DECIMAL(7,2));
}

       
22/07/24 17:58:30 INFO CodecPool: Got brand-new compressor [.snappy]
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 17:58:30 INFO CodeGenerator: Code generated in 264.56658 ms
22/07/24 17:59:01 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 107694901
22/07/24 17:59:01 INFO FileOutputCommitter: Saved output of task 'attempt_202207241758298517003867272127575_0000_m_000000_0' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_sales/_temporary/0/task_202207241758298517003867272127575_0000_m_000000
22/07/24 17:59:01 INFO SparkHadoopMapRedUtil: attempt_202207241758298517003867272127575_0000_m_000000_0: Committed
22/07/24 17:59:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2439 bytes result sent to driver
22/07/24 17:59:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 32238 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 17:59:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
22/07/24 17:59:01 INFO DAGScheduler: ResultStage 0 (main at NativeMethodAccessorImpl.java:0) finished in 32.569 s
22/07/24 17:59:01 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 17:59:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
22/07/24 17:59:01 INFO DAGScheduler: Job 0 finished: main at NativeMethodAccessorImpl.java:0, took 32.626199 s
22/07/24 17:59:02 INFO FileFormatWriter: Write Job 767520bf-f6bc-4361-accf-a7e67c4cb91a committed.
22/07/24 17:59:02 INFO FileFormatWriter: Finished processing stats for write job 767520bf-f6bc-4361-accf-a7e67c4cb91a.
22/07/24 17:59:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:02 INFO CodeGenerator: Code generated in 43.809114 ms
22/07/24 17:59:02 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 17:59:02 INFO DAGScheduler: Got job 1 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 17:59:02 INFO DAGScheduler: Final stage: ResultStage 1 (main at NativeMethodAccessorImpl.java:0)
22/07/24 17:59:02 INFO DAGScheduler: Parents of final stage: List()
22/07/24 17:59:02 INFO DAGScheduler: Missing parents: List()
22/07/24 17:59:02 INFO DAGScheduler: Submitting ResultStage 1 (CoalescedRDD[15] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 17:59:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 223.0 KiB, free 365.8 MiB)
22/07/24 17:59:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 69.2 KiB, free 365.7 MiB)
22/07/24 17:59:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 69.2 KiB, free: 366.2 MiB)
22/07/24 17:59:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383
22/07/24 17:59:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (CoalescedRDD[15] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 17:59:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
22/07/24 17:59:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 17:59:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
22/07/24 17:59:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:02 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:59:02 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:59:02 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 17:59:02 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 17:59:02 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 17:59:02 INFO ParquetOutputFormat: Dictionary is on
22/07/24 17:59:02 INFO ParquetOutputFormat: Validation is off
22/07/24 17:59:02 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 17:59:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 17:59:02 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 17:59:02 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 17:59:02 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 17:59:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "cr_returned_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_returned_time_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_refunded_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_refunded_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_refunded_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_refunded_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_returning_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_returning_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_returning_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_returning_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_call_center_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_catalog_page_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_ship_mode_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_warehouse_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_reason_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_order_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_return_quantity",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_return_amount",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_return_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_return_amt_inc_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_fee",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_return_ship_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_refunded_cash",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_reversed_charge",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_store_credit",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cr_net_loss",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 cr_returned_date_sk;
  optional int32 cr_returned_time_sk;
  optional int32 cr_item_sk;
  optional int32 cr_refunded_customer_sk;
  optional int32 cr_refunded_cdemo_sk;
  optional int32 cr_refunded_hdemo_sk;
  optional int32 cr_refunded_addr_sk;
  optional int32 cr_returning_customer_sk;
  optional int32 cr_returning_cdemo_sk;
  optional int32 cr_returning_hdemo_sk;
  optional int32 cr_returning_addr_sk;
  optional int32 cr_call_center_sk;
  optional int32 cr_catalog_page_sk;
  optional int32 cr_ship_mode_sk;
  optional int32 cr_warehouse_sk;
  optional int32 cr_reason_sk;
  optional int32 cr_order_number;
  optional int32 cr_return_quantity;
  optional int32 cr_return_amount (DECIMAL(7,2));
  optional int32 cr_return_tax (DECIMAL(7,2));
  optional int32 cr_return_amt_inc_tax (DECIMAL(7,2));
  optional int32 cr_fee (DECIMAL(7,2));
  optional int32 cr_return_ship_cost (DECIMAL(7,2));
  optional int32 cr_refunded_cash (DECIMAL(7,2));
  optional int32 cr_reversed_charge (DECIMAL(7,2));
  optional int32 cr_store_credit (DECIMAL(7,2));
  optional int32 cr_net_loss (DECIMAL(7,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 17:59:02 INFO CodeGenerator: Code generated in 98.803148 ms
22/07/24 17:59:10 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 20485980
22/07/24 17:59:10 INFO FileOutputCommitter: Saved output of task 'attempt_202207241759027642905203811657318_0001_m_000000_1' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_returns/_temporary/0/task_202207241759027642905203811657318_0001_m_000000
22/07/24 17:59:10 INFO SparkHadoopMapRedUtil: attempt_202207241759027642905203811657318_0001_m_000000_1: Committed
22/07/24 17:59:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2396 bytes result sent to driver
22/07/24 17:59:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 8065 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 17:59:10 INFO DAGScheduler: ResultStage 1 (main at NativeMethodAccessorImpl.java:0) finished in 8.142 s
22/07/24 17:59:10 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 17:59:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
22/07/24 17:59:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
22/07/24 17:59:10 INFO DAGScheduler: Job 1 finished: main at NativeMethodAccessorImpl.java:0, took 8.156436 s
22/07/24 17:59:10 INFO FileFormatWriter: Write Job 902f90dd-7b53-406e-8c56-c53e6e547f0d committed.
22/07/24 17:59:10 INFO FileFormatWriter: Finished processing stats for write job 902f90dd-7b53-406e-8c56-c53e6e547f0d.
22/07/24 17:59:10 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:10 INFO CodeGenerator: Code generated in 20.576108 ms
22/07/24 17:59:10 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 17:59:10 INFO DAGScheduler: Got job 2 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 17:59:10 INFO DAGScheduler: Final stage: ResultStage 2 (main at NativeMethodAccessorImpl.java:0)
22/07/24 17:59:10 INFO DAGScheduler: Parents of final stage: List()
22/07/24 17:59:10 INFO DAGScheduler: Missing parents: List()
22/07/24 17:59:10 INFO DAGScheduler: Submitting ResultStage 2 (CoalescedRDD[24] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 17:59:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 186.9 KiB, free 365.5 MiB)
22/07/24 17:59:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 63.7 KiB, free 365.5 MiB)
22/07/24 17:59:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 63.7 KiB, free: 366.1 MiB)
22/07/24 17:59:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1383
22/07/24 17:59:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (CoalescedRDD[24] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 17:59:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
22/07/24 17:59:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 17:59:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
22/07/24 17:59:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:10 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:59:10 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:59:10 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 17:59:10 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 17:59:10 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 17:59:10 INFO ParquetOutputFormat: Dictionary is on
22/07/24 17:59:10 INFO ParquetOutputFormat: Validation is off
22/07/24 17:59:10 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 17:59:10 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 17:59:10 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 17:59:10 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 17:59:10 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 17:59:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "inv_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "inv_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "inv_warehouse_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "inv_quantity_on_hand",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 inv_date_sk;
  optional int32 inv_item_sk;
  optional int32 inv_warehouse_sk;
  optional int32 inv_quantity_on_hand;
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 17:59:10 INFO CodeGenerator: Code generated in 39.121325 ms
22/07/24 17:59:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 69.2 KiB, free: 366.2 MiB)
22/07/24 17:59:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 71.0 KiB, free: 366.2 MiB)
22/07/24 17:59:40 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38555812
22/07/24 17:59:40 INFO FileOutputCommitter: Saved output of task 'attempt_202207241759108872275499926363710_0002_m_000000_2' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/inventory/_temporary/0/task_202207241759108872275499926363710_0002_m_000000
22/07/24 17:59:40 INFO SparkHadoopMapRedUtil: attempt_202207241759108872275499926363710_0002_m_000000_2: Committed
22/07/24 17:59:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2396 bytes result sent to driver
22/07/24 17:59:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29505 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 17:59:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
22/07/24 17:59:40 INFO DAGScheduler: ResultStage 2 (main at NativeMethodAccessorImpl.java:0) finished in 29.562 s
22/07/24 17:59:40 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 17:59:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
22/07/24 17:59:40 INFO DAGScheduler: Job 2 finished: main at NativeMethodAccessorImpl.java:0, took 29.566746 s
22/07/24 17:59:40 INFO FileFormatWriter: Write Job d783dcb1-8282-4461-a1e6-392801e8a69b committed.
22/07/24 17:59:40 INFO FileFormatWriter: Finished processing stats for write job d783dcb1-8282-4461-a1e6-392801e8a69b.
22/07/24 17:59:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:40 INFO CodeGenerator: Code generated in 15.805696 ms
22/07/24 17:59:40 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 17:59:40 INFO DAGScheduler: Got job 3 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 17:59:40 INFO DAGScheduler: Final stage: ResultStage 3 (main at NativeMethodAccessorImpl.java:0)
22/07/24 17:59:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 17:59:40 INFO DAGScheduler: Missing parents: List()
22/07/24 17:59:40 INFO DAGScheduler: Submitting ResultStage 3 (CoalescedRDD[33] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 17:59:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 216.7 KiB, free 365.8 MiB)
22/07/24 17:59:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 68.5 KiB, free 365.8 MiB)
22/07/24 17:59:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 68.5 KiB, free: 366.2 MiB)
22/07/24 17:59:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383
22/07/24 17:59:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (CoalescedRDD[33] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 17:59:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
22/07/24 17:59:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 17:59:40 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
22/07/24 17:59:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 17:59:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 17:59:40 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:59:40 INFO CodecConfig: Compression: SNAPPY
22/07/24 17:59:40 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 17:59:40 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 17:59:40 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 17:59:40 INFO ParquetOutputFormat: Dictionary is on
22/07/24 17:59:40 INFO ParquetOutputFormat: Validation is off
22/07/24 17:59:40 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 17:59:40 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 17:59:40 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 17:59:40 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 17:59:40 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 17:59:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "ss_sold_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_sold_time_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_store_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_promo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_ticket_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_quantity",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_wholesale_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_list_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_sales_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_ext_discount_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_ext_sales_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_ext_wholesale_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_ext_list_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_ext_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_coupon_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_net_paid",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_net_paid_inc_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ss_net_profit",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 ss_sold_date_sk;
  optional int32 ss_sold_time_sk;
  optional int32 ss_item_sk;
  optional int32 ss_customer_sk;
  optional int32 ss_cdemo_sk;
  optional int32 ss_hdemo_sk;
  optional int32 ss_addr_sk;
  optional int32 ss_store_sk;
  optional int32 ss_promo_sk;
  optional int32 ss_ticket_number;
  optional int32 ss_quantity;
  optional int32 ss_wholesale_cost (DECIMAL(7,2));
  optional int32 ss_list_price (DECIMAL(7,2));
  optional int32 ss_sales_price (DECIMAL(7,2));
  optional int32 ss_ext_discount_amt (DECIMAL(7,2));
  optional int32 ss_ext_sales_price (DECIMAL(7,2));
  optional int32 ss_ext_wholesale_cost (DECIMAL(7,2));
  optional int32 ss_ext_list_price (DECIMAL(7,2));
  optional int32 ss_ext_tax (DECIMAL(7,2));
  optional int32 ss_coupon_amt (DECIMAL(7,2));
  optional int32 ss_net_paid (DECIMAL(7,2));
  optional int32 ss_net_paid_inc_tax (DECIMAL(7,2));
  optional int32 ss_net_profit (DECIMAL(7,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 17:59:40 INFO CodeGenerator: Code generated in 90.165856 ms
22/07/24 18:00:04 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 63.7 KiB, free: 366.2 MiB)
22/07/24 18:00:17 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 131748686
22/07/24 18:00:17 INFO FileOutputCommitter: Saved output of task 'attempt_20220724175940943329183762362309_0003_m_000000_3' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_sales/_temporary/0/task_20220724175940943329183762362309_0003_m_000000
22/07/24 18:00:17 INFO SparkHadoopMapRedUtil: attempt_20220724175940943329183762362309_0003_m_000000_3: Committed
22/07/24 18:00:17 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2396 bytes result sent to driver
22/07/24 18:00:17 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 37099 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:17 INFO DAGScheduler: ResultStage 3 (main at NativeMethodAccessorImpl.java:0) finished in 37.270 s
22/07/24 18:00:17 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:17 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
22/07/24 18:00:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
22/07/24 18:00:17 INFO DAGScheduler: Job 3 finished: main at NativeMethodAccessorImpl.java:0, took 37.273599 s
22/07/24 18:00:17 INFO FileFormatWriter: Write Job 88238a80-cfee-4cfd-87d9-6186aad7dafd committed.
22/07/24 18:00:17 INFO FileFormatWriter: Finished processing stats for write job 88238a80-cfee-4cfd-87d9-6186aad7dafd.
22/07/24 18:00:17 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:17 INFO CodeGenerator: Code generated in 6.524011 ms
22/07/24 18:00:17 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:17 INFO DAGScheduler: Got job 4 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:17 INFO DAGScheduler: Final stage: ResultStage 4 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:17 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:17 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:17 INFO DAGScheduler: Submitting ResultStage 4 (CoalescedRDD[42] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 211.9 KiB, free 365.8 MiB)
22/07/24 18:00:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 67.6 KiB, free 365.7 MiB)
22/07/24 18:00:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 67.6 KiB, free: 366.2 MiB)
22/07/24 18:00:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (CoalescedRDD[42] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:17 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
22/07/24 18:00:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:17 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
22/07/24 18:00:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:17 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:17 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:17 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:17 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:17 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:17 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:17 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:17 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:17 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:17 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:17 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:17 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "sr_returned_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_return_time_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_store_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_reason_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_ticket_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_return_quantity",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_return_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_return_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_return_amt_inc_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_fee",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_return_ship_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_refunded_cash",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_reversed_charge",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_store_credit",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sr_net_loss",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 sr_returned_date_sk;
  optional int32 sr_return_time_sk;
  optional int32 sr_item_sk;
  optional int32 sr_customer_sk;
  optional int32 sr_cdemo_sk;
  optional int32 sr_hdemo_sk;
  optional int32 sr_addr_sk;
  optional int32 sr_store_sk;
  optional int32 sr_reason_sk;
  optional int32 sr_ticket_number;
  optional int32 sr_return_quantity;
  optional int32 sr_return_amt (DECIMAL(7,2));
  optional int32 sr_return_tax (DECIMAL(7,2));
  optional int32 sr_return_amt_inc_tax (DECIMAL(7,2));
  optional int32 sr_fee (DECIMAL(7,2));
  optional int32 sr_return_ship_cost (DECIMAL(7,2));
  optional int32 sr_refunded_cash (DECIMAL(7,2));
  optional int32 sr_reversed_charge (DECIMAL(7,2));
  optional int32 sr_store_credit (DECIMAL(7,2));
  optional int32 sr_net_loss (DECIMAL(7,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:17 INFO CodeGenerator: Code generated in 22.483555 ms
22/07/24 18:00:25 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 15742407
22/07/24 18:00:25 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800171808505187639887769_0004_m_000000_4' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_returns/_temporary/0/task_202207241800171808505187639887769_0004_m_000000
22/07/24 18:00:25 INFO SparkHadoopMapRedUtil: attempt_202207241800171808505187639887769_0004_m_000000_4: Committed
22/07/24 18:00:25 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2396 bytes result sent to driver
22/07/24 18:00:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7951 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
22/07/24 18:00:25 INFO DAGScheduler: ResultStage 4 (main at NativeMethodAccessorImpl.java:0) finished in 7.993 s
22/07/24 18:00:25 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
22/07/24 18:00:25 INFO DAGScheduler: Job 4 finished: main at NativeMethodAccessorImpl.java:0, took 7.995172 s
22/07/24 18:00:25 INFO FileFormatWriter: Write Job 5d86366d-8a94-4ec7-8973-b2e52140a057 committed.
22/07/24 18:00:25 INFO FileFormatWriter: Finished processing stats for write job 5d86366d-8a94-4ec7-8973-b2e52140a057.
22/07/24 18:00:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:25 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:25 INFO DAGScheduler: Got job 5 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:25 INFO DAGScheduler: Final stage: ResultStage 5 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:25 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:25 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:25 INFO DAGScheduler: Submitting ResultStage 5 (CoalescedRDD[51] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 234.0 KiB, free 365.5 MiB)
22/07/24 18:00:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 70.9 KiB, free 365.5 MiB)
22/07/24 18:00:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 70.9 KiB, free: 366.1 MiB)
22/07/24 18:00:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (CoalescedRDD[51] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
22/07/24 18:00:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:25 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
22/07/24 18:00:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:25 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:25 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:25 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:25 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:25 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:25 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:25 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:25 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:25 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:25 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:25 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:25 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:25 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "ws_sold_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_sold_time_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ship_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_bill_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_bill_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_bill_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_bill_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ship_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ship_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ship_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ship_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_web_page_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_web_site_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ship_mode_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_warehouse_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_promo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_order_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_quantity",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_wholesale_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_list_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_sales_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ext_discount_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ext_sales_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ext_wholesale_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ext_list_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ext_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_coupon_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_ext_ship_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_net_paid",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_net_paid_inc_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_net_paid_inc_ship",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_net_paid_inc_ship_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ws_net_profit",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 ws_sold_date_sk;
  optional int32 ws_sold_time_sk;
  optional int32 ws_ship_date_sk;
  optional int32 ws_item_sk;
  optional int32 ws_bill_customer_sk;
  optional int32 ws_bill_cdemo_sk;
  optional int32 ws_bill_hdemo_sk;
  optional int32 ws_bill_addr_sk;
  optional int32 ws_ship_customer_sk;
  optional int32 ws_ship_cdemo_sk;
  optional int32 ws_ship_hdemo_sk;
  optional int32 ws_ship_addr_sk;
  optional int32 ws_web_page_sk;
  optional int32 ws_web_site_sk;
  optional int32 ws_ship_mode_sk;
  optional int32 ws_warehouse_sk;
  optional int32 ws_promo_sk;
  optional int32 ws_order_number;
  optional int32 ws_quantity;
  optional int32 ws_wholesale_cost (DECIMAL(7,2));
  optional int32 ws_list_price (DECIMAL(7,2));
  optional int32 ws_sales_price (DECIMAL(7,2));
  optional int32 ws_ext_discount_amt (DECIMAL(7,2));
  optional int32 ws_ext_sales_price (DECIMAL(7,2));
  optional int32 ws_ext_wholesale_cost (DECIMAL(7,2));
  optional int32 ws_ext_list_price (DECIMAL(7,2));
  optional int32 ws_ext_tax (DECIMAL(7,2));
  optional int32 ws_coupon_amt (DECIMAL(7,2));
  optional int32 ws_ext_ship_cost (DECIMAL(7,2));
  optional int32 ws_net_paid (DECIMAL(7,2));
  optional int32 ws_net_paid_inc_tax (DECIMAL(7,2));
  optional int32 ws_net_paid_inc_ship (DECIMAL(7,2));
  optional int32 ws_net_paid_inc_ship_tax (DECIMAL(7,2));
  optional int32 ws_net_profit (DECIMAL(7,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:28 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 67.6 KiB, free: 366.2 MiB)
22/07/24 18:00:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 68.5 KiB, free: 366.2 MiB)
22/07/24 18:00:35 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 61179989
22/07/24 18:00:35 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800252679148624694231441_0005_m_000000_5' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_sales/_temporary/0/task_202207241800252679148624694231441_0005_m_000000
22/07/24 18:00:35 INFO SparkHadoopMapRedUtil: attempt_202207241800252679148624694231441_0005_m_000000_5: Committed
22/07/24 18:00:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2396 bytes result sent to driver
22/07/24 18:00:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10235 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
22/07/24 18:00:35 INFO DAGScheduler: ResultStage 5 (main at NativeMethodAccessorImpl.java:0) finished in 10.272 s
22/07/24 18:00:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
22/07/24 18:00:35 INFO DAGScheduler: Job 5 finished: main at NativeMethodAccessorImpl.java:0, took 10.275040 s
22/07/24 18:00:35 INFO FileFormatWriter: Write Job 9ab4fe16-ff52-4855-8323-08b312e24ba5 committed.
22/07/24 18:00:35 INFO FileFormatWriter: Finished processing stats for write job 9ab4fe16-ff52-4855-8323-08b312e24ba5.
22/07/24 18:00:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:35 INFO CodeGenerator: Code generated in 8.868111 ms
22/07/24 18:00:35 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:35 INFO DAGScheduler: Got job 6 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:35 INFO DAGScheduler: Final stage: ResultStage 6 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:35 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:35 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:35 INFO DAGScheduler: Submitting ResultStage 6 (CoalescedRDD[60] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:35 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 218.3 KiB, free 365.8 MiB)
22/07/24 18:00:35 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 68.6 KiB, free 365.7 MiB)
22/07/24 18:00:35 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 68.6 KiB, free: 366.2 MiB)
22/07/24 18:00:35 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (CoalescedRDD[60] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
22/07/24 18:00:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:35 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
22/07/24 18:00:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:35 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:35 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:35 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:35 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:35 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:35 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:35 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:35 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:35 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:35 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:35 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:35 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "wr_returned_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_returned_time_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_refunded_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_refunded_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_refunded_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_refunded_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_returning_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_returning_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_returning_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_returning_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_web_page_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_reason_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_order_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_return_quantity",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_return_amt",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_return_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_return_amt_inc_tax",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_fee",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_return_ship_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_refunded_cash",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_reversed_charge",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_account_credit",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wr_net_loss",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 wr_returned_date_sk;
  optional int32 wr_returned_time_sk;
  optional int32 wr_item_sk;
  optional int32 wr_refunded_customer_sk;
  optional int32 wr_refunded_cdemo_sk;
  optional int32 wr_refunded_hdemo_sk;
  optional int32 wr_refunded_addr_sk;
  optional int32 wr_returning_customer_sk;
  optional int32 wr_returning_cdemo_sk;
  optional int32 wr_returning_hdemo_sk;
  optional int32 wr_returning_addr_sk;
  optional int32 wr_web_page_sk;
  optional int32 wr_reason_sk;
  optional int32 wr_order_number;
  optional int32 wr_return_quantity;
  optional int32 wr_return_amt (DECIMAL(7,2));
  optional int32 wr_return_tax (DECIMAL(7,2));
  optional int32 wr_return_amt_inc_tax (DECIMAL(7,2));
  optional int32 wr_fee (DECIMAL(7,2));
  optional int32 wr_return_ship_cost (DECIMAL(7,2));
  optional int32 wr_refunded_cash (DECIMAL(7,2));
  optional int32 wr_reversed_charge (DECIMAL(7,2));
  optional int32 wr_account_credit (DECIMAL(7,2));
  optional int32 wr_net_loss (DECIMAL(7,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:36 INFO CodeGenerator: Code generated in 26.237566 ms
22/07/24 18:00:38 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 9854552
22/07/24 18:00:38 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800357067361171626247559_0006_m_000000_6' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_returns/_temporary/0/task_202207241800357067361171626247559_0006_m_000000
22/07/24 18:00:38 INFO SparkHadoopMapRedUtil: attempt_202207241800357067361171626247559_0006_m_000000_6: Committed
22/07/24 18:00:38 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2396 bytes result sent to driver
22/07/24 18:00:38 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 2421 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:38 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
22/07/24 18:00:38 INFO DAGScheduler: ResultStage 6 (main at NativeMethodAccessorImpl.java:0) finished in 2.433 s
22/07/24 18:00:38 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
22/07/24 18:00:38 INFO DAGScheduler: Job 6 finished: main at NativeMethodAccessorImpl.java:0, took 2.435111 s
22/07/24 18:00:38 INFO FileFormatWriter: Write Job daa56b60-3024-4fc0-afae-37182e084bd0 committed.
22/07/24 18:00:38 INFO FileFormatWriter: Finished processing stats for write job daa56b60-3024-4fc0-afae-37182e084bd0.
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO CodeGenerator: Code generated in 8.704537 ms
22/07/24 18:00:38 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:38 INFO DAGScheduler: Got job 7 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:38 INFO DAGScheduler: Final stage: ResultStage 7 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:38 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:38 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:38 INFO DAGScheduler: Submitting ResultStage 7 (CoalescedRDD[69] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 224.7 KiB, free 365.5 MiB)
22/07/24 18:00:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 69.6 KiB, free 365.4 MiB)
22/07/24 18:00:38 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 69.6 KiB, free: 366.1 MiB)
22/07/24 18:00:38 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (CoalescedRDD[69] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
22/07/24 18:00:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:38 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:38 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:38 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:38 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:38 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:38 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:38 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:38 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:38 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:38 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:38 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:38 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "cc_call_center_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_call_center_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_rec_start_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_rec_end_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_closed_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_open_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_class",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_employees",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_sq_ft",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_hours",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_manager",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_mkt_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_mkt_class",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_mkt_desc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_market_manager",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_division",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_division_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_company",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_company_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_street_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_street_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_street_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_suite_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_city",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_county",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_state",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_zip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_gmt_offset",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cc_tax_percentage",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 cc_call_center_sk;
  optional binary cc_call_center_id (UTF8);
  optional int32 cc_rec_start_date (DATE);
  optional int32 cc_rec_end_date (DATE);
  optional int32 cc_closed_date_sk;
  optional int32 cc_open_date_sk;
  optional binary cc_name (UTF8);
  optional binary cc_class (UTF8);
  optional int32 cc_employees;
  optional int32 cc_sq_ft;
  optional binary cc_hours (UTF8);
  optional binary cc_manager (UTF8);
  optional int32 cc_mkt_id;
  optional binary cc_mkt_class (UTF8);
  optional binary cc_mkt_desc (UTF8);
  optional binary cc_market_manager (UTF8);
  optional int32 cc_division;
  optional binary cc_division_name (UTF8);
  optional int32 cc_company;
  optional binary cc_company_name (UTF8);
  optional binary cc_street_number (UTF8);
  optional binary cc_street_name (UTF8);
  optional binary cc_street_type (UTF8);
  optional binary cc_suite_number (UTF8);
  optional binary cc_city (UTF8);
  optional binary cc_county (UTF8);
  optional binary cc_state (UTF8);
  optional binary cc_zip (UTF8);
  optional binary cc_country (UTF8);
  optional int32 cc_gmt_offset (DECIMAL(5,2));
  optional int32 cc_tax_percentage (DECIMAL(5,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:38 INFO CodeGenerator: Code generated in 33.251877 ms
22/07/24 18:00:38 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 2238
22/07/24 18:00:38 INFO FileOutputCommitter: Saved output of task 'attempt_20220724180038488368057500210255_0007_m_000000_7' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/call_center/_temporary/0/task_20220724180038488368057500210255_0007_m_000000
22/07/24 18:00:38 INFO SparkHadoopMapRedUtil: attempt_20220724180038488368057500210255_0007_m_000000_7: Committed
22/07/24 18:00:38 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2396 bytes result sent to driver
22/07/24 18:00:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 150 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
22/07/24 18:00:38 INFO DAGScheduler: ResultStage 7 (main at NativeMethodAccessorImpl.java:0) finished in 0.166 s
22/07/24 18:00:38 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
22/07/24 18:00:38 INFO DAGScheduler: Job 7 finished: main at NativeMethodAccessorImpl.java:0, took 0.168736 s
22/07/24 18:00:38 INFO FileFormatWriter: Write Job f0480a38-25d5-4677-bb58-2a09fb6a38a6 committed.
22/07/24 18:00:38 INFO FileFormatWriter: Finished processing stats for write job f0480a38-25d5-4677-bb58-2a09fb6a38a6.
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO CodeGenerator: Code generated in 6.324831 ms
22/07/24 18:00:38 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:38 INFO DAGScheduler: Got job 8 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:38 INFO DAGScheduler: Final stage: ResultStage 8 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:38 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:38 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:38 INFO DAGScheduler: Submitting ResultStage 8 (CoalescedRDD[78] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 193.5 KiB, free 365.2 MiB)
22/07/24 18:00:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 64.8 KiB, free 365.2 MiB)
22/07/24 18:00:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 64.8 KiB, free: 366.0 MiB)
22/07/24 18:00:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (CoalescedRDD[78] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
22/07/24 18:00:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:38 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:38 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:38 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:38 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:38 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:38 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:38 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:38 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:38 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:38 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:38 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:38 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "cp_catalog_page_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_catalog_page_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_start_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_end_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_department",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_catalog_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_catalog_page_number",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_description",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cp_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 cp_catalog_page_sk;
  optional binary cp_catalog_page_id (UTF8);
  optional int32 cp_start_date_sk;
  optional int32 cp_end_date_sk;
  optional binary cp_department (UTF8);
  optional int32 cp_catalog_number;
  optional int32 cp_catalog_page_number;
  optional binary cp_description (UTF8);
  optional binary cp_type (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:38 INFO CodeGenerator: Code generated in 8.398973 ms
22/07/24 18:00:39 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1617237
22/07/24 18:00:39 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800387778926330573726053_0008_m_000000_8' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_page/_temporary/0/task_202207241800387778926330573726053_0008_m_000000
22/07/24 18:00:39 INFO SparkHadoopMapRedUtil: attempt_202207241800387778926330573726053_0008_m_000000_8: Committed
22/07/24 18:00:39 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2353 bytes result sent to driver
22/07/24 18:00:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 182 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:39 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
22/07/24 18:00:39 INFO DAGScheduler: ResultStage 8 (main at NativeMethodAccessorImpl.java:0) finished in 0.200 s
22/07/24 18:00:39 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
22/07/24 18:00:39 INFO DAGScheduler: Job 8 finished: main at NativeMethodAccessorImpl.java:0, took 0.202601 s
22/07/24 18:00:39 INFO FileFormatWriter: Write Job 2d27e602-a10a-4ec4-9f41-67ba8568174c committed.
22/07/24 18:00:39 INFO FileFormatWriter: Finished processing stats for write job 2d27e602-a10a-4ec4-9f41-67ba8568174c.
22/07/24 18:00:39 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:39 INFO CodeGenerator: Code generated in 5.338964 ms
22/07/24 18:00:39 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:39 INFO DAGScheduler: Got job 9 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:39 INFO DAGScheduler: Final stage: ResultStage 9 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:39 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:39 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:39 INFO DAGScheduler: Submitting ResultStage 9 (CoalescedRDD[87] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 207.7 KiB, free 365.0 MiB)
22/07/24 18:00:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 66.5 KiB, free 364.9 MiB)
22/07/24 18:00:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 66.5 KiB, free: 366.0 MiB)
22/07/24 18:00:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (CoalescedRDD[87] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:39 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
22/07/24 18:00:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:39 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
22/07/24 18:00:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:39 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:39 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:39 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:39 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:39 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:39 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:39 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:39 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:39 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:39 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:39 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:39 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "c_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_current_cdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_current_hdemo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_current_addr_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_first_shipto_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_first_sales_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_salutation",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_first_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_last_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_preferred_cust_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_birth_day",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_birth_month",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_birth_year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_birth_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_login",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_email_address",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "c_last_review_date",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 c_customer_sk;
  optional binary c_customer_id (UTF8);
  optional int32 c_current_cdemo_sk;
  optional int32 c_current_hdemo_sk;
  optional int32 c_current_addr_sk;
  optional int32 c_first_shipto_date_sk;
  optional int32 c_first_sales_date_sk;
  optional binary c_salutation (UTF8);
  optional binary c_first_name (UTF8);
  optional binary c_last_name (UTF8);
  optional binary c_preferred_cust_flag (UTF8);
  optional int32 c_birth_day;
  optional int32 c_birth_month;
  optional int32 c_birth_year;
  optional binary c_birth_country (UTF8);
  optional binary c_login (UTF8);
  optional binary c_email_address (UTF8);
  optional int32 c_last_review_date;
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:39 INFO CodeGenerator: Code generated in 19.68024 ms
22/07/24 18:00:39 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 70.9 KiB, free: 366.0 MiB)
22/07/24 18:00:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 64.8 KiB, free: 366.1 MiB)
22/07/24 18:00:39 INFO BlockManagerInfo: Removed broadcast_7_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 69.6 KiB, free: 366.2 MiB)
22/07/24 18:00:39 INFO BlockManagerInfo: Removed broadcast_6_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 68.6 KiB, free: 366.2 MiB)
22/07/24 18:00:40 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 10864080
22/07/24 18:00:40 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800398272046535761249146_0009_m_000000_9' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer/_temporary/0/task_202207241800398272046535761249146_0009_m_000000
22/07/24 18:00:40 INFO SparkHadoopMapRedUtil: attempt_202207241800398272046535761249146_0009_m_000000_9: Committed
22/07/24 18:00:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2396 bytes result sent to driver
22/07/24 18:00:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 1319 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
22/07/24 18:00:40 INFO DAGScheduler: ResultStage 9 (main at NativeMethodAccessorImpl.java:0) finished in 1.329 s
22/07/24 18:00:40 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
22/07/24 18:00:40 INFO DAGScheduler: Job 9 finished: main at NativeMethodAccessorImpl.java:0, took 1.331005 s
22/07/24 18:00:40 INFO FileFormatWriter: Write Job 18cf03e4-a068-40ae-9d60-f260b4ea91e0 committed.
22/07/24 18:00:40 INFO FileFormatWriter: Finished processing stats for write job 18cf03e4-a068-40ae-9d60-f260b4ea91e0.
22/07/24 18:00:40 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:40 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:40 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:40 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO CodeGenerator: Code generated in 7.008129 ms
22/07/24 18:00:40 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:40 INFO DAGScheduler: Got job 10 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:40 INFO DAGScheduler: Final stage: ResultStage 10 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:40 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:40 INFO DAGScheduler: Submitting ResultStage 10 (CoalescedRDD[96] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 198.9 KiB, free 365.8 MiB)
22/07/24 18:00:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 65.7 KiB, free 365.8 MiB)
22/07/24 18:00:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 65.7 KiB, free: 366.2 MiB)
22/07/24 18:00:40 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (CoalescedRDD[96] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:40 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
22/07/24 18:00:40 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:40 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
22/07/24 18:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:40 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:40 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:40 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:40 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:40 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:40 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:40 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:40 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:40 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:40 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:40 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "ca_address_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_address_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_street_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_street_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_street_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_suite_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_city",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_county",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_state",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_zip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_gmt_offset",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ca_location_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 ca_address_sk;
  optional binary ca_address_id (UTF8);
  optional binary ca_street_number (UTF8);
  optional binary ca_street_name (UTF8);
  optional binary ca_street_type (UTF8);
  optional binary ca_suite_number (UTF8);
  optional binary ca_city (UTF8);
  optional binary ca_county (UTF8);
  optional binary ca_state (UTF8);
  optional binary ca_zip (UTF8);
  optional binary ca_country (UTF8);
  optional int32 ca_gmt_offset (DECIMAL(5,2));
  optional binary ca_location_type (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:40 INFO CodeGenerator: Code generated in 13.43815 ms
22/07/24 18:00:40 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 3874344
22/07/24 18:00:40 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800406851782104763993370_0010_m_000000_10' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer_address/_temporary/0/task_202207241800406851782104763993370_0010_m_000000
22/07/24 18:00:40 INFO SparkHadoopMapRedUtil: attempt_202207241800406851782104763993370_0010_m_000000_10: Committed
22/07/24 18:00:40 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2396 bytes result sent to driver
22/07/24 18:00:40 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 439 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:40 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
22/07/24 18:00:40 INFO DAGScheduler: ResultStage 10 (main at NativeMethodAccessorImpl.java:0) finished in 0.451 s
22/07/24 18:00:40 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
22/07/24 18:00:40 INFO DAGScheduler: Job 10 finished: main at NativeMethodAccessorImpl.java:0, took 0.452668 s
22/07/24 18:00:40 INFO FileFormatWriter: Write Job 8323b3ff-6df8-4a5f-a100-e958b79cfc5a committed.
22/07/24 18:00:40 INFO FileFormatWriter: Finished processing stats for write job 8323b3ff-6df8-4a5f-a100-e958b79cfc5a.
22/07/24 18:00:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:40 INFO CodeGenerator: Code generated in 3.769867 ms
22/07/24 18:00:41 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:41 INFO DAGScheduler: Got job 11 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:41 INFO DAGScheduler: Final stage: ResultStage 11 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:41 INFO DAGScheduler: Submitting ResultStage 11 (CoalescedRDD[105] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 194.4 KiB, free 365.6 MiB)
22/07/24 18:00:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 65.2 KiB, free 365.5 MiB)
22/07/24 18:00:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 65.2 KiB, free: 366.1 MiB)
22/07/24 18:00:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (CoalescedRDD[105] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
22/07/24 18:00:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
22/07/24 18:00:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:41 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:41 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:41 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:41 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:41 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:41 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:41 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:41 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:41 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:41 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:41 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:41 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "cd_demo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_gender",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_marital_status",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_education_status",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_purchase_estimate",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_credit_rating",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_dep_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_dep_employed_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "cd_dep_college_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 cd_demo_sk;
  optional binary cd_gender (UTF8);
  optional binary cd_marital_status (UTF8);
  optional binary cd_education_status (UTF8);
  optional int32 cd_purchase_estimate;
  optional binary cd_credit_rating (UTF8);
  optional int32 cd_dep_count;
  optional int32 cd_dep_employed_count;
  optional int32 cd_dep_college_count;
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:44 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 9928540
22/07/24 18:00:44 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800412671082796981297116_0011_m_000000_11' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer_demographics/_temporary/0/task_202207241800412671082796981297116_0011_m_000000
22/07/24 18:00:44 INFO SparkHadoopMapRedUtil: attempt_202207241800412671082796981297116_0011_m_000000_11: Committed
22/07/24 18:00:44 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2396 bytes result sent to driver
22/07/24 18:00:44 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 3565 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:44 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
22/07/24 18:00:44 INFO DAGScheduler: ResultStage 11 (main at NativeMethodAccessorImpl.java:0) finished in 3.581 s
22/07/24 18:00:44 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
22/07/24 18:00:44 INFO DAGScheduler: Job 11 finished: main at NativeMethodAccessorImpl.java:0, took 3.584535 s
22/07/24 18:00:44 INFO FileFormatWriter: Write Job 377824c1-402b-4633-89ba-2b8d1ecab4d4 committed.
22/07/24 18:00:44 INFO FileFormatWriter: Finished processing stats for write job 377824c1-402b-4633-89ba-2b8d1ecab4d4.
22/07/24 18:00:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:44 INFO CodeGenerator: Code generated in 15.925983 ms
22/07/24 18:00:44 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:44 INFO DAGScheduler: Got job 12 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:44 INFO DAGScheduler: Final stage: ResultStage 12 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:44 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:44 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:44 INFO DAGScheduler: Submitting ResultStage 12 (CoalescedRDD[114] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:44 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 223.0 KiB, free 365.3 MiB)
22/07/24 18:00:44 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 69.1 KiB, free 365.2 MiB)
22/07/24 18:00:44 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 69.1 KiB, free: 366.0 MiB)
22/07/24 18:00:44 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (CoalescedRDD[114] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:44 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
22/07/24 18:00:44 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:44 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
22/07/24 18:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:44 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:44 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:44 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:44 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:44 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:44 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:44 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:44 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:44 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:44 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:44 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:44 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "d_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_date_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_month_seq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_week_seq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_quarter_seq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_dow",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_moy",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_dom",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_qoy",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_fy_year",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_fy_quarter_seq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_fy_week_seq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_day_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_quarter_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_holiday",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_weekend",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_following_holiday",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_first_dom",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_last_dom",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_same_day_ly",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_same_day_lq",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_current_day",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_current_week",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_current_month",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_current_quarter",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "d_current_year",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 d_date_sk;
  optional binary d_date_id (UTF8);
  optional int32 d_date (DATE);
  optional int32 d_month_seq;
  optional int32 d_week_seq;
  optional int32 d_quarter_seq;
  optional int32 d_year;
  optional int32 d_dow;
  optional int32 d_moy;
  optional int32 d_dom;
  optional int32 d_qoy;
  optional int32 d_fy_year;
  optional int32 d_fy_quarter_seq;
  optional int32 d_fy_week_seq;
  optional binary d_day_name (UTF8);
  optional binary d_quarter_name (UTF8);
  optional binary d_holiday (UTF8);
  optional binary d_weekend (UTF8);
  optional binary d_following_holiday (UTF8);
  optional int32 d_first_dom;
  optional int32 d_last_dom;
  optional int32 d_same_day_ly;
  optional int32 d_same_day_lq;
  optional binary d_current_day (UTF8);
  optional binary d_current_week (UTF8);
  optional binary d_current_month (UTF8);
  optional binary d_current_quarter (UTF8);
  optional binary d_current_year (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:44 INFO CodeGenerator: Code generated in 26.936185 ms
22/07/24 18:00:45 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 9955302
22/07/24 18:00:45 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800441870431334512756462_0012_m_000000_12' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/date_dim/_temporary/0/task_202207241800441870431334512756462_0012_m_000000
22/07/24 18:00:45 INFO SparkHadoopMapRedUtil: attempt_202207241800441870431334512756462_0012_m_000000_12: Committed
22/07/24 18:00:45 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2396 bytes result sent to driver
22/07/24 18:00:45 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 687 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:45 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
22/07/24 18:00:45 INFO DAGScheduler: ResultStage 12 (main at NativeMethodAccessorImpl.java:0) finished in 0.699 s
22/07/24 18:00:45 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
22/07/24 18:00:45 INFO DAGScheduler: Job 12 finished: main at NativeMethodAccessorImpl.java:0, took 0.700941 s
22/07/24 18:00:45 INFO FileFormatWriter: Write Job 456e2631-3dcd-417d-b221-0f61f2222522 committed.
22/07/24 18:00:45 INFO FileFormatWriter: Finished processing stats for write job 456e2631-3dcd-417d-b221-0f61f2222522.
22/07/24 18:00:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO CodeGenerator: Code generated in 3.557333 ms
22/07/24 18:00:45 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:45 INFO DAGScheduler: Got job 13 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:45 INFO DAGScheduler: Final stage: ResultStage 13 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:45 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:45 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:45 INFO DAGScheduler: Submitting ResultStage 13 (CoalescedRDD[123] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:45 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 188.4 KiB, free 365.1 MiB)
22/07/24 18:00:45 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 365.0 MiB)
22/07/24 18:00:45 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 64.2 KiB, free: 366.0 MiB)
22/07/24 18:00:45 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (CoalescedRDD[123] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:45 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
22/07/24 18:00:45 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:45 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:45 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:45 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:45 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:45 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:45 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:45 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:45 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:45 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "hd_demo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hd_income_band_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hd_buy_potential",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hd_dep_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hd_vehicle_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 hd_demo_sk;
  optional int32 hd_income_band_sk;
  optional binary hd_buy_potential (UTF8);
  optional int32 hd_dep_count;
  optional int32 hd_vehicle_count;
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:45 INFO CodeGenerator: Code generated in 7.73717 ms
22/07/24 18:00:45 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 173058
22/07/24 18:00:45 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800453183132444581140386_0013_m_000000_13' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/household_demographics/_temporary/0/task_202207241800453183132444581140386_0013_m_000000
22/07/24 18:00:45 INFO SparkHadoopMapRedUtil: attempt_202207241800453183132444581140386_0013_m_000000_13: Committed
22/07/24 18:00:45 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2396 bytes result sent to driver
22/07/24 18:00:45 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 60 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:45 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
22/07/24 18:00:45 INFO DAGScheduler: ResultStage 13 (main at NativeMethodAccessorImpl.java:0) finished in 0.069 s
22/07/24 18:00:45 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
22/07/24 18:00:45 INFO DAGScheduler: Job 13 finished: main at NativeMethodAccessorImpl.java:0, took 0.070531 s
22/07/24 18:00:45 INFO FileFormatWriter: Write Job eb451e61-f455-4ca4-8610-df45d772aa00 committed.
22/07/24 18:00:45 INFO FileFormatWriter: Finished processing stats for write job eb451e61-f455-4ca4-8610-df45d772aa00.
22/07/24 18:00:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO CodeGenerator: Code generated in 4.336484 ms
22/07/24 18:00:45 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:45 INFO DAGScheduler: Got job 14 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:45 INFO DAGScheduler: Final stage: ResultStage 14 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:45 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:45 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:45 INFO DAGScheduler: Submitting ResultStage 14 (CoalescedRDD[132] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:45 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 185.4 KiB, free 364.8 MiB)
22/07/24 18:00:45 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 63.7 KiB, free 364.7 MiB)
22/07/24 18:00:45 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 63.7 KiB, free: 365.9 MiB)
22/07/24 18:00:45 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (CoalescedRDD[132] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:45 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
22/07/24 18:00:45 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:45 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:45 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:45 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:45 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:45 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:45 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:45 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:45 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:45 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "ib_income_band_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ib_lower_bound",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "ib_upper_bound",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 ib_income_band_sk;
  optional int32 ib_lower_bound;
  optional int32 ib_upper_bound;
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:45 INFO CodeGenerator: Code generated in 5.70195 ms
22/07/24 18:00:45 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 480
22/07/24 18:00:45 INFO FileOutputCommitter: Saved output of task 'attempt_20220724180045944057737525549963_0014_m_000000_14' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/income_band/_temporary/0/task_20220724180045944057737525549963_0014_m_000000
22/07/24 18:00:45 INFO SparkHadoopMapRedUtil: attempt_20220724180045944057737525549963_0014_m_000000_14: Committed
22/07/24 18:00:45 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2353 bytes result sent to driver
22/07/24 18:00:45 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 27 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:45 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
22/07/24 18:00:45 INFO DAGScheduler: ResultStage 14 (main at NativeMethodAccessorImpl.java:0) finished in 0.045 s
22/07/24 18:00:45 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
22/07/24 18:00:45 INFO DAGScheduler: Job 14 finished: main at NativeMethodAccessorImpl.java:0, took 0.047022 s
22/07/24 18:00:45 INFO FileFormatWriter: Write Job 9f72d28b-2fb0-48f7-887a-eb113e385f84 committed.
22/07/24 18:00:45 INFO FileFormatWriter: Finished processing stats for write job 9f72d28b-2fb0-48f7-887a-eb113e385f84.
22/07/24 18:00:45 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO CodeGenerator: Code generated in 8.879367 ms
22/07/24 18:00:45 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:45 INFO DAGScheduler: Got job 15 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:45 INFO DAGScheduler: Final stage: ResultStage 15 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:45 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:45 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:45 INFO DAGScheduler: Submitting ResultStage 15 (CoalescedRDD[141] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:45 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 213.6 KiB, free 364.5 MiB)
22/07/24 18:00:45 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 68.0 KiB, free 364.5 MiB)
22/07/24 18:00:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 68.0 KiB, free: 365.8 MiB)
22/07/24 18:00:45 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (CoalescedRDD[141] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:45 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
22/07/24 18:00:45 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:45 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:45 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:45 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:45 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:45 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:45 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:45 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:45 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:45 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:45 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:45 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "i_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_item_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_rec_start_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_rec_end_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_item_desc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_current_price",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_wholesale_cost",
    "type" : "decimal(7,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_brand_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_brand",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_class_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_class",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_category_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_manufact_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_manufact",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_size",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_formulation",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_color",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_units",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_container",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_manager_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "i_product_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 i_item_sk;
  optional binary i_item_id (UTF8);
  optional int32 i_rec_start_date (DATE);
  optional int32 i_rec_end_date (DATE);
  optional binary i_item_desc (UTF8);
  optional int32 i_current_price (DECIMAL(7,2));
  optional int32 i_wholesale_cost (DECIMAL(7,2));
  optional int32 i_brand_id;
  optional binary i_brand (UTF8);
  optional int32 i_class_id;
  optional binary i_class (UTF8);
  optional int32 i_category_id;
  optional binary i_category (UTF8);
  optional int32 i_manufact_id;
  optional binary i_manufact (UTF8);
  optional binary i_size (UTF8);
  optional binary i_formulation (UTF8);
  optional binary i_color (UTF8);
  optional binary i_units (UTF8);
  optional binary i_container (UTF8);
  optional int32 i_manager_id;
  optional binary i_product_name (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:45 INFO CodeGenerator: Code generated in 19.245417 ms
22/07/24 18:00:45 INFO BlockManagerInfo: Removed broadcast_14_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 63.7 KiB, free: 365.9 MiB)
22/07/24 18:00:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 4063302
22/07/24 18:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800454361530920469818471_0015_m_000000_15' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/item/_temporary/0/task_202207241800454361530920469818471_0015_m_000000
22/07/24 18:00:46 INFO SparkHadoopMapRedUtil: attempt_202207241800454361530920469818471_0015_m_000000_15: Committed
22/07/24 18:00:46 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2396 bytes result sent to driver
22/07/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 352 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
22/07/24 18:00:46 INFO DAGScheduler: ResultStage 15 (main at NativeMethodAccessorImpl.java:0) finished in 0.368 s
22/07/24 18:00:46 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
22/07/24 18:00:46 INFO DAGScheduler: Job 15 finished: main at NativeMethodAccessorImpl.java:0, took 0.369585 s
22/07/24 18:00:46 INFO FileFormatWriter: Write Job efd1d55d-9bab-43aa-a991-6c4409de47f5 committed.
22/07/24 18:00:46 INFO FileFormatWriter: Finished processing stats for write job efd1d55d-9bab-43aa-a991-6c4409de47f5.
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 4.490562 ms
22/07/24 18:00:46 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:46 INFO DAGScheduler: Got job 16 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:46 INFO DAGScheduler: Final stage: ResultStage 16 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:46 INFO DAGScheduler: Submitting ResultStage 16 (CoalescedRDD[150] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 208.8 KiB, free 364.5 MiB)
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 66.6 KiB, free 364.4 MiB)
22/07/24 18:00:46 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 66.6 KiB, free: 365.8 MiB)
22/07/24 18:00:46 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (CoalescedRDD[150] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:46 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
22/07/24 18:00:46 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:46 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:46 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:46 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:46 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:46 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:46 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:46 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "p_promo_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_promo_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_start_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_end_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_item_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_cost",
    "type" : "decimal(15,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_response_target",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_promo_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_dmail",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_email",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_catalog",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_tv",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_radio",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_press",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_event",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_demo",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_channel_details",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_purpose",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "p_discount_active",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 p_promo_sk;
  optional binary p_promo_id (UTF8);
  optional int32 p_start_date_sk;
  optional int32 p_end_date_sk;
  optional int32 p_item_sk;
  optional int64 p_cost (DECIMAL(15,2));
  optional int32 p_response_target;
  optional binary p_promo_name (UTF8);
  optional binary p_channel_dmail (UTF8);
  optional binary p_channel_email (UTF8);
  optional binary p_channel_catalog (UTF8);
  optional binary p_channel_tv (UTF8);
  optional binary p_channel_radio (UTF8);
  optional binary p_channel_press (UTF8);
  optional binary p_channel_event (UTF8);
  optional binary p_channel_demo (UTF8);
  optional binary p_channel_details (UTF8);
  optional binary p_purpose (UTF8);
  optional binary p_discount_active (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 12.571169 ms
22/07/24 18:00:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 47702
22/07/24 18:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800462137277590681184487_0016_m_000000_16' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/promotion/_temporary/0/task_202207241800462137277590681184487_0016_m_000000
22/07/24 18:00:46 INFO SparkHadoopMapRedUtil: attempt_202207241800462137277590681184487_0016_m_000000_16: Committed
22/07/24 18:00:46 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2353 bytes result sent to driver
22/07/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 54 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
22/07/24 18:00:46 INFO DAGScheduler: ResultStage 16 (main at NativeMethodAccessorImpl.java:0) finished in 0.064 s
22/07/24 18:00:46 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
22/07/24 18:00:46 INFO DAGScheduler: Job 16 finished: main at NativeMethodAccessorImpl.java:0, took 0.065836 s
22/07/24 18:00:46 INFO FileFormatWriter: Write Job ed6b6a28-7685-40e9-b0aa-12e8abe3b97d committed.
22/07/24 18:00:46 INFO FileFormatWriter: Finished processing stats for write job ed6b6a28-7685-40e9-b0aa-12e8abe3b97d.
22/07/24 18:00:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 3.438837 ms
22/07/24 18:00:46 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:46 INFO DAGScheduler: Got job 17 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:46 INFO DAGScheduler: Final stage: ResultStage 17 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:46 INFO DAGScheduler: Submitting ResultStage 17 (CoalescedRDD[159] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 185.2 KiB, free 364.3 MiB)
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 63.7 KiB, free 364.2 MiB)
22/07/24 18:00:46 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 63.7 KiB, free: 365.8 MiB)
22/07/24 18:00:46 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (CoalescedRDD[159] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:46 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
22/07/24 18:00:46 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:46 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:46 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:46 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:46 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:46 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:46 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:46 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "r_reason_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "r_reason_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "r_reason_desc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 r_reason_sk;
  optional binary r_reason_id (UTF8);
  optional binary r_reason_desc (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 4796
22/07/24 18:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800464001596724418442683_0017_m_000000_17' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/reason/_temporary/0/task_202207241800464001596724418442683_0017_m_000000
22/07/24 18:00:46 INFO SparkHadoopMapRedUtil: attempt_202207241800464001596724418442683_0017_m_000000_17: Committed
22/07/24 18:00:46 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2353 bytes result sent to driver
22/07/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 21 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
22/07/24 18:00:46 INFO DAGScheduler: ResultStage 17 (main at NativeMethodAccessorImpl.java:0) finished in 0.031 s
22/07/24 18:00:46 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
22/07/24 18:00:46 INFO DAGScheduler: Job 17 finished: main at NativeMethodAccessorImpl.java:0, took 0.031942 s
22/07/24 18:00:46 INFO FileFormatWriter: Write Job ce199d71-0b06-4f39-8e24-6a1bb59a7f48 committed.
22/07/24 18:00:46 INFO FileFormatWriter: Finished processing stats for write job ce199d71-0b06-4f39-8e24-6a1bb59a7f48.
22/07/24 18:00:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 3.164616 ms
22/07/24 18:00:46 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:46 INFO DAGScheduler: Got job 18 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:46 INFO DAGScheduler: Final stage: ResultStage 18 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:46 INFO DAGScheduler: Submitting ResultStage 18 (CoalescedRDD[168] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 189.6 KiB, free 364.0 MiB)
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 64.0 KiB, free 364.0 MiB)
22/07/24 18:00:46 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 64.0 KiB, free: 365.7 MiB)
22/07/24 18:00:46 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (CoalescedRDD[168] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:46 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
22/07/24 18:00:46 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:46 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:46 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:46 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:46 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:46 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:46 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:46 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "sm_ship_mode_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sm_ship_mode_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sm_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sm_code",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sm_carrier",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sm_contract",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 sm_ship_mode_sk;
  optional binary sm_ship_mode_id (UTF8);
  optional binary sm_type (UTF8);
  optional binary sm_code (UTF8);
  optional binary sm_carrier (UTF8);
  optional binary sm_contract (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 7.644916 ms
22/07/24 18:00:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 2180
22/07/24 18:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800462157304366773448997_0018_m_000000_18' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/ship_mode/_temporary/0/task_202207241800462157304366773448997_0018_m_000000
22/07/24 18:00:46 INFO SparkHadoopMapRedUtil: attempt_202207241800462157304366773448997_0018_m_000000_18: Committed
22/07/24 18:00:46 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2353 bytes result sent to driver
22/07/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 38 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
22/07/24 18:00:46 INFO DAGScheduler: ResultStage 18 (main at NativeMethodAccessorImpl.java:0) finished in 0.048 s
22/07/24 18:00:46 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
22/07/24 18:00:46 INFO DAGScheduler: Job 18 finished: main at NativeMethodAccessorImpl.java:0, took 0.048986 s
22/07/24 18:00:46 INFO FileFormatWriter: Write Job f8e9ca34-7d70-4122-a022-f802a1ef18e3 committed.
22/07/24 18:00:46 INFO FileFormatWriter: Finished processing stats for write job f8e9ca34-7d70-4122-a022-f802a1ef18e3.
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 7.143967 ms
22/07/24 18:00:46 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:46 INFO DAGScheduler: Got job 19 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:46 INFO DAGScheduler: Final stage: ResultStage 19 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:46 INFO DAGScheduler: Submitting ResultStage 19 (CoalescedRDD[177] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 221.1 KiB, free 363.7 MiB)
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 68.9 KiB, free 363.7 MiB)
22/07/24 18:00:46 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 68.9 KiB, free: 365.7 MiB)
22/07/24 18:00:46 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (CoalescedRDD[177] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:46 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
22/07/24 18:00:46 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:46 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:46 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:46 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:46 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:46 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:46 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:46 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "s_store_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_store_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_rec_start_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_rec_end_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_closed_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_store_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_number_employees",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_floor_space",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_hours",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_manager",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_market_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_geography_class",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_market_desc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_market_manager",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_division_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_division_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_company_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_company_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_street_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_street_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_street_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_suite_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_city",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_county",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_state",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_zip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_gmt_offset",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "s_tax_percentage",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 s_store_sk;
  optional binary s_store_id (UTF8);
  optional int32 s_rec_start_date (DATE);
  optional int32 s_rec_end_date (DATE);
  optional int32 s_closed_date_sk;
  optional binary s_store_name (UTF8);
  optional int32 s_number_employees;
  optional int32 s_floor_space;
  optional binary s_hours (UTF8);
  optional binary s_manager (UTF8);
  optional int32 s_market_id;
  optional binary s_geography_class (UTF8);
  optional binary s_market_desc (UTF8);
  optional binary s_market_manager (UTF8);
  optional int32 s_division_id;
  optional binary s_division_name (UTF8);
  optional int32 s_company_id;
  optional binary s_company_name (UTF8);
  optional binary s_street_number (UTF8);
  optional binary s_street_name (UTF8);
  optional binary s_street_type (UTF8);
  optional binary s_suite_number (UTF8);
  optional binary s_city (UTF8);
  optional binary s_county (UTF8);
  optional binary s_state (UTF8);
  optional binary s_zip (UTF8);
  optional binary s_country (UTF8);
  optional int32 s_gmt_offset (DECIMAL(5,2));
  optional int32 s_tax_percentage (DECIMAL(5,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:46 INFO BlockManagerInfo: Removed broadcast_18_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 64.0 KiB, free: 365.7 MiB)
22/07/24 18:00:46 INFO BlockManagerInfo: Removed broadcast_16_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 66.6 KiB, free: 365.8 MiB)
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 41.152526 ms
22/07/24 18:00:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 3322
22/07/24 18:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800461562761738798817029_0019_m_000000_19' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store/_temporary/0/task_202207241800461562761738798817029_0019_m_000000
22/07/24 18:00:46 INFO SparkHadoopMapRedUtil: attempt_202207241800461562761738798817029_0019_m_000000_19: Committed
22/07/24 18:00:46 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2396 bytes result sent to driver
22/07/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 91 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
22/07/24 18:00:46 INFO DAGScheduler: ResultStage 19 (main at NativeMethodAccessorImpl.java:0) finished in 0.103 s
22/07/24 18:00:46 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
22/07/24 18:00:46 INFO DAGScheduler: Job 19 finished: main at NativeMethodAccessorImpl.java:0, took 0.103462 s
22/07/24 18:00:46 INFO FileFormatWriter: Write Job 2424a24c-2673-4919-8dca-2df03c6b1f30 committed.
22/07/24 18:00:46 INFO FileFormatWriter: Finished processing stats for write job 2424a24c-2673-4919-8dca-2df03c6b1f30.
22/07/24 18:00:46 INFO BlockManagerInfo: Removed broadcast_17_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 63.7 KiB, free: 365.8 MiB)
22/07/24 18:00:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 4.478858 ms
22/07/24 18:00:46 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:46 INFO DAGScheduler: Got job 20 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:46 INFO DAGScheduler: Final stage: ResultStage 20 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:46 INFO DAGScheduler: Submitting ResultStage 20 (CoalescedRDD[186] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 195.6 KiB, free 364.2 MiB)
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 65.3 KiB, free 364.2 MiB)
22/07/24 18:00:46 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 65.3 KiB, free: 365.8 MiB)
22/07/24 18:00:46 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (CoalescedRDD[186] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:46 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
22/07/24 18:00:46 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:46 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:46 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:46 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:46 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:46 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:46 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:46 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "t_time_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_time_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_time",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_minute",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_second",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_am_pm",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_shift",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_sub_shift",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "t_meal_time",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 t_time_sk;
  optional binary t_time_id (UTF8);
  optional int32 t_time;
  optional int32 t_hour;
  optional int32 t_minute;
  optional int32 t_second;
  optional binary t_am_pm (UTF8);
  optional binary t_shift (UTF8);
  optional binary t_sub_shift (UTF8);
  optional binary t_meal_time (UTF8);
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 10.65388 ms
22/07/24 18:00:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 4231531
22/07/24 18:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800461810316188748916631_0020_m_000000_20' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/time_dim/_temporary/0/task_202207241800461810316188748916631_0020_m_000000
22/07/24 18:00:46 INFO SparkHadoopMapRedUtil: attempt_202207241800461810316188748916631_0020_m_000000_20: Committed
22/07/24 18:00:46 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2396 bytes result sent to driver
22/07/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 349 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
22/07/24 18:00:46 INFO DAGScheduler: ResultStage 20 (main at NativeMethodAccessorImpl.java:0) finished in 0.361 s
22/07/24 18:00:46 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
22/07/24 18:00:46 INFO DAGScheduler: Job 20 finished: main at NativeMethodAccessorImpl.java:0, took 0.362619 s
22/07/24 18:00:46 INFO FileFormatWriter: Write Job 8f70b23a-8297-4914-afd9-ef55c2b566c5 committed.
22/07/24 18:00:46 INFO FileFormatWriter: Finished processing stats for write job 8f70b23a-8297-4914-afd9-ef55c2b566c5.
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 4.045462 ms
22/07/24 18:00:46 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:46 INFO DAGScheduler: Got job 21 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:46 INFO DAGScheduler: Final stage: ResultStage 21 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:46 INFO DAGScheduler: Submitting ResultStage 21 (CoalescedRDD[195] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 200.1 KiB, free 364.0 MiB)
22/07/24 18:00:46 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 65.8 KiB, free 363.9 MiB)
22/07/24 18:00:46 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 65.8 KiB, free: 365.7 MiB)
22/07/24 18:00:46 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (CoalescedRDD[195] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:46 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
22/07/24 18:00:46 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:46 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:46 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:46 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:46 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:46 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:46 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:46 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:46 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "w_warehouse_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_warehouse_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_warehouse_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_warehouse_sq_ft",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_street_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_street_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_street_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_suite_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_city",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_county",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_state",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_zip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "w_gmt_offset",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 w_warehouse_sk;
  optional binary w_warehouse_id (UTF8);
  optional binary w_warehouse_name (UTF8);
  optional int32 w_warehouse_sq_ft;
  optional binary w_street_number (UTF8);
  optional binary w_street_name (UTF8);
  optional binary w_street_type (UTF8);
  optional binary w_suite_number (UTF8);
  optional binary w_city (UTF8);
  optional binary w_county (UTF8);
  optional binary w_state (UTF8);
  optional binary w_zip (UTF8);
  optional binary w_country (UTF8);
  optional int32 w_gmt_offset (DECIMAL(5,2));
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:46 INFO CodeGenerator: Code generated in 8.92967 ms
22/07/24 18:00:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 786
22/07/24 18:00:46 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800466803750019079828915_0021_m_000000_21' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/warehouse/_temporary/0/task_202207241800466803750019079828915_0021_m_000000
22/07/24 18:00:46 INFO SparkHadoopMapRedUtil: attempt_202207241800466803750019079828915_0021_m_000000_21: Committed
22/07/24 18:00:46 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 2353 bytes result sent to driver
22/07/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 39 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
22/07/24 18:00:46 INFO DAGScheduler: ResultStage 21 (main at NativeMethodAccessorImpl.java:0) finished in 0.049 s
22/07/24 18:00:46 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
22/07/24 18:00:46 INFO DAGScheduler: Job 21 finished: main at NativeMethodAccessorImpl.java:0, took 0.049382 s
22/07/24 18:00:46 INFO FileFormatWriter: Write Job fb12b780-7915-4b80-8a26-7afface0131d committed.
22/07/24 18:00:46 INFO FileFormatWriter: Finished processing stats for write job fb12b780-7915-4b80-8a26-7afface0131d.
22/07/24 18:00:46 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO CodeGenerator: Code generated in 5.627971 ms
22/07/24 18:00:47 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:47 INFO DAGScheduler: Got job 22 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:47 INFO DAGScheduler: Final stage: ResultStage 22 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:47 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:47 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:47 INFO DAGScheduler: Submitting ResultStage 22 (CoalescedRDD[204] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:47 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 201.9 KiB, free 363.7 MiB)
22/07/24 18:00:47 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 66.3 KiB, free 363.7 MiB)
22/07/24 18:00:47 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 66.3 KiB, free: 365.7 MiB)
22/07/24 18:00:47 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (CoalescedRDD[204] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:47 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
22/07/24 18:00:47 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:47 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:47 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:47 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:47 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:47 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:47 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:47 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:47 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:47 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:47 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:47 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "wp_web_page_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_web_page_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_rec_start_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_rec_end_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_creation_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_access_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_autogen_flag",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_customer_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_url",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_char_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_link_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_image_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "wp_max_ad_count",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 wp_web_page_sk;
  optional binary wp_web_page_id (UTF8);
  optional int32 wp_rec_start_date (DATE);
  optional int32 wp_rec_end_date (DATE);
  optional int32 wp_creation_date_sk;
  optional int32 wp_access_date_sk;
  optional binary wp_autogen_flag (UTF8);
  optional int32 wp_customer_sk;
  optional binary wp_url (UTF8);
  optional binary wp_type (UTF8);
  optional int32 wp_char_count;
  optional int32 wp_link_count;
  optional int32 wp_image_count;
  optional int32 wp_max_ad_count;
}

       
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:47 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 5414
22/07/24 18:00:47 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800477664791526683556725_0022_m_000000_22' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_page/_temporary/0/task_202207241800477664791526683556725_0022_m_000000
22/07/24 18:00:47 INFO SparkHadoopMapRedUtil: attempt_202207241800477664791526683556725_0022_m_000000_22: Committed
22/07/24 18:00:47 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 2353 bytes result sent to driver
22/07/24 18:00:47 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 23 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:47 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
22/07/24 18:00:47 INFO DAGScheduler: ResultStage 22 (main at NativeMethodAccessorImpl.java:0) finished in 0.034 s
22/07/24 18:00:47 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
22/07/24 18:00:47 INFO DAGScheduler: Job 22 finished: main at NativeMethodAccessorImpl.java:0, took 0.034707 s
22/07/24 18:00:47 INFO FileFormatWriter: Write Job ee6733f8-5455-4e13-a2c0-4e4bc8269d45 committed.
22/07/24 18:00:47 INFO FileFormatWriter: Finished processing stats for write job ee6733f8-5455-4e13-a2c0-4e4bc8269d45.
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 WARN CharVarcharUtils: The Spark cast operator does not support char/varchar type and simply treats them as string type. Please use string type directly to avoid confusion. Otherwise, you can set spark.sql.legacy.charVarcharAsString to true, so that Spark treat them as string type as same as Spark 3.0 and earlier
22/07/24 18:00:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO CodeGenerator: Code generated in 7.055186 ms
22/07/24 18:00:47 INFO BlockManagerInfo: Removed broadcast_21_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 65.8 KiB, free: 365.7 MiB)
22/07/24 18:00:47 INFO SparkContext: Starting job: main at NativeMethodAccessorImpl.java:0
22/07/24 18:00:47 INFO DAGScheduler: Got job 23 (main at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/07/24 18:00:47 INFO DAGScheduler: Final stage: ResultStage 23 (main at NativeMethodAccessorImpl.java:0)
22/07/24 18:00:47 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:00:47 INFO DAGScheduler: Missing parents: List()
22/07/24 18:00:47 INFO DAGScheduler: Submitting ResultStage 23 (CoalescedRDD[213] at main at NativeMethodAccessorImpl.java:0), which has no missing parents
22/07/24 18:00:47 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 217.2 KiB, free 363.7 MiB)
22/07/24 18:00:47 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 68.3 KiB, free 363.6 MiB)
22/07/24 18:00:47 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:38047 (size: 68.3 KiB, free: 365.6 MiB)
22/07/24 18:00:47 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1383
22/07/24 18:00:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (CoalescedRDD[213] at main at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/07/24 18:00:47 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
22/07/24 18:00:47 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4834 bytes) taskResourceAssignments Map()
22/07/24 18:00:47 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/24 18:00:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/07/24 18:00:47 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:47 INFO CodecConfig: Compression: SNAPPY
22/07/24 18:00:47 INFO ParquetOutputFormat: Parquet block size to 134217728
22/07/24 18:00:47 INFO ParquetOutputFormat: Parquet page size to 1048576
22/07/24 18:00:47 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/07/24 18:00:47 INFO ParquetOutputFormat: Dictionary is on
22/07/24 18:00:47 INFO ParquetOutputFormat: Validation is off
22/07/24 18:00:47 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/07/24 18:00:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/07/24 18:00:47 INFO ParquetOutputFormat: Page size checking is: estimated
22/07/24 18:00:47 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/07/24 18:00:47 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/07/24 18:00:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "web_site_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_rec_start_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_rec_end_date",
    "type" : "date",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_open_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_close_date_sk",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_class",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_manager",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_mkt_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_mkt_class",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_mkt_desc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_market_manager",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_company_id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_company_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_street_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_street_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_street_type",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_suite_number",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_city",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_county",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_state",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_zip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_country",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_gmt_offset",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "web_tax_percentage",
    "type" : "decimal(5,2)",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 web_site_sk;
  optional binary web_site_id (UTF8);
  optional int32 web_rec_start_date (DATE);
  optional int32 web_rec_end_date (DATE);
  optional binary web_name (UTF8);
  optional int32 web_open_date_sk;
  optional int32 web_close_date_sk;
  optional binary web_class (UTF8);
  optional binary web_manager (UTF8);
  optional int32 web_mkt_id;
  optional binary web_mkt_class (UTF8);
  optional binary web_mkt_desc (UTF8);
  optional binary web_market_manager (UTF8);
  optional int32 web_company_id;
  optional binary web_company_name (UTF8);
  optional binary web_street_number (UTF8);
  optional binary web_street_name (UTF8);
  optional binary web_street_type (UTF8);
  optional binary web_suite_number (UTF8);
  optional binary web_city (UTF8);
  optional binary web_county (UTF8);
  optional binary web_state (UTF8);
  optional binary web_zip (UTF8);
  optional binary web_country (UTF8);
  optional int32 web_gmt_offset (DECIMAL(5,2));
  optional int32 web_tax_percentage (DECIMAL(5,2));
}

       
22/07/24 18:00:47 INFO BlockManagerInfo: Removed broadcast_22_piece0 on ubuntu-Virtual-Machine.mshome.net:38047 in memory (size: 66.3 KiB, free: 365.7 MiB)
DBGEN2 Population Generator (Version 1.0.0h (pre-release))
Copyright Transaction Processing Performance Council (TPC) 2001 - 2008
Warning: This scale factor is valid for QUALIFICATION ONLY
22/07/24 18:00:47 INFO CodeGenerator: Code generated in 14.241948 ms
22/07/24 18:00:47 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8386
22/07/24 18:00:47 INFO FileOutputCommitter: Saved output of task 'attempt_202207241800473752427891236578435_0023_m_000000_23' to file:/home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_site/_temporary/0/task_202207241800473752427891236578435_0023_m_000000
22/07/24 18:00:47 INFO SparkHadoopMapRedUtil: attempt_202207241800473752427891236578435_0023_m_000000_23: Committed
22/07/24 18:00:47 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2353 bytes result sent to driver
22/07/24 18:00:47 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 65 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:00:47 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
22/07/24 18:00:47 INFO DAGScheduler: ResultStage 23 (main at NativeMethodAccessorImpl.java:0) finished in 0.079 s
22/07/24 18:00:47 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:00:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
22/07/24 18:00:47 INFO DAGScheduler: Job 23 finished: main at NativeMethodAccessorImpl.java:0, took 0.080125 s
22/07/24 18:00:47 INFO FileFormatWriter: Write Job b33f7b8b-9100-4d8b-a89d-d1a7d7b44733 committed.
22/07/24 18:00:47 INFO FileFormatWriter: Finished processing stats for write job b33f7b8b-9100-4d8b-a89d-d1a7d7b44733.
22/07/24 18:00:47 INFO SparkUI: Stopped Spark web UI at http://ubuntu-Virtual-Machine.mshome.net:4040
22/07/24 18:00:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
22/07/24 18:00:47 INFO MemoryStore: MemoryStore cleared
22/07/24 18:00:47 INFO BlockManager: BlockManager stopped
22/07/24 18:00:47 INFO BlockManagerMaster: BlockManagerMaster stopped
22/07/24 18:00:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
22/07/24 18:00:47 INFO SparkContext: Successfully stopped SparkContext
22/07/24 18:00:47 INFO ShutdownHookManager: Shutdown hook called
22/07/24 18:00:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe9b1ba4-3ef1-4061-ad6d-b15f9243ba66
22/07/24 18:00:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-f7358032-96fd-4933-9317-4811dbd3c8c8
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ echo $?
0
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ wget https://repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/3.1.1/spark-catalyst_2.12-3.1.1-tests.jar
--2022-07-24 18:05:36--  https://repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/3.1.1/spark-catalyst_2.12-3.1.1-tests.jar
Resolving repo1.maven.org (repo1.maven.org)... 199.232.196.209, 199.232.192.209
Connecting to repo1.maven.org (repo1.maven.org)|199.232.196.209|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4642097 (4.4M) [application/java-archive]
Saving to: ‘spark-catalyst_2.12-3.1.1-tests.jar’

spark-catalyst_2.12-3.1.1-t 100%[==========================================>]   4.43M  3.52MB/s    in 1.3s    

2022-07-24 18:05:39 (3.52 MB/s) - ‘spark-catalyst_2.12-3.1.1-tests.jar’ saved [4642097/4642097]

ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ wget https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/3.1.1/spark-core_2.12-3.1.1-tests.jar
--2022-07-24 18:06:50--  https://repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/3.1.1/spark-core_2.12-3.1.1-tests.jar
Resolving repo1.maven.org (repo1.maven.org)... 199.232.196.209, 199.232.192.209
Connecting to repo1.maven.org (repo1.maven.org)|199.232.196.209|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4860916 (4.6M) [application/java-archive]
Saving to: ‘spark-core_2.12-3.1.1-tests.jar’

spark-core_2.12-3.1.1-tests 100%[==========================================>]   4.63M  3.93MB/s    in 1.2s    

2022-07-24 18:06:52 (3.93 MB/s) - ‘spark-core_2.12-3.1.1-tests.jar’ saved [4860916/4860916]

ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ wget https://repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/3.1.1/spark-sql_2.12-3.1.1-tests.jar
--2022-07-24 18:07:39--  https://repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/3.1.1/spark-sql_2.12-3.1.1-tests.jar
Resolving repo1.maven.org (repo1.maven.org)... 199.232.196.209, 199.232.192.209
Connecting to repo1.maven.org (repo1.maven.org)|199.232.196.209|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 15921702 (15M) [application/java-archive]
Saving to: ‘spark-sql_2.12-3.1.1-tests.jar’

spark-sql_2.12-3.1.1-tests. 100%[==========================================>]  15.18M  8.74MB/s    in 1.7s    

2022-07-24 18:07:42 (8.74 MB/s) - ‘spark-sql_2.12-3.1.1-tests.jar’ saved [15921702/15921702]

ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ 


ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ ./spark-3.1.1-bin-hadoop2.7/bin/spark-submit --class org.apache.spark.sql.execution.benchmark.TPCDSQueryBenchmark --jars spark-core_2.12-3.1.1-tests.jar,spark-catalyst_2.12-3.1.1-tests.jar spark-sql_2.12-3.1.1-tests.jar --data-location tpcds-data-1g --query-filter "q38"
22/07/24 18:25:36 WARN Utils: Your hostname, ubuntu-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 172.28.45.111 instead (on interface eth0)
22/07/24 18:25:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
22/07/24 18:25:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/07/24 18:25:36 INFO SparkContext: Running Spark version 3.1.1
22/07/24 18:25:36 INFO ResourceUtils: ==============================================================
22/07/24 18:25:36 INFO ResourceUtils: No custom resources configured for spark.driver.
22/07/24 18:25:36 INFO ResourceUtils: ==============================================================
22/07/24 18:25:36 INFO SparkContext: Submitted application: test-sql-context
22/07/24 18:25:36 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/07/24 18:25:36 INFO ResourceProfile: Limiting resource is cpu
22/07/24 18:25:36 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/07/24 18:25:36 INFO SecurityManager: Changing view acls to: ubuntu
22/07/24 18:25:36 INFO SecurityManager: Changing modify acls to: ubuntu
22/07/24 18:25:36 INFO SecurityManager: Changing view acls groups to: 
22/07/24 18:25:36 INFO SecurityManager: Changing modify acls groups to: 
22/07/24 18:25:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()
22/07/24 18:25:37 INFO Utils: Successfully started service 'sparkDriver' on port 46621.
22/07/24 18:25:37 INFO SparkEnv: Registering MapOutputTracker
22/07/24 18:25:37 INFO SparkEnv: Registering BlockManagerMaster
22/07/24 18:25:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/07/24 18:25:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/07/24 18:25:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/07/24 18:25:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-517e4f93-0132-4a91-98ed-325b72453273
22/07/24 18:25:37 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/07/24 18:25:37 INFO SparkEnv: Registering OutputCommitCoordinator
22/07/24 18:25:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/07/24 18:25:37 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ubuntu-Virtual-Machine.mshome.net:4040
22/07/24 18:25:37 INFO SparkContext: Added JAR file:///home/ubuntu/git/spark-tpcds-datagen/spark-core_2.12-3.1.1-tests.jar at spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-core_2.12-3.1.1-tests.jar with timestamp 1658658336820
22/07/24 18:25:37 INFO SparkContext: Added JAR file:///home/ubuntu/git/spark-tpcds-datagen/spark-catalyst_2.12-3.1.1-tests.jar at spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-catalyst_2.12-3.1.1-tests.jar with timestamp 1658658336820
22/07/24 18:25:37 INFO SparkContext: Added JAR file:/home/ubuntu/git/spark-tpcds-datagen/spark-sql_2.12-3.1.1-tests.jar at spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-sql_2.12-3.1.1-tests.jar with timestamp 1658658336820
22/07/24 18:25:37 INFO Executor: Starting executor ID driver on host ubuntu-Virtual-Machine.mshome.net
22/07/24 18:25:37 INFO Executor: Fetching spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-catalyst_2.12-3.1.1-tests.jar with timestamp 1658658336820
22/07/24 18:25:37 INFO TransportClientFactory: Successfully created connection to ubuntu-Virtual-Machine.mshome.net/172.28.45.111:46621 after 22 ms (0 ms spent in bootstraps)
22/07/24 18:25:37 INFO Utils: Fetching spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-catalyst_2.12-3.1.1-tests.jar to /tmp/spark-418ce721-0a2c-4ce0-86c6-2a6cca94e1ce/userFiles-07bcc3a1-131d-4289-8635-8e0b7e969cb0/fetchFileTemp8585516426456111031.tmp
22/07/24 18:25:37 INFO Executor: Adding file:/tmp/spark-418ce721-0a2c-4ce0-86c6-2a6cca94e1ce/userFiles-07bcc3a1-131d-4289-8635-8e0b7e969cb0/spark-catalyst_2.12-3.1.1-tests.jar to class loader
22/07/24 18:25:37 INFO Executor: Fetching spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-sql_2.12-3.1.1-tests.jar with timestamp 1658658336820
22/07/24 18:25:37 INFO Utils: Fetching spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-sql_2.12-3.1.1-tests.jar to /tmp/spark-418ce721-0a2c-4ce0-86c6-2a6cca94e1ce/userFiles-07bcc3a1-131d-4289-8635-8e0b7e969cb0/fetchFileTemp6049307870036278209.tmp
22/07/24 18:25:37 INFO Executor: Adding file:/tmp/spark-418ce721-0a2c-4ce0-86c6-2a6cca94e1ce/userFiles-07bcc3a1-131d-4289-8635-8e0b7e969cb0/spark-sql_2.12-3.1.1-tests.jar to class loader
22/07/24 18:25:37 INFO Executor: Fetching spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-core_2.12-3.1.1-tests.jar with timestamp 1658658336820
22/07/24 18:25:37 INFO Utils: Fetching spark://ubuntu-Virtual-Machine.mshome.net:46621/jars/spark-core_2.12-3.1.1-tests.jar to /tmp/spark-418ce721-0a2c-4ce0-86c6-2a6cca94e1ce/userFiles-07bcc3a1-131d-4289-8635-8e0b7e969cb0/fetchFileTemp5146253938797816458.tmp
22/07/24 18:25:37 INFO Executor: Adding file:/tmp/spark-418ce721-0a2c-4ce0-86c6-2a6cca94e1ce/userFiles-07bcc3a1-131d-4289-8635-8e0b7e969cb0/spark-core_2.12-3.1.1-tests.jar to class loader
22/07/24 18:25:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35817.
22/07/24 18:25:37 INFO NettyBlockTransferService: Server created on ubuntu-Virtual-Machine.mshome.net:35817
22/07/24 18:25:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/07/24 18:25:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 35817, None)
22/07/24 18:25:37 INFO BlockManagerMasterEndpoint: Registering block manager ubuntu-Virtual-Machine.mshome.net:35817 with 366.3 MiB RAM, BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 35817, None)
22/07/24 18:25:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 35817, None)
22/07/24 18:25:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ubuntu-Virtual-Machine.mshome.net, 35817, None)
22/07/24 18:25:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/ubuntu/git/spark-tpcds-datagen/spark-warehouse').
22/07/24 18:25:37 INFO SharedState: Warehouse path is 'file:/home/ubuntu/git/spark-tpcds-datagen/spark-warehouse'.
22/07/24 18:25:38 INFO InMemoryFileIndex: It took 15 ms to list leaf files for 1 paths.
22/07/24 18:25:38 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:38 INFO DAGScheduler: Got job 0 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:38 INFO DAGScheduler: Final stage: ResultStage 0 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:38 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:38 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 74.4 KiB, free 366.2 MiB)
22/07/24 18:25:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 366.2 MiB)
22/07/24 18:25:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.3 MiB)
22/07/24 18:25:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
22/07/24 18:25:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4712 bytes) taskResourceAssignments Map()
22/07/24 18:25:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
22/07/24 18:25:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2129 bytes result sent to driver
22/07/24 18:25:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 264 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
22/07/24 18:25:38 INFO DAGScheduler: ResultStage 0 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.349 s
22/07/24 18:25:38 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
22/07/24 18:25:38 INFO DAGScheduler: Job 0 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.389834 s
22/07/24 18:25:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.3 MiB)
22/07/24 18:25:39 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:39 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:39 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:39 INFO CodeGenerator: Code generated in 100.284938 ms
22/07/24 18:25:39 INFO CodeGenerator: Code generated in 11.911476 ms
22/07/24 18:25:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 292.4 KiB, free 366.0 MiB)
22/07/24 18:25:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 366.0 MiB)
22/07/24 18:25:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.3 MiB)
22/07/24 18:25:39 INFO SparkContext: Created broadcast 1 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4889417 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Registering RDD 5 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 0
22/07/24 18:25:40 INFO DAGScheduler: Got job 1 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 2 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
22/07/24 18:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.7 KiB, free 366.0 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 366.0 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.3 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
22/07/24 18:25:40 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_page/part-00000-db3a32da-2631-4bec-8673-109c450e9e47-c000.snappy.parquet, range: 0-695113, partition values: [empty row]
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2157 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 97 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ShuffleMapStage 1 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.115 s
22/07/24 18:25:40 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:40 INFO DAGScheduler: running: Set()
22/07/24 18:25:40 INFO DAGScheduler: waiting: Set(ResultStage 2)
22/07/24 18:25:40 INFO DAGScheduler: failed: Set()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[8] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.1 KiB, free 366.0 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 366.0 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.3 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 2 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.039 s
22/07/24 18:25:40 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 1 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.171208 s
22/07/24 18:25:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Got job 2 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 3 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[10] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 74.4 KiB, free 365.9 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.9 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[10] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4715 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 3565 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 3 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.026 s
22/07/24 18:25:40 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 2 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.030234 s
22/07/24 18:25:40 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
22/07/24 18:25:40 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 292.4 KiB, free 365.6 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 5 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14574465 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Registering RDD 14 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 1
22/07/24 18:25:40 INFO DAGScheduler: Got job 3 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 5 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
22/07/24 18:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.7 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4955 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
22/07/24 18:25:40 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_returns/part-00000-1b337d33-5eee-4221-9e4c-837c1cce47d7-c000.snappy.parquet, range: 0-10380161, partition values: [empty row]
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2157 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 17 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ShuffleMapStage 4 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.023 s
22/07/24 18:25:40 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:40 INFO DAGScheduler: running: Set()
22/07/24 18:25:40 INFO DAGScheduler: waiting: Set(ResultStage 5)
22/07/24 18:25:40 INFO DAGScheduler: failed: Set()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[17] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 10.1 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 5 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.013 s
22/07/24 18:25:40 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 3 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.046986 s
22/07/24 18:25:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Got job 4 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 6 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 74.4 KiB, free 365.4 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.4 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4708 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2498 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 32 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 6 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.040 s
22/07/24 18:25:40 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 4 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.042197 s
22/07/24 18:25:40 INFO BlockManagerInfo: Removed broadcast_7_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 292.4 KiB, free 365.1 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.1 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 9 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9766600 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Registering RDD 23 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 2
22/07/24 18:25:40 INFO DAGScheduler: Got job 5 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 8 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
22/07/24 18:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 14.7 KiB, free 365.2 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.2 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
22/07/24 18:25:40 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer/part-00000-3fb5fb40-6c98-4939-86be-88f3d65875d2-c000.snappy.parquet, range: 0-5572296, partition values: [empty row]
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2157 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 16 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ShuffleMapStage 7 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.034 s
22/07/24 18:25:40 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:40 INFO DAGScheduler: running: Set()
22/07/24 18:25:40 INFO DAGScheduler: waiting: Set(ResultStage 8)
22/07/24 18:25:40 INFO DAGScheduler: failed: Set()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO BlockManagerInfo: Removed broadcast_6_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2605 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 8 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:40 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 5 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.050596 s
22/07/24 18:25:40 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Got job 6 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 9 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[28] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 74.4 KiB, free 365.8 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.8 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[28] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4716 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2594 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 9 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.014 s
22/07/24 18:25:40 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 6 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.015976 s
22/07/24 18:25:40 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 292.4 KiB, free 365.5 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.4 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 13 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5254093 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Registering RDD 32 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 3
22/07/24 18:25:40 INFO DAGScheduler: Got job 7 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 11 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
22/07/24 18:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[32] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 14.7 KiB, free 365.4 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.4 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[32] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4956 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
22/07/24 18:25:40 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer_address/part-00000-66bd7199-e138-4180-8890-6ddeb94c76f2-c000.snappy.parquet, range: 0-1059789, partition values: [empty row]
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2157 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ShuffleMapStage 10 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.012 s
22/07/24 18:25:40 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:40 INFO DAGScheduler: running: Set()
22/07/24 18:25:40 INFO DAGScheduler: waiting: Set(ResultStage 11)
22/07/24 18:25:40 INFO DAGScheduler: failed: Set()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[35] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 10.1 KiB, free 365.4 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.4 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[35] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2648 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 11 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.008 s
22/07/24 18:25:40 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 7 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.023254 s
22/07/24 18:25:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Got job 8 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 12 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[37] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 74.4 KiB, free 365.3 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.3 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[37] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4721 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2048 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 12 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.016 s
22/07/24 18:25:40 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 8 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.017200 s
22/07/24 18:25:40 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 292.4 KiB, free 365.0 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.0 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 17 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 11959856 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Registering RDD 41 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 4
22/07/24 18:25:40 INFO DAGScheduler: Got job 9 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 14 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
22/07/24 18:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[41] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 14.7 KiB, free 365.0 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.0 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[41] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
22/07/24 18:25:40 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer_demographics/part-00000-dc3f337f-54b6-4be6-b7aa-b2dcba3de2a0-c000.snappy.parquet, range: 0-7765552, partition values: [empty row]
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2157 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ShuffleMapStage 13 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.014 s
22/07/24 18:25:40 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:40 INFO DAGScheduler: running: Set()
22/07/24 18:25:40 INFO DAGScheduler: waiting: Set(ResultStage 14)
22/07/24 18:25:40 INFO DAGScheduler: failed: Set()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[44] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 10.1 KiB, free 365.0 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.0 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[44] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2605 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 14 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.006 s
22/07/24 18:25:40 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 9 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.022505 s
22/07/24 18:25:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Got job 10 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 15 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[46] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.4 KiB, free 364.9 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.9 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[46] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4708 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2849 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 15 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 15 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.024 s
22/07/24 18:25:40 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 10 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.025638 s
22/07/24 18:25:40 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 292.4 KiB, free 364.6 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.6 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 21 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6037354 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Registering RDD 50 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 5
22/07/24 18:25:40 INFO DAGScheduler: Got job 11 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 17 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
22/07/24 18:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[50] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 14.7 KiB, free 364.5 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.5 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[50] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
22/07/24 18:25:40 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/date_dim/part-00000-75a59129-a25a-4d72-836c-ce88969352f2-c000.snappy.parquet, range: 0-1843050, partition values: [empty row]
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2157 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 13 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ShuffleMapStage 16 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.017 s
22/07/24 18:25:40 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:40 INFO DAGScheduler: running: Set()
22/07/24 18:25:40 INFO DAGScheduler: waiting: Set(ResultStage 17)
22/07/24 18:25:40 INFO DAGScheduler: failed: Set()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[53] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 10.1 KiB, free 364.5 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.5 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[53] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2648 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 17 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:40 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 11 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.030165 s
22/07/24 18:25:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Got job 12 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 18 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:40 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[55] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 74.4 KiB, free 364.4 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.4 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[55] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:40 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
22/07/24 18:25:40 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4722 bytes) taskResourceAssignments Map()
22/07/24 18:25:40 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
22/07/24 18:25:40 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1851 bytes result sent to driver
22/07/24 18:25:40 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:40 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
22/07/24 18:25:40 INFO DAGScheduler: ResultStage 18 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.014 s
22/07/24 18:25:40 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
22/07/24 18:25:40 INFO DAGScheduler: Job 12 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.017197 s
22/07/24 18:25:40 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:40 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 292.4 KiB, free 364.1 MiB)
22/07/24 18:25:40 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.1 MiB)
22/07/24 18:25:40 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:40 INFO SparkContext: Created broadcast 25 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4225251 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:40 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:40 INFO DAGScheduler: Registering RDD 59 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 6
22/07/24 18:25:40 INFO DAGScheduler: Got job 13 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:40 INFO DAGScheduler: Final stage: ResultStage 20 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
22/07/24 18:25:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
22/07/24 18:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[59] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 14.7 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[59] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4962 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/household_demographics/part-00000-71065d7f-2464-4454-8cb1-518a4cfdaad6-c000.snappy.parquet, range: 0-30947, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 19 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 20)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[62] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 10.1 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[62] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2562 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 20 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.007 s
22/07/24 18:25:41 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 13 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.018751 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 14 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 21 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[64] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 74.4 KiB, free 364.0 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[64] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4709 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_18_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1755 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 16 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 21 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.032 s
22/07/24 18:25:41 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 14 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.033689 s
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_17_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 292.4 KiB, free 364.0 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 29 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 39975269 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 68 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 7
22/07/24 18:25:41 INFO DAGScheduler: Got job 15 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 23 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[68] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 14.7 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[68] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_16_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/inventory/part-00000-fe3a3dd5-d8ee-4255-9aeb-cf88cf89c3b0-c000.snappy.parquet, range: 0-35780965, partition values: [empty row]
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_22_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 14 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 22 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.019 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 23)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[71] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.1 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[71] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_24_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2648 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_26_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 23 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.009 s
22/07/24 18:25:41 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 15 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.031541 s
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_9_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_15_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 16 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 24 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[73] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 74.4 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.4 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[73] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4704 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_25_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 3038 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 17 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 24 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.023 s
22/07/24 18:25:41 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 16 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.024792 s
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_19_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 292.4 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.4 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 33 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5969446 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_14_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 77 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 8
22/07/24 18:25:41 INFO DAGScheduler: Got job 17 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 26 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[77] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 14.7 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_23_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[77] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4944 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/item/part-00000-319fe6b3-44b2-4352-9195-786611bc849b-c000.snappy.parquet, range: 0-1775142, partition values: [empty row]
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_27_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 25 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.017 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 26)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[80] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 10.1 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[80] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2562 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 26 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.005 s
22/07/24 18:25:41 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 17 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.024544 s
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_20_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_21_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 18 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 27 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[82] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_13_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 74.4 KiB, free 365.3 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.3 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[82] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4709 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 2881 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 27 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.012 s
22/07/24 18:25:41 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 18 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.014276 s
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 292.4 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 37 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4215907 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 86 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 9
22/07/24 18:25:41 INFO DAGScheduler: Got job 19 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 29 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[86] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 14.7 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[86] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/promotion/part-00000-a3ad0cbd-b891-46fb-b608-6dcac392fca2-c000.snappy.parquet, range: 0-21603, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 13 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 28 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.016 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 29)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[89] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 10.1 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[89] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 2562 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 29 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.006 s
22/07/24 18:25:41 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 19 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.025316 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 20 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 30 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[91] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 74.4 KiB, free 364.9 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.9 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[91] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4705 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 3372 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 12 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 30 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.017 s
22/07/24 18:25:41 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 20 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.018343 s
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 292.4 KiB, free 364.6 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.6 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 41 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4203787 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 95 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 10
22/07/24 18:25:41 INFO DAGScheduler: Got job 21 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 32 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[95] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 14.7 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[95] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4945 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store/part-00000-b05e03cf-2b25-4482-a13d-c047eafcebaf-c000.snappy.parquet, range: 0-9483, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 31 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.008 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 32)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[98] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 10.1 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.5 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[98] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 2605 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 32 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.008 s
22/07/24 18:25:41 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 21 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.017971 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 22 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 33 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[100] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 74.4 KiB, free 364.4 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.4 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[100] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4713 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 3125 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 33 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:41 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 22 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.011439 s
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 292.4 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 45 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 18857844 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 104 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 11
22/07/24 18:25:41 INFO DAGScheduler: Got job 23 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 35 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[104] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 14.7 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[104] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_returns/part-00000-9de3acf1-7be1-48f0-90ed-5acd6e61c436-c000.snappy.parquet, range: 0-14663540, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 34 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.008 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 35)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[107] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 10.1 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[107] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 2562 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 35 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.005 s
22/07/24 18:25:41 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 23 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.017384 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 24 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 36 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_32_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[109] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 74.4 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[109] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4713 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_46_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 3988 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 36 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.015 s
22/07/24 18:25:41 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 24 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.018132 s
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_31_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_41_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_42_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 292.4 KiB, free 364.2 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 49 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 100763528 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_36_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 113 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 12
22/07/24 18:25:41 INFO DAGScheduler: Got job 25 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 38 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[113] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 14.7 KiB, free 364.6 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_33_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.6 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[113] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_43_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_sales/part-00000-e44b35cf-e4e1-4304-95ca-e106b3d97ef0-c000.snappy.parquet, range: 0-96569224, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_38_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 13 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 37 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.023 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 38)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[116] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 10.1 KiB, free 364.9 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.9 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[116] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 2562 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 38 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.005 s
22/07/24 18:25:41 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_44_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO DAGScheduler: Job 25 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.031250 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_47_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_40_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_30_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_29_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_28_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 26 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 39 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[118] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 74.4 KiB, free 365.5 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.4 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[118] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4709 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 39.0 (TID 39)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 3981 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 10 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 39 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.018 s
22/07/24 18:25:41 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 26 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.019245 s
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 292.4 KiB, free 365.2 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 53 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48694286 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 122 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 13
22/07/24 18:25:41 INFO DAGScheduler: Got job 27 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 41 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[122] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 14.7 KiB, free 365.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[122] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 40.0 (TID 40)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_sales/part-00000-c79381f5-f0b0-439a-aaca-89acfda21c12-c000.snappy.parquet, range: 0-44499982, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 40.0 (TID 40). 2114 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 40 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.012 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 41)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[125] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 10.1 KiB, free 365.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[125] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 41.0 (TID 41)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 41.0 (TID 41). 2605 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 41 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.007 s
22/07/24 18:25:41 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 27 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.024941 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 28 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 42 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[127] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 74.4 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.0 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[127] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4711 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 42.0 (TID 42)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 42.0 (TID 42). 3344 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 42 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.011 s
22/07/24 18:25:41 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 28 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.011324 s
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 292.4 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 57 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 124086532 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 131 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 14
22/07/24 18:25:41 INFO DAGScheduler: Got job 29 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 44 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[131] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 14.7 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[131] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 43) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 43.0 (TID 43)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_sales/part-00000-aadc4cd6-fb63-4cb6-85be-f942835071d3-c000.snappy.parquet, range: 0-119892228, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 43.0 (TID 43). 2114 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 43) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 43 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.009 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 44)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[134] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 10.1 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.7 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[134] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 44.0 (TID 44)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 44.0 (TID 44). 2562 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 44 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.005 s
22/07/24 18:25:41 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 29 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.015220 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 30 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 45 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[136] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 74.4 KiB, free 364.6 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.6 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[136] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4711 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 3377 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 45 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.011 s
22/07/24 18:25:41 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 30 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.012296 s
22/07/24 18:25:41 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:41 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 292.4 KiB, free 364.3 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 61 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9462479 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Registering RDD 140 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 15
22/07/24 18:25:41 INFO DAGScheduler: Got job 31 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 47 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
22/07/24 18:25:41 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[140] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 14.7 KiB, free 364.2 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[140] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 46.0 (TID 46)
22/07/24 18:25:41 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_returns/part-00000-78fee2d9-1690-446a-861f-c17dcf2fbb3e-c000.snappy.parquet, range: 0-5268175, partition values: [empty row]
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 46.0 (TID 46). 2157 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ShuffleMapStage 46 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.012 s
22/07/24 18:25:41 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:41 INFO DAGScheduler: running: Set()
22/07/24 18:25:41 INFO DAGScheduler: waiting: Set(ResultStage 47)
22/07/24 18:25:41 INFO DAGScheduler: failed: Set()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[143] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 10.1 KiB, free 364.2 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.2 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[143] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 47.0 (TID 47)
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 47.0 (TID 47). 2605 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 47 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.006 s
22/07/24 18:25:41 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 31 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.021724 s
22/07/24 18:25:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:41 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:41 INFO DAGScheduler: Got job 32 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:41 INFO DAGScheduler: Final stage: ResultStage 48 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:41 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:41 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:41 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[145] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 74.4 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.1 MiB)
22/07/24 18:25:41 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:41 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[145] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:41 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
22/07/24 18:25:41 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 48) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4708 bytes) taskResourceAssignments Map()
22/07/24 18:25:41 INFO Executor: Running task 0.0 in stage 48.0 (TID 48)
22/07/24 18:25:41 INFO Executor: Finished task 0.0 in stage 48.0 (TID 48). 3265 bytes result sent to driver
22/07/24 18:25:41 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 48) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:41 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
22/07/24 18:25:41 INFO DAGScheduler: ResultStage 48 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.013 s
22/07/24 18:25:41 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
22/07/24 18:25:41 INFO DAGScheduler: Job 32 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.014403 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 292.4 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 65 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4205935 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 149 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 16
22/07/24 18:25:42 INFO DAGScheduler: Got job 33 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 50 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[149] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 14.7 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[149] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 49) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 49.0 (TID 49)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_site/part-00000-5dea6278-ddc8-47ae-9d1c-93329c79037c-c000.snappy.parquet, range: 0-11631, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 49.0 (TID 49). 2157 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 49) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 49 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 50)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[152] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 10.1 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[152] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 50) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 50.0 (TID 50)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 50.0 (TID 50). 2562 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 50) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 50 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.006 s
22/07/24 18:25:42 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 33 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.018273 s
22/07/24 18:25:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Got job 34 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 51 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[154] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 74.4 KiB, free 363.7 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 363.7 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[154] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 51) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4706 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 51.0 (TID 51)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 51.0 (TID 51). 1751 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 51) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 51 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.011 s
22/07/24 18:25:42 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 34 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.011906 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 292.4 KiB, free 363.4 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 363.4 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 69 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4196659 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 158 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 17
22/07/24 18:25:42 INFO DAGScheduler: Got job 35 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 53 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[158] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 14.7 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[158] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 52) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4946 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 52.0 (TID 52)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/reason/part-00000-9d09b039-c80a-46db-b093-26903c24c128-c000.snappy.parquet, range: 0-2355, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 52.0 (TID 52). 2114 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 52) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 52 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.007 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 53)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[161] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 10.1 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[161] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 53) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 53.0 (TID 53)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_55_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_49_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_61_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_68_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_62_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 53.0 (TID 53). 2648 bytes result sent to driver
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_60_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 53) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 53 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.020 s
22/07/24 18:25:42 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 35 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.029396 s
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_57_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_63_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_53_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_50_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_59_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_67_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_45_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_66_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_52_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_56_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_48_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_54_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_51_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_64_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_58_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_65_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.3 MiB)
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Got job 36 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 54 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[163] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 74.4 KiB, free 365.9 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.9 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[163] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 54) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4711 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 54.0 (TID 54)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 54.0 (TID 54). 3461 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 54) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 54 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:42 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 36 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.010820 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 292.4 KiB, free 365.6 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.5 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 73 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4204207 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 167 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 18
22/07/24 18:25:42 INFO DAGScheduler: Got job 37 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 56 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 55)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[167] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 14.7 KiB, free 365.5 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.5 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[167] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 55.0 (TID 55)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/call_center/part-00000-e43c4a6b-238c-4f7b-a8d7-c8b8441796d9-c000.snappy.parquet, range: 0-9903, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 55.0 (TID 55). 2157 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 55 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.009 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 56)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[170] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 10.1 KiB, free 365.5 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.5 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[170] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 56) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 56.0 (TID 56)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 56.0 (TID 56). 2648 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 56) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 56 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.007 s
22/07/24 18:25:42 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 37 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.017654 s
22/07/24 18:25:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Got job 38 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 57 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[172] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 74.4 KiB, free 365.4 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.4 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[172] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 57) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4709 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 57.0 (TID 57)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 57.0 (TID 57). 2634 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 57) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 57 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:42 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 38 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.011199 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 292.4 KiB, free 365.1 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 365.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 77 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4198541 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 176 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 19
22/07/24 18:25:42 INFO DAGScheduler: Got job 39 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 59 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[176] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 14.7 KiB, free 365.1 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 365.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[176] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 58) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 58.0 (TID 58)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/warehouse/part-00000-b4855a81-d301-4246-b417-f2ee34562569-c000.snappy.parquet, range: 0-4237, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 58.0 (TID 58). 2114 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 58) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 58 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.010 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 59)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[179] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 10.1 KiB, free 365.1 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 365.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[179] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 59) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 59.0 (TID 59)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 59.0 (TID 59). 2562 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 59) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 59 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.006 s
22/07/24 18:25:42 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 39 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.016878 s
22/07/24 18:25:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Got job 40 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 60 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[181] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 74.4 KiB, free 365.0 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 365.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[181] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 60) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4709 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 60.0 (TID 60)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 60.0 (TID 60). 1876 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 60) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 60 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.011 s
22/07/24 18:25:42 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 40 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.011115 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 292.4 KiB, free 364.7 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.7 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 81 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197051 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 185 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 20
22/07/24 18:25:42 INFO DAGScheduler: Got job 41 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 62 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[185] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 14.7 KiB, free 364.6 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.6 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[185] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 61) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 61.0 (TID 61)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/ship_mode/part-00000-d32cb32e-ddc3-47cc-b1ab-e6006d42ff98-c000.snappy.parquet, range: 0-2747, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 61.0 (TID 61). 2157 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 61) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 61 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.011 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 62)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[188] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 10.1 KiB, free 364.6 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.6 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[188] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 62) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 62.0 (TID 62)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 62.0 (TID 62). 2562 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 62) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 62 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.005 s
22/07/24 18:25:42 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 41 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.017250 s
22/07/24 18:25:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Got job 42 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 63 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[190] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 74.4 KiB, free 364.5 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.5 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[190] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 63) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4711 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 63.0 (TID 63)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 63.0 (TID 63). 1711 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 63) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 63 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.009 s
22/07/24 18:25:42 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 42 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.010704 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 292.4 KiB, free 364.2 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 364.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 85 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195484 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 194 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 21
22/07/24 18:25:42 INFO DAGScheduler: Got job 43 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 65 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[194] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 14.7 KiB, free 364.2 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 364.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[194] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 64) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 64.0 (TID 64)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/income_band/part-00000-de7a092b-e49b-42ab-a8e9-61e608f00170-c000.snappy.parquet, range: 0-1180, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 64.0 (TID 64). 2157 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 64) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 64 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.007 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 65)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[197] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 10.1 KiB, free 364.2 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[197] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 65) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 65.0 (TID 65)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 65.0 (TID 65). 2562 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 65) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 65 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.004 s
22/07/24 18:25:42 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 43 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.013346 s
22/07/24 18:25:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Got job 44 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 66 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[199] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 74.4 KiB, free 364.1 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 364.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[199] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 66) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4708 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 66.0 (TID 66)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 66.0 (TID 66). 2017 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 66) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 66 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.012 s
22/07/24 18:25:42 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 44 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.012660 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 292.4 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 89 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5322828 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 203 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 22
22/07/24 18:25:42 INFO DAGScheduler: Got job 45 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 68 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[203] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 14.7 KiB, free 363.8 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 363.7 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[203] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 67) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 67.0 (TID 67)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/time_dim/part-00000-1e35308c-0543-40c1-9bec-601efd1ee82b-c000.snappy.parquet, range: 0-1128524, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 67.0 (TID 67). 2114 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 67) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 67 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.007 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 68)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[206] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 10.1 KiB, free 363.7 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 363.7 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[206] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 68) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 68.0 (TID 68)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 68.0 (TID 68). 2562 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 68) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 68 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.004 s
22/07/24 18:25:42 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 45 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.012394 s
22/07/24 18:25:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Got job 46 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 69 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[208] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 74.4 KiB, free 363.7 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 363.6 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.7 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[208] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 69) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4708 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 69.0 (TID 69)
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 69.0 (TID 69). 2303 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 69) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 69 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.009 s
22/07/24 18:25:42 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 46 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.010300 s
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: 
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<>
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 292.4 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 24.8 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.8 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 93 from runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199818 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:42 INFO SparkContext: Starting job: runBenchmarkSuite at BenchmarkBase.scala:58
22/07/24 18:25:42 INFO DAGScheduler: Registering RDD 212 (runBenchmarkSuite at BenchmarkBase.scala:58) as input to shuffle 23
22/07/24 18:25:42 INFO DAGScheduler: Got job 47 (runBenchmarkSuite at BenchmarkBase.scala:58) with 1 output partitions
22/07/24 18:25:42 INFO DAGScheduler: Final stage: ResultStage 71 (runBenchmarkSuite at BenchmarkBase.scala:58)
22/07/24 18:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
22/07/24 18:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
22/07/24 18:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[212] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 14.7 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 7.0 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[212] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 70) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 70.0 (TID 70)
22/07/24 18:25:42 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_page/part-00000-58ec1cf3-301c-47bd-9117-56cb855fb2ef-c000.snappy.parquet, range: 0-5514, partition values: [empty row]
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 70.0 (TID 70). 2114 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 70) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ShuffleMapStage 70 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.007 s
22/07/24 18:25:42 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:42 INFO DAGScheduler: running: Set()
22/07/24 18:25:42 INFO DAGScheduler: waiting: Set(ResultStage 71)
22/07/24 18:25:42 INFO DAGScheduler: failed: Set()
22/07/24 18:25:42 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[215] at runBenchmarkSuite at BenchmarkBase.scala:58), which has no missing parents
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 10.1 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 363.3 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.0 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[215] at runBenchmarkSuite at BenchmarkBase.scala:58) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:42 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
22/07/24 18:25:42 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 71) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:42 INFO Executor: Running task 0.0 in stage 71.0 (TID 71)
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:42 INFO Executor: Finished task 0.0 in stage 71.0 (TID 71). 2562 bytes result sent to driver
22/07/24 18:25:42 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 71) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:42 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
22/07/24 18:25:42 INFO DAGScheduler: ResultStage 71 (runBenchmarkSuite at BenchmarkBase.scala:58) finished in 0.005 s
22/07/24 18:25:42 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
22/07/24 18:25:42 INFO DAGScheduler: Job 47 finished: runBenchmarkSuite at BenchmarkBase.scala:58, took 0.012604 s
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_75_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_77_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_81_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 365.9 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_89_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_88_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_91_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_73_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_86_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.0 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_84_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_69_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_78_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_79_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_80_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_70_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_95_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.1 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_85_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_94_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_72_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_83_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_90_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_71_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_82_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_92_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_87_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.0 KiB, free: 366.2 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_76_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.7 KiB, free: 366.3 MiB)
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_74_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 7.0 KiB, free: 366.3 MiB)
Running benchmark: TPCDS Snappy
  Running case: q38
22/07/24 18:25:42 INFO BlockManagerInfo: Removed broadcast_93_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.8 KiB, free: 366.3 MiB)
22/07/24 18:25:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ss_sold_date_sk),IsNotNull(ss_customer_sk)
22/07/24 18:25:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ss_sold_date_sk#1154),isnotnull(ss_customer_sk#1157)
22/07/24 18:25:42 INFO FileSourceStrategy: Output Data Schema: struct<ss_sold_date_sk: int, ss_customer_sk: int>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#332),(d_month_seq#332 >= 1200),(d_month_seq#332 <= 1211),isnotnull(d_date_sk#329)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#154)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(cs_sold_date_sk),IsNotNull(cs_bill_customer_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cs_sold_date_sk#872),isnotnull(cs_bill_customer_sk#875)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<cs_sold_date_sk: int, cs_bill_customer_sk: int>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#1918),(d_month_seq#1918 >= 1200),(d_month_seq#1918 <= 1211),isnotnull(d_date_sk#1915)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#1943)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ws_sold_date_sk),IsNotNull(ws_bill_customer_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ws_sold_date_sk#1013),isnotnull(ws_bill_customer_sk#1017)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<ws_sold_date_sk: int, ws_bill_customer_sk: int>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#1964),(d_month_seq#1964 >= 1200),(d_month_seq#1964 <= 1211),isnotnull(d_date_sk#1961)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#1989)
22/07/24 18:25:43 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 9.318433 ms
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 10.761509 ms
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 293.2 KiB, free 366.0 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 366.0 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 366.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 96 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9766600 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 22.118062 ms
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 293.2 KiB, free 365.7 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 365.7 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 366.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:43 INFO SparkContext: Created broadcast 97 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:43 INFO DAGScheduler: Got job 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:43 INFO DAGScheduler: Final stage: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:43 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:43 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:43 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[219] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6037354 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 13.3 KiB, free 365.7 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 365.7 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.7 KiB, free: 366.2 MiB)
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[219] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:43 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 72) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO Executor: Running task 0.0 in stage 72.0 (TID 72)
22/07/24 18:25:43 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer/part-00000-3fb5fb40-6c98-4939-86be-88f3d65875d2-c000.snappy.parquet, range: 0-5572296, partition values: [empty row]
22/07/24 18:25:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:43 INFO DAGScheduler: Got job 49 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:43 INFO DAGScheduler: Final stage: ResultStage 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:43 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:43 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:43 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 14.0 KiB, free 365.6 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 365.6 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.9 KiB, free: 366.2 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:43 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:43 INFO CodecPool: Got brand-new decompressor [.snappy]
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 70.838306 ms
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 11.615181 ms
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 7.94437 ms
22/07/24 18:25:43 INFO MemoryStore: Block taskresult_72 stored as bytes in memory (estimated size 2.4 MiB, free 363.3 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added taskresult_72 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.4 MiB, free: 363.9 MiB)
22/07/24 18:25:43 INFO Executor: Finished task 0.0 in stage 72.0 (TID 72). 2488452 bytes result sent via BlockManager)
22/07/24 18:25:43 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 73) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO Executor: Running task 0.0 in stage 73.0 (TID 73)
22/07/24 18:25:43 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/date_dim/part-00000-75a59129-a25a-4d72-836c-ce88969352f2-c000.snappy.parquet, range: 0-1843050, partition values: [empty row]
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:43 INFO TransportClientFactory: Successfully created connection to ubuntu-Virtual-Machine.mshome.net/172.28.45.111:35817 after 12 ms (0 ms spent in bootstraps)
22/07/24 18:25:43 INFO Executor: Finished task 0.0 in stage 73.0 (TID 73). 5058 bytes result sent to driver
22/07/24 18:25:43 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 73) in 39 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:43 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
22/07/24 18:25:43 INFO DAGScheduler: ResultStage 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.233 s
22/07/24 18:25:43 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
22/07/24 18:25:43 INFO DAGScheduler: Job 49 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.233490 s
22/07/24 18:25:43 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 72) in 258 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:43 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
22/07/24 18:25:43 INFO DAGScheduler: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.260 s
22/07/24 18:25:43 INFO BlockManagerInfo: Removed taskresult_72 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.4 MiB, free: 366.2 MiB)
22/07/24 18:25:43 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
22/07/24 18:25:43 INFO DAGScheduler: Job 48 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.260983 s
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 14.946941 ms
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 6.387195 ms
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 1026.9 KiB, free 364.6 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 364.6 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 366.2 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 100 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 16.8 MiB, free 347.9 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 2.9 MiB, free 345.0 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.9 MiB, free: 363.4 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 101 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 16.439953 ms
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 293.0 KiB, free 344.7 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 344.7 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 102 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 124086532 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 5.215324 ms
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 12.482718 ms
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 11.007151 ms
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 293.0 KiB, free 344.4 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 344.4 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 103 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 100763528 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:43 INFO BlockManagerInfo: Removed broadcast_99_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.9 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Removed broadcast_98_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.7 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 6.316905 ms
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 6.653809 ms
22/07/24 18:25:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 17.308241 ms
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 293.0 KiB, free 344.1 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 344.1 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 104 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48694286 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:43 INFO OverwriteByExpressionExec: Start processing data source write support: org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2. The input RDD has 1 partitions.
22/07/24 18:25:43 INFO SparkContext: Starting job: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:43 INFO DAGScheduler: Registering RDD 243 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 27
22/07/24 18:25:43 INFO DAGScheduler: Registering RDD 233 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 25
22/07/24 18:25:43 INFO DAGScheduler: Registering RDD 236 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 26
22/07/24 18:25:43 INFO DAGScheduler: Registering RDD 227 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 24
22/07/24 18:25:43 INFO DAGScheduler: Registering RDD 246 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 28
22/07/24 18:25:43 INFO DAGScheduler: Registering RDD 251 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 29
22/07/24 18:25:43 INFO DAGScheduler: Registering RDD 254 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 30
22/07/24 18:25:43 INFO DAGScheduler: Got job 50 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) with 1 output partitions
22/07/24 18:25:43 INFO DAGScheduler: Final stage: ResultStage 81 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77)
22/07/24 18:25:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
22/07/24 18:25:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 80)
22/07/24 18:25:43 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[233] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 36.4 KiB, free 344.1 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 344.1 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[233] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:43 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
22/07/24 18:25:43 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[227] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:43 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 74) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO Executor: Running task 0.0 in stage 75.0 (TID 74)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 19.9 KiB, free 344.0 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 344.0 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 8.5 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[227] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:43 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0
22/07/24 18:25:43 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[243] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 36.4 KiB, free 344.0 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 344.0 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 363.3 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[243] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:43 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 6.929994 ms
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 4.510968 ms
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 3.072489 ms
22/07/24 18:25:43 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_sales/part-00000-e44b35cf-e4e1-4304-95ca-e106b3d97ef0-c000.snappy.parquet, range: 0-96569224, partition values: [empty row]
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:43 INFO Executor: Finished task 0.0 in stage 75.0 (TID 74). 4633 bytes result sent to driver
22/07/24 18:25:43 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 75) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 74) in 165 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:43 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
22/07/24 18:25:43 INFO DAGScheduler: ShuffleMapStage 75 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.168 s
22/07/24 18:25:43 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:43 INFO DAGScheduler: running: Set(ShuffleMapStage 74, ShuffleMapStage 77)
22/07/24 18:25:43 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 78, ShuffleMapStage 79, ShuffleMapStage 76, ShuffleMapStage 80)
22/07/24 18:25:43 INFO DAGScheduler: failed: Set()
22/07/24 18:25:43 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[236] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:43 INFO Executor: Running task 0.0 in stage 74.0 (TID 75)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 33.7 KiB, free 343.9 MiB)
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 343.9 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.5 KiB, free: 363.2 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:43 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[236] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:43 INFO TaskSchedulerImpl: Adding task set 76.0 with 4 tasks resource profile 0
22/07/24 18:25:43 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_sales/part-00000-c79381f5-f0b0-439a-aaca-89acfda21c12-c000.snappy.parquet, range: 0-44499982, partition values: [empty row]
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:43 INFO Executor: Finished task 0.0 in stage 74.0 (TID 75). 4633 bytes result sent to driver
22/07/24 18:25:43 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 76) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 75) in 74 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:43 INFO Executor: Running task 0.0 in stage 76.0 (TID 76)
22/07/24 18:25:43 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
22/07/24 18:25:43 INFO DAGScheduler: ShuffleMapStage 74 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.239 s
22/07/24 18:25:43 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:43 INFO DAGScheduler: running: Set(ShuffleMapStage 76, ShuffleMapStage 77)
22/07/24 18:25:43 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 78, ShuffleMapStage 79, ShuffleMapStage 80)
22/07/24 18:25:43 INFO DAGScheduler: failed: Set()
22/07/24 18:25:43 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[246] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 34.0 KiB, free 343.9 MiB)
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:43 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 343.9 MiB)
22/07/24 18:25:43 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 363.2 MiB)
22/07/24 18:25:43 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:43 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[246] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:43 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks resource profile 0
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 6.531901 ms
22/07/24 18:25:43 INFO Executor: Finished task 0.0 in stage 76.0 (TID 76). 6008 bytes result sent to driver
22/07/24 18:25:43 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 77) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 76) in 49 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:43 INFO Executor: Running task 1.0 in stage 76.0 (TID 77)
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:43 INFO Executor: Finished task 1.0 in stage 76.0 (TID 77). 6008 bytes result sent to driver
22/07/24 18:25:43 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 78) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO Executor: Running task 2.0 in stage 76.0 (TID 78)
22/07/24 18:25:43 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 77) in 19 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:43 INFO Executor: Finished task 2.0 in stage 76.0 (TID 78). 6008 bytes result sent to driver
22/07/24 18:25:43 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 79) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 78) in 15 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:43 INFO Executor: Running task 3.0 in stage 76.0 (TID 79)
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:43 INFO Executor: Finished task 3.0 in stage 76.0 (TID 79). 6008 bytes result sent to driver
22/07/24 18:25:43 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 80) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:43 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 79) in 14 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:43 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
22/07/24 18:25:43 INFO Executor: Running task 0.0 in stage 77.0 (TID 80)
22/07/24 18:25:43 INFO DAGScheduler: ShuffleMapStage 76 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.167 s
22/07/24 18:25:43 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:43 INFO DAGScheduler: running: Set(ShuffleMapStage 78, ShuffleMapStage 77)
22/07/24 18:25:43 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
22/07/24 18:25:43 INFO DAGScheduler: failed: Set()
22/07/24 18:25:43 INFO CodeGenerator: Code generated in 6.286611 ms
22/07/24 18:25:43 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_sales/part-00000-aadc4cd6-fb63-4cb6-85be-f942835071d3-c000.snappy.parquet, range: 0-119892228, partition values: [empty row]
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:43 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:44 INFO Executor: Finished task 0.0 in stage 77.0 (TID 80). 2242 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 81) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 80) in 182 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:44 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
22/07/24 18:25:44 INFO Executor: Running task 0.0 in stage 78.0 (TID 81)
22/07/24 18:25:44 INFO DAGScheduler: ShuffleMapStage 77 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.516 s
22/07/24 18:25:44 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:44 INFO DAGScheduler: running: Set(ShuffleMapStage 78)
22/07/24 18:25:44 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
22/07/24 18:25:44 INFO DAGScheduler: failed: Set()
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 0.0 in stage 78.0 (TID 81). 6008 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 82) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 81) in 13 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:44 INFO Executor: Running task 1.0 in stage 78.0 (TID 82)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 1.0 in stage 78.0 (TID 82). 6008 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 83) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 82) in 11 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:44 INFO Executor: Running task 2.0 in stage 78.0 (TID 83)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 2.0 in stage 78.0 (TID 83). 6008 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 84) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 83) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:44 INFO Executor: Running task 3.0 in stage 78.0 (TID 84)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 3.0 in stage 78.0 (TID 84). 6008 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 84) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:44 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
22/07/24 18:25:44 INFO DAGScheduler: ShuffleMapStage 78 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.316 s
22/07/24 18:25:44 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:44 INFO DAGScheduler: running: Set()
22/07/24 18:25:44 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
22/07/24 18:25:44 INFO DAGScheduler: failed: Set()
22/07/24 18:25:44 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[251] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 58.1 KiB, free 343.8 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 24.2 KiB, free 343.8 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.2 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:44 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[251] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:44 INFO TaskSchedulerImpl: Adding task set 79.0 with 4 tasks resource profile 0
22/07/24 18:25:44 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 85) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 0.0 in stage 79.0 (TID 85)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 11.909158 ms
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 6.97463 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 6.670406 ms
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 4.669042 ms
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 5.273714 ms
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 3.297639 ms
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 6.58424 ms
22/07/24 18:25:44 INFO BlockManagerInfo: Removed broadcast_107_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Removed broadcast_106_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 8.5 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Removed broadcast_105_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Removed broadcast_109_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 363.3 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Removed broadcast_108_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.5 KiB, free: 363.3 MiB)
22/07/24 18:25:44 INFO CodeGenerator: Code generated in 11.509252 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (71.8 KiB) non-empty blocks including 4 (71.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 0.0 in stage 79.0 (TID 85). 12072 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 86) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 1.0 in stage 79.0 (TID 86)
22/07/24 18:25:44 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 85) in 245 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (70.0 KiB) non-empty blocks including 4 (70.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 1.0 in stage 79.0 (TID 86). 12029 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 87) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 86) in 100 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:44 INFO Executor: Running task 2.0 in stage 79.0 (TID 87)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 2.0 in stage 79.0 (TID 87). 12072 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 88) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 87) in 97 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:44 INFO Executor: Running task 3.0 in stage 79.0 (TID 88)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 3.0 in stage 79.0 (TID 88). 12029 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 88) in 67 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:44 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
22/07/24 18:25:44 INFO DAGScheduler: ShuffleMapStage 79 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.512 s
22/07/24 18:25:44 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:44 INFO DAGScheduler: running: Set()
22/07/24 18:25:44 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 80)
22/07/24 18:25:44 INFO DAGScheduler: failed: Set()
22/07/24 18:25:44 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[254] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 74.3 KiB, free 344.0 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 343.9 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.6 KiB, free: 363.3 MiB)
22/07/24 18:25:44 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:44 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[254] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:44 INFO TaskSchedulerImpl: Adding task set 80.0 with 4 tasks resource profile 0
22/07/24 18:25:44 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 89) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 0.0 in stage 80.0 (TID 89)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (371.0 B) non-empty blocks including 4 (371.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 0.0 in stage 80.0 (TID 89). 14630 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 90) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 89) in 23 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:44 INFO Executor: Running task 1.0 in stage 80.0 (TID 90)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (473.0 B) non-empty blocks including 4 (473.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 1.0 in stage 80.0 (TID 90). 14630 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 91) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 2.0 in stage 80.0 (TID 91)
22/07/24 18:25:44 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 90) in 16 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (348.0 B) non-empty blocks including 4 (348.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 2.0 in stage 80.0 (TID 91). 14630 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 92) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 3.0 in stage 80.0 (TID 92)
22/07/24 18:25:44 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 91) in 11 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (388.0 B) non-empty blocks including 4 (388.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO Executor: Finished task 3.0 in stage 80.0 (TID 92). 14630 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 92) in 10 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:44 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
22/07/24 18:25:44 INFO DAGScheduler: ShuffleMapStage 80 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.062 s
22/07/24 18:25:44 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:44 INFO DAGScheduler: running: Set()
22/07/24 18:25:44 INFO DAGScheduler: waiting: Set(ResultStage 81)
22/07/24 18:25:44 INFO DAGScheduler: failed: Set()
22/07/24 18:25:44 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[256] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 9.6 KiB, free 343.9 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 343.9 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[256] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:44 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
22/07/24 18:25:44 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 93) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 0.0 in stage 81.0 (TID 93)
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:44 INFO DataWritingSparkTask: Writer for partition 0 is committing.
22/07/24 18:25:44 INFO DataWritingSparkTask: Committed partition 0 (task 93, attempt 0, stage 81.0)
22/07/24 18:25:44 INFO Executor: Finished task 0.0 in stage 81.0 (TID 93). 2571 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 93) in 16 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:44 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
22/07/24 18:25:44 INFO DAGScheduler: ResultStage 81 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.018 s
22/07/24 18:25:44 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
22/07/24 18:25:44 INFO DAGScheduler: Job 50 finished: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77, took 1.156845 s
22/07/24 18:25:44 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 is committing.
22/07/24 18:25:44 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 committed.
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ss_sold_date_sk),IsNotNull(ss_customer_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ss_sold_date_sk#1154),isnotnull(ss_customer_sk#1157)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<ss_sold_date_sk: int, ss_customer_sk: int>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#332),(d_month_seq#332 >= 1200),(d_month_seq#332 <= 1211),isnotnull(d_date_sk#329)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#154)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(cs_sold_date_sk),IsNotNull(cs_bill_customer_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cs_sold_date_sk#872),isnotnull(cs_bill_customer_sk#875)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<cs_sold_date_sk: int, cs_bill_customer_sk: int>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2016),(d_month_seq#2016 >= 1200),(d_month_seq#2016 <= 1211),isnotnull(d_date_sk#2013)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2041)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ws_sold_date_sk),IsNotNull(ws_bill_customer_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ws_sold_date_sk#1013),isnotnull(ws_bill_customer_sk#1017)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<ws_sold_date_sk: int, ws_bill_customer_sk: int>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2062),(d_month_seq#2062 >= 1200),(d_month_seq#2062 <= 1211),isnotnull(d_date_sk#2059)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:44 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:44 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2087)
22/07/24 18:25:44 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 293.2 KiB, free 343.6 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 293.2 KiB, free 343.3 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 343.3 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 343.3 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO SparkContext: Created broadcast 113 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:44 INFO SparkContext: Created broadcast 114 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6037354 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9766600 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:44 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:44 INFO DAGScheduler: Got job 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:44 INFO DAGScheduler: Final stage: ResultStage 82 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:44 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:44 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:44 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[265] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 13.3 KiB, free 343.3 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 343.3 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.7 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[265] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:44 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
22/07/24 18:25:44 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 94) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 0.0 in stage 82.0 (TID 94)
22/07/24 18:25:44 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer/part-00000-3fb5fb40-6c98-4939-86be-88f3d65875d2-c000.snappy.parquet, range: 0-5572296, partition values: [empty row]
22/07/24 18:25:44 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:44 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:44 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:44 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:44 INFO DAGScheduler: Got job 52 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:44 INFO DAGScheduler: Final stage: ResultStage 83 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:44 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:44 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:44 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[266] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 14.0 KiB, free 343.3 MiB)
22/07/24 18:25:44 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 343.3 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.9 KiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[266] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:44 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0
22/07/24 18:25:44 INFO MemoryStore: Block taskresult_94 stored as bytes in memory (estimated size 2.4 MiB, free 340.9 MiB)
22/07/24 18:25:44 INFO BlockManagerInfo: Added taskresult_94 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.4 MiB, free: 360.8 MiB)
22/07/24 18:25:44 INFO Executor: Finished task 0.0 in stage 82.0 (TID 94). 2488452 bytes result sent via BlockManager)
22/07/24 18:25:44 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 95) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:44 INFO Executor: Running task 0.0 in stage 83.0 (TID 95)
22/07/24 18:25:44 INFO BlockManagerInfo: Removed taskresult_94 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.4 MiB, free: 363.2 MiB)
22/07/24 18:25:44 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 94) in 42 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:44 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
22/07/24 18:25:44 INFO DAGScheduler: ResultStage 82 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.046 s
22/07/24 18:25:44 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:44 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/date_dim/part-00000-75a59129-a25a-4d72-836c-ce88969352f2-c000.snappy.parquet, range: 0-1843050, partition values: [empty row]
22/07/24 18:25:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
22/07/24 18:25:44 INFO DAGScheduler: Job 51 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.047071 s
22/07/24 18:25:44 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:44 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:44 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:44 INFO Executor: Finished task 0.0 in stage 83.0 (TID 95). 5101 bytes result sent to driver
22/07/24 18:25:44 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 95) in 13 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:44 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
22/07/24 18:25:44 INFO DAGScheduler: ResultStage 83 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.036 s
22/07/24 18:25:44 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
22/07/24 18:25:44 INFO DAGScheduler: Job 52 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.037170 s
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 1026.9 KiB, free 342.3 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 342.2 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 363.2 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 117 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_101_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.9 MiB, free: 366.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_111_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.6 KiB, free: 366.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_116_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.9 KiB, free: 366.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_97_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 366.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_110_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.2 KiB, free: 366.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_96_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 366.2 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_115_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.7 KiB, free: 366.2 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_112_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 4.9 KiB, free: 366.2 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_100_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 4.9 KiB, free: 366.2 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_103_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 366.2 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_104_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 366.2 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Removed broadcast_102_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 366.2 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 16.8 MiB, free 347.9 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 2.9 MiB, free 345.0 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.9 MiB, free: 363.4 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 118 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 293.0 KiB, free 344.8 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 344.7 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.4 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 119 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 124086532 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 293.0 KiB, free 344.4 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 344.4 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.3 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 120 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 100763528 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 293.0 KiB, free 344.1 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 344.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.3 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 121 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48694286 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:45 INFO OverwriteByExpressionExec: Start processing data source write support: org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2. The input RDD has 1 partitions.
22/07/24 18:25:45 INFO SparkContext: Starting job: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:45 INFO DAGScheduler: Registering RDD 276 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 32
22/07/24 18:25:45 INFO DAGScheduler: Registering RDD 286 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 34
22/07/24 18:25:45 INFO DAGScheduler: Registering RDD 289 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 35
22/07/24 18:25:45 INFO DAGScheduler: Registering RDD 279 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 33
22/07/24 18:25:45 INFO DAGScheduler: Registering RDD 270 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 31
22/07/24 18:25:45 INFO DAGScheduler: Registering RDD 294 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 36
22/07/24 18:25:45 INFO DAGScheduler: Registering RDD 297 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 37
22/07/24 18:25:45 INFO DAGScheduler: Got job 53 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) with 1 output partitions
22/07/24 18:25:45 INFO DAGScheduler: Final stage: ResultStage 91 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77)
22/07/24 18:25:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
22/07/24 18:25:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
22/07/24 18:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[286] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 36.4 KiB, free 344.1 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 344.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 363.3 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[286] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
22/07/24 18:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[276] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 96) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 85.0 (TID 96)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 36.4 KiB, free 344.0 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 344.0 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 363.3 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[276] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
22/07/24 18:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[270] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 19.9 KiB, free 344.0 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 343.7 MiB)
22/07/24 18:25:45 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_sales/part-00000-c79381f5-f0b0-439a-aaca-89acfda21c12-c000.snappy.parquet, range: 0-44499982, partition values: [empty row]
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 8.5 KiB, free: 363.3 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[270] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 85.0 (TID 96). 4633 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 97) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 96) in 40 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ShuffleMapStage 85 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.043 s
22/07/24 18:25:45 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:45 INFO DAGScheduler: running: Set(ShuffleMapStage 84, ShuffleMapStage 88)
22/07/24 18:25:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 89, ShuffleMapStage 86, ShuffleMapStage 90, ShuffleMapStage 87, ResultStage 91)
22/07/24 18:25:45 INFO DAGScheduler: failed: Set()
22/07/24 18:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[289] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 84.0 (TID 97)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 34.0 KiB, free 343.9 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 343.9 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.6 KiB, free: 363.2 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[289] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 86.0 with 4 tasks resource profile 0
22/07/24 18:25:45 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_sales/part-00000-e44b35cf-e4e1-4304-95ca-e106b3d97ef0-c000.snappy.parquet, range: 0-96569224, partition values: [empty row]
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 84.0 (TID 97). 4633 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 98) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 97) in 88 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 86.0 (TID 98)
22/07/24 18:25:45 INFO DAGScheduler: ShuffleMapStage 84 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.127 s
22/07/24 18:25:45 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:45 INFO DAGScheduler: running: Set(ShuffleMapStage 88, ShuffleMapStage 86)
22/07/24 18:25:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 89, ShuffleMapStage 90, ShuffleMapStage 87, ResultStage 91)
22/07/24 18:25:45 INFO DAGScheduler: failed: Set()
22/07/24 18:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[279] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 33.7 KiB, free 343.9 MiB)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 343.9 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.5 KiB, free: 363.2 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[279] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks resource profile 0
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 86.0 (TID 98). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 99) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 98) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:45 INFO Executor: Running task 1.0 in stage 86.0 (TID 99)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 1.0 in stage 86.0 (TID 99). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 100) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 99) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:45 INFO Executor: Running task 2.0 in stage 86.0 (TID 100)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 2.0 in stage 86.0 (TID 100). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 101) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 3.0 in stage 86.0 (TID 101)
22/07/24 18:25:45 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 100) in 11 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 3.0 in stage 86.0 (TID 101). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 102) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 101) in 10 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ShuffleMapStage 86 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.122 s
22/07/24 18:25:45 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:45 INFO DAGScheduler: running: Set(ShuffleMapStage 88, ShuffleMapStage 87)
22/07/24 18:25:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 89, ShuffleMapStage 90, ResultStage 91)
22/07/24 18:25:45 INFO DAGScheduler: failed: Set()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 87.0 (TID 102)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 87.0 (TID 102). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 103) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 102) in 13 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:45 INFO Executor: Running task 1.0 in stage 87.0 (TID 103)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 1.0 in stage 87.0 (TID 103). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 104) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 103) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:45 INFO Executor: Running task 2.0 in stage 87.0 (TID 104)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 2.0 in stage 87.0 (TID 104). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 105) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 104) in 10 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:45 INFO Executor: Running task 3.0 in stage 87.0 (TID 105)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 3.0 in stage 87.0 (TID 105). 6008 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 106) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 88.0 (TID 106)
22/07/24 18:25:45 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 105) in 11 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ShuffleMapStage 87 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.078 s
22/07/24 18:25:45 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:45 INFO DAGScheduler: running: Set(ShuffleMapStage 88)
22/07/24 18:25:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 89, ShuffleMapStage 90, ResultStage 91)
22/07/24 18:25:45 INFO DAGScheduler: failed: Set()
22/07/24 18:25:45 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_sales/part-00000-aadc4cd6-fb63-4cb6-85be-f942835071d3-c000.snappy.parquet, range: 0-119892228, partition values: [empty row]
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 88.0 (TID 106). 2242 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 106) in 155 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ShuffleMapStage 88 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.359 s
22/07/24 18:25:45 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:45 INFO DAGScheduler: running: Set()
22/07/24 18:25:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 89, ShuffleMapStage 90, ResultStage 91)
22/07/24 18:25:45 INFO DAGScheduler: failed: Set()
22/07/24 18:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[294] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 58.1 KiB, free 343.8 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 24.2 KiB, free 343.8 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.2 KiB, free: 363.2 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[294] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 89.0 with 4 tasks resource profile 0
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 107) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 89.0 (TID 107)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (71.8 KiB) non-empty blocks including 4 (71.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 89.0 (TID 107). 12072 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 108) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 107) in 75 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:45 INFO Executor: Running task 1.0 in stage 89.0 (TID 108)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (70.0 KiB) non-empty blocks including 4 (70.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 1.0 in stage 89.0 (TID 108). 12029 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 109) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 2.0 in stage 89.0 (TID 109)
22/07/24 18:25:45 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 108) in 60 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 2.0 in stage 89.0 (TID 109). 12029 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 110) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 109) in 61 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:45 INFO Executor: Running task 3.0 in stage 89.0 (TID 110)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 3.0 in stage 89.0 (TID 110). 12029 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 110) in 64 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ShuffleMapStage 89 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.262 s
22/07/24 18:25:45 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:45 INFO DAGScheduler: running: Set()
22/07/24 18:25:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 90, ResultStage 91)
22/07/24 18:25:45 INFO DAGScheduler: failed: Set()
22/07/24 18:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[297] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 74.3 KiB, free 343.7 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 343.7 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.6 KiB, free: 363.2 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[297] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 90.0 with 4 tasks resource profile 0
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 111) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 90.0 (TID 111)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (371.0 B) non-empty blocks including 4 (371.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 90.0 (TID 111). 14630 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 112) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 111) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:45 INFO Executor: Running task 1.0 in stage 90.0 (TID 112)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (473.0 B) non-empty blocks including 4 (473.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 1.0 in stage 90.0 (TID 112). 14630 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 113) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 2.0 in stage 90.0 (TID 113)
22/07/24 18:25:45 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 112) in 18 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (348.0 B) non-empty blocks including 4 (348.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 2.0 in stage 90.0 (TID 113). 14630 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 114) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 113) in 11 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:45 INFO Executor: Running task 3.0 in stage 90.0 (TID 114)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (388.0 B) non-empty blocks including 4 (388.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO Executor: Finished task 3.0 in stage 90.0 (TID 114). 14673 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 114) in 24 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ShuffleMapStage 90 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.062 s
22/07/24 18:25:45 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:45 INFO DAGScheduler: running: Set()
22/07/24 18:25:45 INFO DAGScheduler: waiting: Set(ResultStage 91)
22/07/24 18:25:45 INFO DAGScheduler: failed: Set()
22/07/24 18:25:45 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[299] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 9.6 KiB, free 343.7 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 343.7 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 363.2 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[299] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 115) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 91.0 (TID 115)
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:45 INFO DataWritingSparkTask: Writer for partition 0 is committing.
22/07/24 18:25:45 INFO DataWritingSparkTask: Committed partition 0 (task 115, attempt 0, stage 91.0)
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 91.0 (TID 115). 2571 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 115) in 4 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ResultStage 91 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.006 s
22/07/24 18:25:45 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
22/07/24 18:25:45 INFO DAGScheduler: Job 53 finished: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77, took 0.698783 s
22/07/24 18:25:45 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 is committing.
22/07/24 18:25:45 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 committed.
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ss_sold_date_sk),IsNotNull(ss_customer_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ss_sold_date_sk#1154),isnotnull(ss_customer_sk#1157)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<ss_sold_date_sk: int, ss_customer_sk: int>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#332),(d_month_seq#332 >= 1200),(d_month_seq#332 <= 1211),isnotnull(d_date_sk#329)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#154)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(cs_sold_date_sk),IsNotNull(cs_bill_customer_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cs_sold_date_sk#872),isnotnull(cs_bill_customer_sk#875)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<cs_sold_date_sk: int, cs_bill_customer_sk: int>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2114),(d_month_seq#2114 >= 1200),(d_month_seq#2114 <= 1211),isnotnull(d_date_sk#2111)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2139)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ws_sold_date_sk),IsNotNull(ws_bill_customer_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ws_sold_date_sk#1013),isnotnull(ws_bill_customer_sk#1017)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<ws_sold_date_sk: int, ws_bill_customer_sk: int>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2160),(d_month_seq#2160 >= 1200),(d_month_seq#2160 <= 1211),isnotnull(d_date_sk#2157)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2185)
22/07/24 18:25:45 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 293.2 KiB, free 343.4 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 293.2 KiB, free 343.1 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 343.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.2 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 130 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 343.1 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 363.1 MiB)
22/07/24 18:25:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9766600 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:45 INFO SparkContext: Created broadcast 131 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6037354 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:45 INFO DAGScheduler: Got job 54 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:45 INFO DAGScheduler: Final stage: ResultStage 92 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:45 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:45 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:45 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[307] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 13.3 KiB, free 343.1 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 343.0 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.7 KiB, free: 363.1 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[307] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0
22/07/24 18:25:45 INFO DAGScheduler: Got job 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:45 INFO DAGScheduler: Final stage: ResultStage 93 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:45 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:45 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:45 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[309] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 116) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 92.0 (TID 116)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 14.0 KiB, free 343.0 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 343.0 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.9 KiB, free: 363.1 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:45 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer/part-00000-3fb5fb40-6c98-4939-86be-88f3d65875d2-c000.snappy.parquet, range: 0-5572296, partition values: [empty row]
22/07/24 18:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[309] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:45 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:45 INFO MemoryStore: Block taskresult_116 stored as bytes in memory (estimated size 2.4 MiB, free 340.7 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added taskresult_116 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.4 MiB, free: 360.7 MiB)
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 92.0 (TID 116). 2488495 bytes result sent via BlockManager)
22/07/24 18:25:45 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 117) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:45 INFO Executor: Running task 0.0 in stage 93.0 (TID 117)
22/07/24 18:25:45 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/date_dim/part-00000-75a59129-a25a-4d72-836c-ce88969352f2-c000.snappy.parquet, range: 0-1843050, partition values: [empty row]
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:45 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 116) in 39 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO BlockManagerInfo: Removed taskresult_116 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.4 MiB, free: 363.1 MiB)
22/07/24 18:25:45 INFO DAGScheduler: ResultStage 92 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.041 s
22/07/24 18:25:45 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
22/07/24 18:25:45 INFO DAGScheduler: Job 54 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.041577 s
22/07/24 18:25:45 INFO Executor: Finished task 0.0 in stage 93.0 (TID 117). 5101 bytes result sent to driver
22/07/24 18:25:45 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 117) in 25 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:45 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
22/07/24 18:25:45 INFO DAGScheduler: ResultStage 93 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.056 s
22/07/24 18:25:45 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
22/07/24 18:25:45 INFO DAGScheduler: Job 55 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.058413 s
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 1026.9 KiB, free 342.0 MiB)
22/07/24 18:25:45 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 342.0 MiB)
22/07/24 18:25:45 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 363.1 MiB)
22/07/24 18:25:45 INFO SparkContext: Created broadcast 134 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 16.8 MiB, free 325.3 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 2.9 MiB, free 322.4 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.9 MiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 135 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 293.0 KiB, free 322.1 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 322.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 136 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 124086532 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 293.0 KiB, free 321.8 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 321.8 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 137 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 100763528 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 293.0 KiB, free 321.5 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 321.5 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 138 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48694286 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO OverwriteByExpressionExec: Start processing data source write support: org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2. The input RDD has 1 partitions.
22/07/24 18:25:46 INFO SparkContext: Starting job: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 329 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 41
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 319 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 39
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 322 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 40
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 332 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 42
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 313 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 38
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 337 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 43
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 340 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 44
22/07/24 18:25:46 INFO DAGScheduler: Got job 56 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) with 1 output partitions
22/07/24 18:25:46 INFO DAGScheduler: Final stage: ResultStage 101 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77)
22/07/24 18:25:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
22/07/24 18:25:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 100)
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[319] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 36.4 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[319] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[329] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 118) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 95.0 (TID 118)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 36.4 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[329] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[313] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 19.9 KiB, free 321.3 MiB)
22/07/24 18:25:46 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_sales/part-00000-e44b35cf-e4e1-4304-95ca-e106b3d97ef0-c000.snappy.parquet, range: 0-96569224, partition values: [empty row]
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 321.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 8.5 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[313] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_129_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 4.9 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_128_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.6 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_132_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.7 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_133_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.9 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 95.0 (TID 118). 4676 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 119) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 118) in 77 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ShuffleMapStage 95 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.078 s
22/07/24 18:25:46 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:46 INFO DAGScheduler: running: Set(ShuffleMapStage 94, ShuffleMapStage 98)
22/07/24 18:25:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 99, ShuffleMapStage 96, ShuffleMapStage 100, ResultStage 101, ShuffleMapStage 97)
22/07/24 18:25:46 INFO DAGScheduler: failed: Set()
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[322] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 33.7 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.5 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[322] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 96.0 with 4 tasks resource profile 0
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 94.0 (TID 119)
22/07/24 18:25:46 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_sales/part-00000-c79381f5-f0b0-439a-aaca-89acfda21c12-c000.snappy.parquet, range: 0-44499982, partition values: [empty row]
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 94.0 (TID 119). 4633 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 120) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 119) in 39 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 96.0 (TID 120)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ShuffleMapStage 94 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.116 s
22/07/24 18:25:46 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:46 INFO DAGScheduler: running: Set(ShuffleMapStage 96, ShuffleMapStage 98)
22/07/24 18:25:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 99, ShuffleMapStage 100, ResultStage 101, ShuffleMapStage 97)
22/07/24 18:25:46 INFO DAGScheduler: failed: Set()
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[332] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 34.0 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.6 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[332] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 97.0 with 4 tasks resource profile 0
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 96.0 (TID 120). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 121) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 120) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:46 INFO Executor: Running task 1.0 in stage 96.0 (TID 121)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 1.0 in stage 96.0 (TID 121). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 122) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 2.0 in stage 96.0 (TID 122)
22/07/24 18:25:46 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 121) in 11 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 2.0 in stage 96.0 (TID 122). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 123) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 122) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:46 INFO Executor: Running task 3.0 in stage 96.0 (TID 123)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 3.0 in stage 96.0 (TID 123). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 124) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 123) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 97.0 (TID 124)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ShuffleMapStage 96 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.074 s
22/07/24 18:25:46 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:46 INFO DAGScheduler: running: Set(ShuffleMapStage 97, ShuffleMapStage 98)
22/07/24 18:25:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 99, ShuffleMapStage 100, ResultStage 101)
22/07/24 18:25:46 INFO DAGScheduler: failed: Set()
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 97.0 (TID 124). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 125) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 124) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:46 INFO Executor: Running task 1.0 in stage 97.0 (TID 125)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 1.0 in stage 97.0 (TID 125). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 2.0 in stage 97.0 (TID 126) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 125) in 12 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:46 INFO Executor: Running task 2.0 in stage 97.0 (TID 126)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 2.0 in stage 97.0 (TID 126). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 3.0 in stage 97.0 (TID 127) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 2.0 in stage 97.0 (TID 126) in 10 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:46 INFO Executor: Running task 3.0 in stage 97.0 (TID 127)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 3.0 in stage 97.0 (TID 127). 6008 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 128) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 3.0 in stage 97.0 (TID 127) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 98.0 (TID 128)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ShuffleMapStage 97 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.070 s
22/07/24 18:25:46 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:46 INFO DAGScheduler: running: Set(ShuffleMapStage 98)
22/07/24 18:25:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 99, ShuffleMapStage 100, ResultStage 101)
22/07/24 18:25:46 INFO DAGScheduler: failed: Set()
22/07/24 18:25:46 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_sales/part-00000-aadc4cd6-fb63-4cb6-85be-f942835071d3-c000.snappy.parquet, range: 0-119892228, partition values: [empty row]
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 98.0 (TID 128). 2242 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 128) in 145 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ShuffleMapStage 98 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.329 s
22/07/24 18:25:46 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:46 INFO DAGScheduler: running: Set()
22/07/24 18:25:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 99, ShuffleMapStage 100, ResultStage 101)
22/07/24 18:25:46 INFO DAGScheduler: failed: Set()
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[337] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 58.1 KiB, free 321.3 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 24.2 KiB, free 321.3 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.2 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[337] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 99.0 with 4 tasks resource profile 0
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 129) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 99.0 (TID 129)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (71.8 KiB) non-empty blocks including 4 (71.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 99.0 (TID 129). 12029 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 130) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 129) in 58 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:46 INFO Executor: Running task 1.0 in stage 99.0 (TID 130)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (70.0 KiB) non-empty blocks including 4 (70.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_139_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_142_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.5 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_140_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_141_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 8.5 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_143_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.6 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO Executor: Finished task 1.0 in stage 99.0 (TID 130). 12072 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 131) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 130) in 66 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:46 INFO Executor: Running task 2.0 in stage 99.0 (TID 131)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 2.0 in stage 99.0 (TID 131). 12029 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 132) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 3.0 in stage 99.0 (TID 132)
22/07/24 18:25:46 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 131) in 59 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 3.0 in stage 99.0 (TID 132). 12029 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 132) in 59 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ShuffleMapStage 99 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.246 s
22/07/24 18:25:46 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:46 INFO DAGScheduler: running: Set()
22/07/24 18:25:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 100, ResultStage 101)
22/07/24 18:25:46 INFO DAGScheduler: failed: Set()
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[340] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 74.3 KiB, free 321.5 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 26.5 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.5 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[340] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 100.0 with 4 tasks resource profile 0
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 133) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 100.0 (TID 133)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (371.0 B) non-empty blocks including 4 (371.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 100.0 (TID 133). 14630 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 134) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 133) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:46 INFO Executor: Running task 1.0 in stage 100.0 (TID 134)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (473.0 B) non-empty blocks including 4 (473.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 1.0 in stage 100.0 (TID 134). 14630 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 2.0 in stage 100.0 (TID 135) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 134) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:46 INFO Executor: Running task 2.0 in stage 100.0 (TID 135)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (348.0 B) non-empty blocks including 4 (348.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 2.0 in stage 100.0 (TID 135). 14630 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Starting task 3.0 in stage 100.0 (TID 136) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 3.0 in stage 100.0 (TID 136)
22/07/24 18:25:46 INFO TaskSetManager: Finished task 2.0 in stage 100.0 (TID 135) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (388.0 B) non-empty blocks including 4 (388.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO Executor: Finished task 3.0 in stage 100.0 (TID 136). 14630 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Finished task 3.0 in stage 100.0 (TID 136) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ShuffleMapStage 100 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.028 s
22/07/24 18:25:46 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:46 INFO DAGScheduler: running: Set()
22/07/24 18:25:46 INFO DAGScheduler: waiting: Set(ResultStage 101)
22/07/24 18:25:46 INFO DAGScheduler: failed: Set()
22/07/24 18:25:46 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[342] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 9.6 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 321.4 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[342] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 137) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 101.0 (TID 137)
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:46 INFO DataWritingSparkTask: Writer for partition 0 is committing.
22/07/24 18:25:46 INFO DataWritingSparkTask: Committed partition 0 (task 137, attempt 0, stage 101.0)
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 101.0 (TID 137). 2485 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 137) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ResultStage 101 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.004 s
22/07/24 18:25:46 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished
22/07/24 18:25:46 INFO DAGScheduler: Job 56 finished: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77, took 0.614711 s
22/07/24 18:25:46 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 is committing.
22/07/24 18:25:46 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 committed.
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ss_sold_date_sk),IsNotNull(ss_customer_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ss_sold_date_sk#1154),isnotnull(ss_customer_sk#1157)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<ss_sold_date_sk: int, ss_customer_sk: int>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#332),(d_month_seq#332 >= 1200),(d_month_seq#332 <= 1211),isnotnull(d_date_sk#329)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#154)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(cs_sold_date_sk),IsNotNull(cs_bill_customer_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cs_sold_date_sk#872),isnotnull(cs_bill_customer_sk#875)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<cs_sold_date_sk: int, cs_bill_customer_sk: int>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2212),(d_month_seq#2212 >= 1200),(d_month_seq#2212 <= 1211),isnotnull(d_date_sk#2209)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2237)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ws_sold_date_sk),IsNotNull(ws_bill_customer_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ws_sold_date_sk#1013),isnotnull(ws_bill_customer_sk#1017)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<ws_sold_date_sk: int, ws_bill_customer_sk: int>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2258),(d_month_seq#2258 >= 1200),(d_month_seq#2258 <= 1211),isnotnull(d_date_sk#2255)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2283)
22/07/24 18:25:46 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 293.2 KiB, free 321.1 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 321.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 147 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6037354 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 293.2 KiB, free 320.8 MiB)
22/07/24 18:25:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO DAGScheduler: Got job 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:46 INFO DAGScheduler: Final stage: ResultStage 102 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:46 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[348] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 14.0 KiB, free 320.8 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 320.8 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.9 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[348] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 138) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 320.8 MiB)
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 102.0 (TID 138)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 148 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/date_dim/part-00000-75a59129-a25a-4d72-836c-ce88969352f2-c000.snappy.parquet, range: 0-1843050, partition values: [empty row]
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9766600 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 102.0 (TID 138). 5058 bytes result sent to driver
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 138) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO DAGScheduler: ResultStage 102 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.008 s
22/07/24 18:25:46 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished
22/07/24 18:25:46 INFO DAGScheduler: Job 57 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.009179 s
22/07/24 18:25:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO DAGScheduler: Got job 58 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:46 INFO DAGScheduler: Final stage: ResultStage 103 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:46 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:46 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:46 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[352] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 1026.9 KiB, free 319.8 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 13.3 KiB, free 319.8 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 319.8 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 150 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 319.7 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.7 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[352] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 139) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 103.0 (TID 139)
22/07/24 18:25:46 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer/part-00000-3fb5fb40-6c98-4939-86be-88f3d65875d2-c000.snappy.parquet, range: 0-5572296, partition values: [empty row]
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_145_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.5 KiB, free: 360.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_135_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.9 MiB, free: 363.0 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_144_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.2 KiB, free: 363.0 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_138_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 363.0 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_134_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 4.9 KiB, free: 363.0 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_136_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 363.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_131_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 363.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_137_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 363.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_130_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 363.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_149_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.9 KiB, free: 363.1 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Removed broadcast_146_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 4.9 KiB, free: 363.2 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block taskresult_139 stored as bytes in memory (estimated size 2.4 MiB, free 339.8 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added taskresult_139 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.4 MiB, free: 360.8 MiB)
22/07/24 18:25:46 INFO Executor: Finished task 0.0 in stage 103.0 (TID 139). 2488495 bytes result sent via BlockManager)
22/07/24 18:25:46 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 139) in 40 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:46 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
22/07/24 18:25:46 INFO BlockManagerInfo: Removed taskresult_139 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.4 MiB, free: 363.2 MiB)
22/07/24 18:25:46 INFO DAGScheduler: ResultStage 103 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.042 s
22/07/24 18:25:46 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
22/07/24 18:25:46 INFO DAGScheduler: Job 58 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.043165 s
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 16.8 MiB, free 325.4 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 2.9 MiB, free 322.5 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.9 MiB, free: 360.3 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 152 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 293.0 KiB, free 322.2 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 322.2 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.3 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 153 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 124086532 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 293.0 KiB, free 321.9 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 321.9 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 154 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 100763528 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 293.0 KiB, free 321.6 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 321.6 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 155 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48694286 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:46 INFO OverwriteByExpressionExec: Start processing data source write support: org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2. The input RDD has 1 partitions.
22/07/24 18:25:46 INFO SparkContext: Starting job: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 362 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 46
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 372 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 48
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 356 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 45
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 375 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 49
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 365 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 47
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 380 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 50
22/07/24 18:25:46 INFO DAGScheduler: Registering RDD 383 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 51
22/07/24 18:25:46 INFO DAGScheduler: Got job 59 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) with 1 output partitions
22/07/24 18:25:46 INFO DAGScheduler: Final stage: ResultStage 111 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77)
22/07/24 18:25:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
22/07/24 18:25:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 110)
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[356] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 19.9 KiB, free 321.6 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 321.6 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 8.5 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[356] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[372] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 36.4 KiB, free 321.5 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 321.5 MiB)
22/07/24 18:25:46 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 140) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:46 INFO Executor: Running task 0.0 in stage 106.0 (TID 140)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[372] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[362] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 36.4 KiB, free 321.5 MiB)
22/07/24 18:25:46 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 321.5 MiB)
22/07/24 18:25:46 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:46 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_sales/part-00000-aadc4cd6-fb63-4cb6-85be-f942835071d3-c000.snappy.parquet, range: 0-119892228, partition values: [empty row]
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:46 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[362] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:46 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:46 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 106.0 (TID 140). 2199 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 141) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 140) in 145 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 104.0 (TID 141)
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 106 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.147 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 104, ShuffleMapStage 105)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 107, ResultStage 111, ShuffleMapStage 108, ShuffleMapStage 109, ShuffleMapStage 110)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_sales/part-00000-e44b35cf-e4e1-4304-95ca-e106b3d97ef0-c000.snappy.parquet, range: 0-96569224, partition values: [empty row]
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_156_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 8.5 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_151_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 104.0 (TID 141). 4676 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 142) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 105.0 (TID 142)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 141) in 61 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 104 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.202 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 105)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 107, ResultStage 111, ShuffleMapStage 108, ShuffleMapStage 109, ShuffleMapStage 110)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[365] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 33.7 KiB, free 321.5 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 321.5 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.6 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[365] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 108.0 with 4 tasks resource profile 0
22/07/24 18:25:47 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_sales/part-00000-c79381f5-f0b0-439a-aaca-89acfda21c12-c000.snappy.parquet, range: 0-44499982, partition values: [empty row]
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 105.0 (TID 142). 4633 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 143) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 142) in 31 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 108.0 (TID 143)
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 105 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.237 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 108)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 107, ResultStage 111, ShuffleMapStage 109, ShuffleMapStage 110)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[375] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 34.0 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[375] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 107.0 with 4 tasks resource profile 0
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 108.0 (TID 143). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 144) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 107.0 (TID 144)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 143) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 107.0 (TID 144). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 145) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 144) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:47 INFO Executor: Running task 1.0 in stage 107.0 (TID 145)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 1.0 in stage 107.0 (TID 145). 5965 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 2.0 in stage 107.0 (TID 146) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 2.0 in stage 107.0 (TID 146)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 145) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 2.0 in stage 107.0 (TID 146). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 3.0 in stage 107.0 (TID 147) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 2.0 in stage 107.0 (TID 146) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:47 INFO Executor: Running task 3.0 in stage 107.0 (TID 147)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 3.0 in stage 107.0 (TID 147). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 148) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 3.0 in stage 107.0 (TID 147) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 107 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.031 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 108)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 111, ShuffleMapStage 109, ShuffleMapStage 110)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO Executor: Running task 1.0 in stage 108.0 (TID 148)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 1.0 in stage 108.0 (TID 148). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 149) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 2.0 in stage 108.0 (TID 149)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 148) in 11 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 2.0 in stage 108.0 (TID 149). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 150) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 3.0 in stage 108.0 (TID 150)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 149) in 9 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 3.0 in stage 108.0 (TID 150). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 150) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 108 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.086 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set()
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 111, ShuffleMapStage 109, ShuffleMapStage 110)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[380] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 58.1 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 321.3 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.1 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[380] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 109.0 with 4 tasks resource profile 0
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 151) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 109.0 (TID 151)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (71.8 KiB) non-empty blocks including 4 (71.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 109.0 (TID 151). 12029 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 152) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 151) in 54 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:47 INFO Executor: Running task 1.0 in stage 109.0 (TID 152)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (70.0 KiB) non-empty blocks including 4 (70.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 1.0 in stage 109.0 (TID 152). 12029 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 2.0 in stage 109.0 (TID 153) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 152) in 57 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:47 INFO Executor: Running task 2.0 in stage 109.0 (TID 153)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_159_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.6 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_158_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_157_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_160_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO Executor: Finished task 2.0 in stage 109.0 (TID 153). 12072 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 3.0 in stage 109.0 (TID 154) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 2.0 in stage 109.0 (TID 153) in 61 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:47 INFO Executor: Running task 3.0 in stage 109.0 (TID 154)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 3.0 in stage 109.0 (TID 154). 12029 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Finished task 3.0 in stage 109.0 (TID 154) in 56 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 109 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.230 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set()
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 111, ShuffleMapStage 110)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[383] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 74.3 KiB, free 321.5 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.6 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[383] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 110.0 with 4 tasks resource profile 0
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 155) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 110.0 (TID 155)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (371.0 B) non-empty blocks including 4 (371.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 110.0 (TID 155). 14630 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 1.0 in stage 110.0 (TID 156) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 1.0 in stage 110.0 (TID 156)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 155) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (473.0 B) non-empty blocks including 4 (473.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 1.0 in stage 110.0 (TID 156). 14630 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 2.0 in stage 110.0 (TID 157) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 1.0 in stage 110.0 (TID 156) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:47 INFO Executor: Running task 2.0 in stage 110.0 (TID 157)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (348.0 B) non-empty blocks including 4 (348.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 2.0 in stage 110.0 (TID 157). 14630 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 3.0 in stage 110.0 (TID 158) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 2.0 in stage 110.0 (TID 157) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:47 INFO Executor: Running task 3.0 in stage 110.0 (TID 158)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (388.0 B) non-empty blocks including 4 (388.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 3.0 in stage 110.0 (TID 158). 14630 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Finished task 3.0 in stage 110.0 (TID 158) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 110 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.027 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set()
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 111)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[385] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 9.6 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[385] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 159) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 111.0 (TID 159)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO DataWritingSparkTask: Writer for partition 0 is committing.
22/07/24 18:25:47 INFO DataWritingSparkTask: Committed partition 0 (task 159, attempt 0, stage 111.0)
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 111.0 (TID 159). 2485 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 159) in 2 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ResultStage 111 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.004 s
22/07/24 18:25:47 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
22/07/24 18:25:47 INFO DAGScheduler: Job 59 finished: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77, took 0.558052 s
22/07/24 18:25:47 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 is committing.
22/07/24 18:25:47 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 committed.
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ss_sold_date_sk),IsNotNull(ss_customer_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ss_sold_date_sk#1154),isnotnull(ss_customer_sk#1157)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<ss_sold_date_sk: int, ss_customer_sk: int>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#332),(d_month_seq#332 >= 1200),(d_month_seq#332 <= 1211),isnotnull(d_date_sk#329)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#154)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(cs_sold_date_sk),IsNotNull(cs_bill_customer_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(cs_sold_date_sk#872),isnotnull(cs_bill_customer_sk#875)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<cs_sold_date_sk: int, cs_bill_customer_sk: int>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2310),(d_month_seq#2310 >= 1200),(d_month_seq#2310 <= 1211),isnotnull(d_date_sk#2307)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2335)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(ws_sold_date_sk),IsNotNull(ws_bill_customer_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(ws_sold_date_sk#1013),isnotnull(ws_bill_customer_sk#1017)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<ws_sold_date_sk: int, ws_bill_customer_sk: int>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(d_month_seq),GreaterThanOrEqual(d_month_seq,1200),LessThanOrEqual(d_month_seq,1211),IsNotNull(d_date_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(d_month_seq#2356),(d_month_seq#2356 >= 1200),(d_month_seq#2356 <= 1211),isnotnull(d_date_sk#2353)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<d_date_sk: int, d_date: date, d_month_seq: int ... 1 more fields>
22/07/24 18:25:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(c_customer_sk)
22/07/24 18:25:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(c_customer_sk#2381)
22/07/24 18:25:47 INFO FileSourceStrategy: Output Data Schema: struct<c_customer_sk: int, c_first_name: string, c_last_name: string ... 1 more fields>
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 293.2 KiB, free 321.1 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 293.2 KiB, free 320.8 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 320.8 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 320.8 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 165 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6037354 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 164 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 9766600 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:47 INFO DAGScheduler: Got job 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:47 INFO DAGScheduler: Final stage: ResultStage 112 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:47 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:47 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[393] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 14.0 KiB, free 320.8 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 320.8 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.9 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[393] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0
22/07/24 18:25:47 INFO DAGScheduler: Got job 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
22/07/24 18:25:47 INFO DAGScheduler: Final stage: ResultStage 113 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
22/07/24 18:25:47 INFO DAGScheduler: Parents of final stage: List()
22/07/24 18:25:47 INFO DAGScheduler: Missing parents: List()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[395] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 160) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 13.3 KiB, free 320.8 MiB)
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 112.0 (TID 160)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 320.8 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 5.7 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[395] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0
22/07/24 18:25:47 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/date_dim/part-00000-75a59129-a25a-4d72-836c-ce88969352f2-c000.snappy.parquet, range: 0-1843050, partition values: [empty row]
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(and(and(noteq(d_month_seq, null), gteq(d_month_seq, 1200)), lteq(d_month_seq, 1211)), noteq(d_date_sk, null))
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 112.0 (TID 160). 5058 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 161) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 160) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ResultStage 112 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.008 s
22/07/24 18:25:47 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 113.0 (TID 161)
22/07/24 18:25:47 INFO DAGScheduler: Job 60 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.009209 s
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 1026.9 KiB, free 319.8 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 319.7 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 168 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:47 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/customer/part-00000-3fb5fb40-6c98-4939-86be-88f3d65875d2-c000.snappy.parquet, range: 0-5572296, partition values: [empty row]
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: noteq(c_customer_sk, null)
22/07/24 18:25:47 INFO MemoryStore: Block taskresult_161 stored as bytes in memory (estimated size 2.4 MiB, free 317.4 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added taskresult_161 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.4 MiB, free: 357.7 MiB)
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 113.0 (TID 161). 2488495 bytes result sent via BlockManager)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_163_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 4.9 KiB, free: 357.7 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_154_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 357.7 MiB)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 161) in 43 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ResultStage 113 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.049 s
22/07/24 18:25:47 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
22/07/24 18:25:47 INFO DAGScheduler: Job 61 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.051976 s
22/07/24 18:25:47 INFO BlockManagerInfo: Removed taskresult_161 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.4 MiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_150_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 4.9 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_147_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_155_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_161_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 24.1 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_162_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 26.6 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_153_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 360.3 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_166_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.9 KiB, free: 360.3 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_152_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 2.9 MiB, free: 363.1 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_148_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 25.0 KiB, free: 363.2 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 16.8 MiB, free 325.4 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 2.9 MiB, free 322.5 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 2.9 MiB, free: 360.3 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 169 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 293.0 KiB, free 322.2 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 322.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.3 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 170 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 124086532 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 293.0 KiB, free 321.9 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 321.9 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 171 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 100763528 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 293.0 KiB, free 321.6 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 321.6 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 25.0 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 172 from $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 48694286 bytes, open cost is considered as scanning 4194304 bytes.
22/07/24 18:25:47 INFO OverwriteByExpressionExec: Start processing data source write support: org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2. The input RDD has 1 partitions.
22/07/24 18:25:47 INFO SparkContext: Starting job: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77
22/07/24 18:25:47 INFO DAGScheduler: Registering RDD 415 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 55
22/07/24 18:25:47 INFO DAGScheduler: Registering RDD 405 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 53
22/07/24 18:25:47 INFO DAGScheduler: Registering RDD 408 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 54
22/07/24 18:25:47 INFO DAGScheduler: Registering RDD 399 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 52
22/07/24 18:25:47 INFO DAGScheduler: Registering RDD 418 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 56
22/07/24 18:25:47 INFO DAGScheduler: Registering RDD 423 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 57
22/07/24 18:25:47 INFO DAGScheduler: Registering RDD 426 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) as input to shuffle 58
22/07/24 18:25:47 INFO DAGScheduler: Got job 62 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) with 1 output partitions
22/07/24 18:25:47 INFO DAGScheduler: Final stage: ResultStage 121 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77)
22/07/24 18:25:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)
22/07/24 18:25:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 120)
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[405] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 36.4 KiB, free 321.6 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 321.5 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[405] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[399] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 162) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 115.0 (TID 162)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 19.9 KiB, free 321.5 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 321.5 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 8.5 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[399] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[415] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 36.4 KiB, free 321.5 MiB)
22/07/24 18:25:47 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/catalog_sales/part-00000-e44b35cf-e4e1-4304-95ca-e106b3d97ef0-c000.snappy.parquet, range: 0-96569224, partition values: [empty row]
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 321.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[415] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(cs_sold_date_sk, null), noteq(cs_bill_customer_sk, null))
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 115.0 (TID 162). 4633 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 163) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4949 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 162) in 54 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 114.0 (TID 163)
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 115 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.056 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 117, ShuffleMapStage 114)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 121, ShuffleMapStage 118, ShuffleMapStage 119, ShuffleMapStage 120, ShuffleMapStage 116)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[408] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 33.7 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.5 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[408] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 116.0 with 4 tasks resource profile 0
22/07/24 18:25:47 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/web_sales/part-00000-c79381f5-f0b0-439a-aaca-89acfda21c12-c000.snappy.parquet, range: 0-44499982, partition values: [empty row]
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ws_sold_date_sk, null), noteq(ws_bill_customer_sk, null))
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 114.0 (TID 163). 4633 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 164) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 163) in 30 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 116.0 (TID 164)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 114 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.084 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 117, ShuffleMapStage 116)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 121, ShuffleMapStage 118, ShuffleMapStage 119, ShuffleMapStage 120)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[418] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 34.0 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 321.4 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 15.6 KiB, free: 360.1 MiB)
22/07/24 18:25:47 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[418] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:47 INFO TaskSchedulerImpl: Adding task set 118.0 with 4 tasks resource profile 0
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 116.0 (TID 164). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 165) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 1.0 in stage 116.0 (TID 165)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 164) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 1.0 in stage 116.0 (TID 165). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 2.0 in stage 116.0 (TID 166) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 165) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:47 INFO Executor: Running task 2.0 in stage 116.0 (TID 166)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 2.0 in stage 116.0 (TID 166). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 3.0 in stage 116.0 (TID 167) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 3.0 in stage 116.0 (TID 167)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 2.0 in stage 116.0 (TID 166) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (176.4 KiB) non-empty blocks including 1 (176.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 3.0 in stage 116.0 (TID 167). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 168) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, PROCESS_LOCAL, 4951 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 3.0 in stage 116.0 (TID 167) in 8 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 117.0 (TID 168)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO FileScanRDD: Reading File path: file:///home/ubuntu/git/spark-tpcds-datagen/tpcds-data-1g/store_sales/part-00000-aadc4cd6-fb63-4cb6-85be-f942835071d3-c000.snappy.parquet, range: 0-119892228, partition values: [empty row]
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 116 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.063 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 117, ShuffleMapStage 118)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 121, ShuffleMapStage 119, ShuffleMapStage 120)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:47 INFO FilterCompat: Filtering using predicate: and(noteq(ss_sold_date_sk, null), noteq(ss_customer_sk, null))
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_176_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.5 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_167_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 5.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_175_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO BlockManagerInfo: Removed broadcast_173_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.7 KiB, free: 360.2 MiB)
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 117.0 (TID 168). 2242 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 169) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 168) in 151 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:47 INFO Executor: Running task 0.0 in stage 118.0 (TID 169)
22/07/24 18:25:47 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
22/07/24 18:25:47 INFO DAGScheduler: ShuffleMapStage 117 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.266 s
22/07/24 18:25:47 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:47 INFO DAGScheduler: running: Set(ShuffleMapStage 118)
22/07/24 18:25:47 INFO DAGScheduler: waiting: Set(ResultStage 121, ShuffleMapStage 119, ShuffleMapStage 120)
22/07/24 18:25:47 INFO DAGScheduler: failed: Set()
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 0.0 in stage 118.0 (TID 169). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 170) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO Executor: Running task 1.0 in stage 118.0 (TID 170)
22/07/24 18:25:47 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 169) in 7 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:47 INFO Executor: Finished task 1.0 in stage 118.0 (TID 170). 6008 bytes result sent to driver
22/07/24 18:25:47 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 171) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:47 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 170) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:47 INFO Executor: Running task 2.0 in stage 118.0 (TID 171)
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 2.0 in stage 118.0 (TID 171). 6008 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 172) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 171) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:48 INFO Executor: Running task 3.0 in stage 118.0 (TID 172)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 1 (68.0 KiB) non-empty blocks including 1 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 3.0 in stage 118.0 (TID 172). 6008 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 172) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:48 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
22/07/24 18:25:48 INFO DAGScheduler: ShuffleMapStage 118 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.205 s
22/07/24 18:25:48 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:48 INFO DAGScheduler: running: Set()
22/07/24 18:25:48 INFO DAGScheduler: waiting: Set(ResultStage 121, ShuffleMapStage 119, ShuffleMapStage 120)
22/07/24 18:25:48 INFO DAGScheduler: failed: Set()
22/07/24 18:25:48 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[423] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:48 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 58.1 KiB, free 321.5 MiB)
22/07/24 18:25:48 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 24.2 KiB, free 321.5 MiB)
22/07/24 18:25:48 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 24.2 KiB, free: 360.2 MiB)
22/07/24 18:25:48 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[423] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:48 INFO TaskSchedulerImpl: Adding task set 119.0 with 4 tasks resource profile 0
22/07/24 18:25:48 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 173) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO Executor: Running task 0.0 in stage 119.0 (TID 173)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (71.8 KiB) non-empty blocks including 4 (71.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 0.0 in stage 119.0 (TID 173). 12029 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 174) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO Executor: Running task 1.0 in stage 119.0 (TID 174)
22/07/24 18:25:48 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 173) in 56 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (177.4 KiB) non-empty blocks including 4 (177.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (70.0 KiB) non-empty blocks including 4 (70.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 1.0 in stage 119.0 (TID 174). 12029 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 175) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO Executor: Running task 2.0 in stage 119.0 (TID 175)
22/07/24 18:25:48 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 174) in 57 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO BlockManagerInfo: Removed broadcast_174_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 8.5 KiB, free: 360.2 MiB)
22/07/24 18:25:48 INFO BlockManagerInfo: Removed broadcast_177_piece0 on ubuntu-Virtual-Machine.mshome.net:35817 in memory (size: 15.6 KiB, free: 360.2 MiB)
22/07/24 18:25:48 INFO Executor: Finished task 2.0 in stage 119.0 (TID 175). 12072 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 176) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4775 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 175) in 60 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:48 INFO Executor: Running task 3.0 in stage 119.0 (TID 176)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (181.6 KiB) non-empty blocks including 4 (181.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (71.6 KiB) non-empty blocks including 4 (71.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 3.0 in stage 119.0 (TID 176). 12029 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 176) in 54 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:48 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
22/07/24 18:25:48 INFO DAGScheduler: ShuffleMapStage 119 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.229 s
22/07/24 18:25:48 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:48 INFO DAGScheduler: running: Set()
22/07/24 18:25:48 INFO DAGScheduler: waiting: Set(ResultStage 121, ShuffleMapStage 120)
22/07/24 18:25:48 INFO DAGScheduler: failed: Set()
22/07/24 18:25:48 INFO DAGScheduler: Submitting ShuffleMapStage 120 (MapPartitionsRDD[426] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:48 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 74.3 KiB, free 321.5 MiB)
22/07/24 18:25:48 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 26.6 KiB, free 321.4 MiB)
22/07/24 18:25:48 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 26.6 KiB, free: 360.2 MiB)
22/07/24 18:25:48 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[426] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/07/24 18:25:48 INFO TaskSchedulerImpl: Adding task set 120.0 with 4 tasks resource profile 0
22/07/24 18:25:48 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 177) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO Executor: Running task 0.0 in stage 120.0 (TID 177)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (371.0 B) non-empty blocks including 4 (371.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 0.0 in stage 120.0 (TID 177). 14630 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 178) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 1, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 177) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/4)
22/07/24 18:25:48 INFO Executor: Running task 1.0 in stage 120.0 (TID 178)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (473.0 B) non-empty blocks including 4 (473.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 1.0 in stage 120.0 (TID 178). 14630 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 179) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 2, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 178) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (2/4)
22/07/24 18:25:48 INFO Executor: Running task 2.0 in stage 120.0 (TID 179)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (348.0 B) non-empty blocks including 4 (348.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 2.0 in stage 120.0 (TID 179). 14630 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 180) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 3, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 179) in 6 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (3/4)
22/07/24 18:25:48 INFO Executor: Running task 3.0 in stage 120.0 (TID 180)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (388.0 B) non-empty blocks including 4 (388.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO Executor: Finished task 3.0 in stage 120.0 (TID 180). 14630 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 180) in 5 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (4/4)
22/07/24 18:25:48 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
22/07/24 18:25:48 INFO DAGScheduler: ShuffleMapStage 120 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.024 s
22/07/24 18:25:48 INFO DAGScheduler: looking for newly runnable stages
22/07/24 18:25:48 INFO DAGScheduler: running: Set()
22/07/24 18:25:48 INFO DAGScheduler: waiting: Set(ResultStage 121)
22/07/24 18:25:48 INFO DAGScheduler: failed: Set()
22/07/24 18:25:48 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[428] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77), which has no missing parents
22/07/24 18:25:48 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 9.6 KiB, free 321.4 MiB)
22/07/24 18:25:48 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 321.4 MiB)
22/07/24 18:25:48 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on ubuntu-Virtual-Machine.mshome.net:35817 (size: 4.9 KiB, free: 360.2 MiB)
22/07/24 18:25:48 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1383
22/07/24 18:25:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[428] at $anonfun$runTpcdsQueries$5 at Benchmark.scala:77) (first 15 tasks are for partitions Vector(0))
22/07/24 18:25:48 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0
22/07/24 18:25:48 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 181) (ubuntu-Virtual-Machine.mshome.net, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/07/24 18:25:48 INFO Executor: Running task 0.0 in stage 121.0 (TID 181)
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
22/07/24 18:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
22/07/24 18:25:48 INFO DataWritingSparkTask: Writer for partition 0 is committing.
22/07/24 18:25:48 INFO DataWritingSparkTask: Committed partition 0 (task 181, attempt 0, stage 121.0)
22/07/24 18:25:48 INFO Executor: Finished task 0.0 in stage 121.0 (TID 181). 2485 bytes result sent to driver
22/07/24 18:25:48 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 181) in 3 ms on ubuntu-Virtual-Machine.mshome.net (executor driver) (1/1)
22/07/24 18:25:48 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
22/07/24 18:25:48 INFO DAGScheduler: ResultStage 121 ($anonfun$runTpcdsQueries$5 at Benchmark.scala:77) finished in 0.004 s
22/07/24 18:25:48 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
22/07/24 18:25:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished
22/07/24 18:25:48 INFO DAGScheduler: Job 62 finished: $anonfun$runTpcdsQueries$5 at Benchmark.scala:77, took 0.552946 s
22/07/24 18:25:48 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 is committing.
22/07/24 18:25:48 INFO OverwriteByExpressionExec: Data source write support org.apache.spark.sql.execution.datasources.noop.NoopBatchWrite$@77d771a2 committed.
  Stopped after 3 iterations, 2447 ms

OpenJDK 64-Bit Server VM 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07 on Linux 5.13.0-51-generic
12th Gen Intel(R) Core(TM) i9-12900HK
TPCDS Snappy:                             Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative
------------------------------------------------------------------------------------------------------------------------
q38                                                 793            816          40          6.6         152.0       1.0X

22/07/24 18:25:48 INFO SparkContext: Invoking stop() from shutdown hook
22/07/24 18:25:48 INFO SparkUI: Stopped Spark web UI at http://ubuntu-Virtual-Machine.mshome.net:4040
22/07/24 18:25:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
22/07/24 18:25:48 INFO MemoryStore: MemoryStore cleared
22/07/24 18:25:48 INFO BlockManager: BlockManager stopped
22/07/24 18:25:48 INFO BlockManagerMaster: BlockManagerMaster stopped
22/07/24 18:25:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
22/07/24 18:25:48 INFO SparkContext: Successfully stopped SparkContext
22/07/24 18:25:48 INFO ShutdownHookManager: Shutdown hook called
22/07/24 18:25:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-7e52b938-b585-4138-b140-fcf9859542f5
22/07/24 18:25:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-418ce721-0a2c-4ce0-86c6-2a6cca94e1ce
ubuntu@ubuntu-Virtual-Machine:~/git/spark-tpcds-datagen$ 
